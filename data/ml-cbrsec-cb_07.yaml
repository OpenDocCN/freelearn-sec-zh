- en: Securing and Attacking Data with Machine Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用机器学习保护和攻击数据
- en: In this chapter, we will learn how to employ **machine learning** (**ML**) to
    secure and attack data. We will cover how to assess the strength of a password
    using ML, and conversely, how to crack passwords using deep learning. Similarly,
    we will cover how to hide messages in plain sight using steganography, as well
    as how to detect steganography using ML. In addition, we will apply ML with hardware
    security to attack **physically unclonable functions** (**PUFs**) using AI.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习如何利用**机器学习**（**ML**）来保护和攻击数据。我们将介绍如何使用机器学习评估密码强度，以及如何利用深度学习破解密码。同样，我们还会介绍如何利用隐写术将信息藏匿在明面上，以及如何使用机器学习检测隐写术。此外，我们还将将机器学习与硬件安全结合，利用AI攻击**物理不可克隆函数**（**PUF**）。
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下内容：
- en: Assessing password security using ML
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用机器学习评估密码安全性
- en: Deep learning for password cracking
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用深度学习进行密码破解
- en: Deep steganography
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度隐写术
- en: ML-based steganalysis
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于机器学习的隐写分析
- en: ML attacks on PUFs
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 针对PUF的机器学习攻击
- en: Encryption using deep learning
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用深度学习进行加密
- en: HIPAA data breaches – data exploration and visualization
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HIPAA数据泄露——数据探索与可视化
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'In this chapter, we will be using the following technologies:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用以下技术：
- en: PyTorch
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyTorch
- en: TensorBoardX
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorBoardX
- en: XGBoost
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: XGBoost
- en: scikit-learn
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: scikit-learn
- en: pandas
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: pandas
- en: TensorFlow
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow
- en: Keras
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Keras
- en: Octave
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Octave
- en: The code and datasets for this chapter can be found at [https://github.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/tree/master/Chapter07](https://github.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/tree/master/Chapter07).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码和数据集可以在[https://github.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/tree/master/Chapter07](https://github.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/tree/master/Chapter07)找到。
- en: Assessing password security using ML
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用机器学习评估密码安全性
- en: '**Password cracking** is the systematic endeavor of discovering the password
    of a secure system. Cracking can involve using common passwords, cleverly generated
    candidate passwords (for example, replacing the letter O with the number 0 or
    writing a word backward), or just using a plain bruteforce exhaustive search.
    To make it more difficult to crack a password, a strong password must be chosen.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**密码破解**是系统化地发现安全系统密码的过程。破解可以包括使用常见密码、巧妙生成的候选密码（例如，将字母O替换为数字0或将单词反向书写），或直接使用暴力穷举搜索。为了使密码更难破解，必须选择一个强密码。'
- en: Getting ready
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'To prepare for this recipe, we need to install `pandas`, `sklearn`, and `xgboost`
    in `pip`. Use the following code to do so:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 为了准备这个配方，我们需要在`pip`中安装`pandas`、`sklearn`和`xgboost`。使用以下代码进行安装：
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In addition, extract the archived dataset, that is, `PasswordDataset.7z`.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，解压归档数据集，即`PasswordDataset.7z`。
- en: How to do it…
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'In the following steps, we will read in a dataset of passwords, along with
    labels for their strength, and build a classifier to assess password strength.
    Let''s get started:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的步骤中，我们将读取一个包含密码及其强度标签的数据集，并构建一个分类器来评估密码强度。让我们开始吧：
- en: 'Import `pandas` and read in the passwords into a dataframe:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`pandas`并将密码读取到数据框中：
- en: '[PRE1]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Shuffle the data at random:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随机打乱数据：
- en: '[PRE2]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Split the dataframe into two separate dataframes, one for training and one
    for testing:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据框拆分为两个独立的数据框，一个用于训练，一个用于测试：
- en: '[PRE3]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Create the required labels and featured data:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建所需的标签和特征数据：
- en: '[PRE4]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Define a function that splits a string into its characters:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数，将字符串拆分为其字符：
- en: '[PRE5]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Create a pipeline to perform TF-IDF on the characters of the passwords, followed
    by gradient boosting:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个管道，对密码的字符进行TF-IDF处理，然后进行梯度提升：
- en: '[PRE6]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Train and test the pipeline:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练和测试管道：
- en: '[PRE7]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The following is the output:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是输出结果：
- en: '[PRE8]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Set one variable as a commonly used password and one as a computer-generated,
    high-entropy password:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置一个变量为常用密码，另一个变量为计算机生成的高熵密码：
- en: '[PRE9]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Check what the classifier predicts for the strength of the two passwords:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查分类器对两个密码强度的预测：
- en: '[PRE10]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The following is the output:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是输出结果：
- en: '[PRE11]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: How it works…
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: 'We start by importing `pandas` and then reading our data into a dataframe (*step
    1*). There are two fields in this data: password and password strength. Password
    strength consists of three levels of difficulty. We shuffle the data to create
    more robust training in *step 2*. In *step 3*, we split the dataframe via an 80-20
    split, and then distribute the features and labels into arrays (*step 4*). In
    *step 5*, we define a function that splits the password strings into characters
    in order to tokenize passwords into characters, rather than into words. This will
    allow the classifier to learn fine-grained information about the password dataset.
    In *step 6*, we define a pipeline to perform NLP on the characters of a password,
    followed by using an XGBoost classifier. Next, we train and test our classifier
    (*step 7*). For a somewhat subjective task such as this, the performance of a
    classifier will not necessarily be reflected in a high or low score.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先导入`pandas`，然后将数据读取到一个数据框中（*步骤 1*）。数据中有两个字段：密码和密码强度。密码强度分为三种难度等级。我们在*步骤 2*中打乱数据，以创建更强健的训练。接着，在*步骤
    3*中，我们通过 80-20 的比例划分数据框，然后将特征和标签分配到数组中（*步骤 4*）。在*步骤 5*中，我们定义一个函数，将密码字符串拆分成字符，从而将密码分词为字符，而不是单词。这样可以让分类器学习密码数据集中的细粒度信息。在*步骤
    6*中，我们定义一个管道，对密码的字符进行自然语言处理（NLP），然后使用 XGBoost 分类器。接下来，在*步骤 7*中，我们训练并测试我们的分类器。对于这样的主观任务，分类器的表现不一定会在高分或低分上体现。
- en: Having finished the training, we perform a sanity check/demonstration of the
    efficacy of the classifier. We choose one of the most common passwords and one
    that was generated using a password management system in *step 8*. In *step 9*,
    we can see that the classifier indeed classified the common password as weak (strength
    0) and the strong password as strong (strength 2). Success.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 完成训练后，我们进行合理性检查/演示分类器的有效性。在*步骤 8*中，我们选择最常见的密码之一和一个使用密码管理系统生成的密码。在*步骤 9*中，我们可以看到分类器确实将常见密码分类为弱（强度
    0），而强密码分类为强（强度 2）。成功。
- en: Deep learning for password cracking
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 密码破解的深度学习
- en: Modern password cracking tools, such as **John the Ripper**, allow a hacker
    to test billions of potential passwords in a matter of seconds. Not only do such
    tools allow a hacker to try out every password in a dictionary of common passwords,
    but they can also automatically transform these passwords by using concatenation
    (for example, `password1234`), leetspeak (`p4s5w0rd`), and other promising techniques.
    Though these techniques are promising, finding additional promising transformations
    is a difficult task. The ML system known as PassGAN uses a **generative adversarial
    network** (**GAN**) to automatically learn such rules by observing large datasets
    of real passwords (gathered from a corpus of actual password leaks) and to generate
    high-probability password candidates. In this recipe, you will train PassGAN on
    a corpus of leaked passwords and use it to generate password guesses.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 现代的密码破解工具，如**John the Ripper**，允许黑客在几秒钟内测试数十亿个潜在密码。这些工具不仅能让黑客尝试字典中所有常见密码，还可以通过连接（例如，`password1234`）、键盘替换（`p4s5w0rd`）等技巧自动转换密码。虽然这些技巧有前景，但发现其他有效的转换方法是一个困难的任务。被称为
    PassGAN 的机器学习系统使用**生成对抗网络**（**GAN**），通过观察大量实际密码泄露数据集，自动学习这些规则，并生成高概率的密码候选。 在这个食谱中，你将训练
    PassGAN 来处理泄露的密码语料库，并使用它生成密码猜测。
- en: This project will require a machine with a GPU.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 该项目需要一台配有 GPU 的机器。
- en: Getting ready
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'In preparation for this recipe, perform the following steps:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 为了准备这个食谱，请执行以下步骤：
- en: 'Clone the `PassGAN` repository using the following command:'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令克隆 `PassGAN` 仓库：
- en: '[PRE12]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Place a dataset under the `data` folder. For example, you may download the
    famous `rockyou` password dataset using the following command:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据集放置在 `data` 文件夹下。例如，你可以使用以下命令下载著名的 `rockyou` 密码数据集：
- en: '[PRE13]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'You should see something like the following when running the password dataset:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行密码数据集时，你应该看到如下内容：
- en: '![](assets/d1dc04f5-2f2a-4e10-99a0-1755cca13225.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/d1dc04f5-2f2a-4e10-99a0-1755cca13225.png)'
- en: 'In addition, this recipe requires CUDA 8 to be preinstalled. The required `pip`
    packages can be installed by running the following command:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，本食谱要求预先安装 CUDA 8。所需的 `pip` 包可以通过运行以下命令来安装：
- en: '[PRE14]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: How to do it…
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做……
- en: 'In the following steps, we will train PassGAN on a corpus of leaked passwords
    and then use it to generate new password guesses. Let''s get started:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的步骤中，我们将使用泄露的密码语料库来训练PassGAN，并用它生成新的密码猜测。让我们开始吧：
- en: 'Train your neural network on the dataset by running the following command:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行以下命令，使用数据集训练你的神经网络：
- en: '[PRE15]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Generate a list of (100,000) password guesses by running the following command:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行以下命令生成（100,000）个密码猜测的列表：
- en: '[PRE16]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Your Terminal should look something like the following:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 你的终端应该显示如下内容：
- en: '![](assets/7197b71e-53dd-4103-8677-89b8d6530faf.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/7197b71e-53dd-4103-8677-89b8d6530faf.png)'
- en: How it works…
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: 'We hit the ground running in this recipe by training our neural network straight
    away in *step 1*. Several additional flags are available to customize training,
    depending on our needs. Now that we''ve trained our model, we need to output a
    list of 100,000 passwords, all of which have been generated by the model (*step
    2*). These serve as intelligent guesses of likely passwords. By examining the
    output of *step 2*, we can see that the passwords appear as follows:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们在*步骤1*中直接训练了我们的神经网络。根据需要，还可以使用几个附加的标志来定制训练。现在我们已经训练好了模型，接下来需要输出一个包含100,000个密码的列表，所有这些密码都是由模型生成的（*步骤2*）。这些密码是可能的智能猜测。通过检查*步骤2*的输出，我们可以看到密码的展示方式如下：
- en: '![](assets/accc3663-4d95-4391-b435-b6b3147a87b2.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/accc3663-4d95-4391-b435-b6b3147a87b2.png)'
- en: Now, we can use these as candidates for cracking passwords.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以将这些作为破解密码的候选项。
- en: There's more
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多内容
- en: The original paper describing PassGAN can be found at [https://arxiv.org/abs/1709.00440](https://arxiv.org/abs/1709.00440).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 描述PassGAN的原始论文可以在[https://arxiv.org/abs/1709.00440](https://arxiv.org/abs/1709.00440)找到。
- en: Deep steganography
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度隐写术
- en: Steganography is the practice of hiding a message (that is, the secret) within
    another medium, such as a file, text, image, or video (that is, the cover). When
    the secret is embedded into the cover, the result is called the **container**.
    In this recipe, we will use deep neural networks to create the hiding and revealing
    processes. Unlike common steganographic methods, which encode the secret in the
    LSB of the cover, deep learning distributes the secret across all bits.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 隐写术是将一条消息（即秘密）隐藏在另一种媒介中的实践，比如文件、文本、图像或视频（即封面）。当秘密嵌入到封面中时，结果称为**容器**。在本教程中，我们将使用深度神经网络来创建隐藏和揭示过程。与常见的隐写方法不同，深度学习将秘密分布在所有位上，而不是仅仅编码在封面的最低有效位（LSB）中。
- en: Getting ready
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: In this recipe, you will need access to a GPU.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个教程中，你将需要访问一个GPU。
- en: How to do it…
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'Clone the repository using the following command:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令克隆仓库：
- en: '[PRE17]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Prepare a pretrained model:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准备一个预训练模型：
- en: '[PRE18]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Prepare a secret image and a cover image in the `example_pics` folder:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`example_pics`文件夹中准备一个秘密图像和一个封面图像：
- en: 'As you can see, we are using the following image as the cover image:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们使用以下图像作为封面图像：
- en: '![](assets/f2a3c562-1e86-4d91-a79f-289b6e59b284.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/f2a3c562-1e86-4d91-a79f-289b6e59b284.png)'
- en: 'We are using the following image as the secret image:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用以下图像作为秘密图像：
- en: '![](assets/35e17f89-b9a2-4a6a-9534-a3febfbbe528.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/35e17f89-b9a2-4a6a-9534-a3febfbbe528.png)'
- en: 'Execute the pretrained model to produce a container image and a reconstructed
    secret:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行预训练模型生成容器图像和重建的秘密：
- en: '[PRE19]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The first part of the output is displayed in the following screenshot:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 输出的第一部分显示在以下截图中：
- en: '![](assets/a5e2086c-f527-44cd-80cf-fd202b5bc819.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/a5e2086c-f527-44cd-80cf-fd202b5bc819.png)'
- en: 'The second part of the output is displayed in the following screenshot:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 输出的第二部分显示在以下截图中：
- en: '![](assets/1b1e7753-0f80-4cbc-bd1d-cf6c916d4dc6.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/1b1e7753-0f80-4cbc-bd1d-cf6c916d4dc6.png)'
- en: 'The final part of the output is displayed in the following screenshot:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 输出的最后一部分显示在以下截图中：
- en: '![](assets/98320e7f-704f-44e9-b4dc-f38e585e6103.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/98320e7f-704f-44e9-b4dc-f38e585e6103.png)'
- en: 'Examine your results under the training folder. You should see the following
    image:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练文件夹下查看结果。你应该能看到以下图像：
- en: '![](assets/d2cfcfb2-9eb9-4b12-ac11-e61602d58d83.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/d2cfcfb2-9eb9-4b12-ac11-e61602d58d83.png)'
- en: 'Row 1: cover. Row 2: container. Row 3: secret. Row 4: reconstructed secret'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 第1行：封面。第2行：容器。第3行：秘密。第4行：重建的秘密
- en: How it works…
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: 'In *step 1*, we simply clone the repository for the deep steganography project.
    Some background on the theory and implementation of this project can be found
    in the paper *Hiding Images in Plain Sight: Deep Steganography* ([https://papers.nips.cc/paper/6802-hiding-images-in-plain-sight-deep-steganography](https://papers.nips.cc/paper/6802-hiding-images-in-plain-sight-deep-steganography)).'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤1*中，我们简单地克隆了深度隐写术项目的存储库。关于该项目的理论和实现的背景可以在论文*在明处隐藏图像：深度隐写术*中找到（[https://papers.nips.cc/paper/6802-hiding-images-in-plain-sight-deep-steganography](https://papers.nips.cc/paper/6802-hiding-images-in-plain-sight-deep-steganography)）。
- en: The basic idea is that there is a **hiding network** (**H-net**) and a **reveal
    network** (**R-net**), both of which are trained adversarially. Continuing to
    *step 2*, we prepare our pretrained model. The model that we used here was trained
    on 45,000 images from ImageNet, and evaluated on 5,000 images. All of the images
    were resized to 256 × 256 without normalization and the task took 24 hours of
    training on a single NVIDIA GTX 1080 Ti. Next, we pick two images of our choosing
    to serve as a cover and a secret (*step 3*). Feel free to use your own pair of
    images. In *steps 4* and *5*, we run the model, create a container image (the
    one containing the hidden secret), and produce an image showing our results. As
    you can see, the container image and cover image are indistinguishable to the
    human eye, meaning that no one will be able to tell that you have hidden a secret
    in the cover image.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 基本思想是有一个**隐藏网络**（**H-net**）和一个**揭示网络**（**R-net**），两者都是通过对抗训练的。继续到*步骤2*，我们准备我们的预训练模型。我们在这里使用的模型是在ImageNet的45000张图像上训练的，并在5000张图像上进行了评估。所有图像都被调整为256×256，没有归一化，任务在一块NVIDIA
    GTX 1080 Ti上进行了24小时的训练。接下来，我们选择两张我们选择的图像作为封面和秘密（*步骤3*）。请随意使用您自己的图像对。在*步骤4*和*5*中，我们运行模型，创建一个容器图像（包含隐藏秘密的图像），并生成一个显示我们结果的图像。正如您所看到的，容器图像和封面图像在人眼中是无法区分的，这意味着没有人能够看出您在封面图像中隐藏了一个秘密。
- en: ML-based steganalysis
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于机器学习的隐写分析
- en: One of the main techniques in steganography is hiding messages in images by
    altering the **least significant bits** (**LSB**) of the pixels with those of
    the message bits. The result is an image with a message hidden in it that the
    human eye cannot distinguish from the original image. This is because, on changing
    the LSB in the pixels of an image, the pixel values are only altered by a small
    amount, resulting in a visually similar image.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 隐写术中的主要技术之一是通过改变像素的**最低有效位**（**LSB**）来隐藏消息在图像中。结果是一个带有隐藏消息的图像，人眼无法区分其与原始图像的区别。这是因为在改变图像像素的LSB时，像素值只会被微小地改变，导致一个视觉上相似的图像。
- en: 'There are two prominent methods for LSB:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: LSB有两种显著的方法：
- en: The naïve method is called LSB replacement. In this method, the LSB bit remains
    unchanged if the message bit is the same as the LSB; otherwise, the bit is altered.
    Hence, the odd pixels are reduced by 1 in intensity, whereas the even pixel values
    are incremented by 1\. However, this causes an imbalance in the image histogram,
    which can be easily detected by statistical methods for steganalysis.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 天真的方法被称为LSB替换。在这种方法中，如果消息位与LSB相同，则LSB位保持不变；否则，该位被改变。因此，奇数像素的强度减少1，而偶数像素值增加1。然而，这会导致图像直方图的不平衡，可以很容易地通过统计方法检测到进行隐写分析。
- en: The second method of LSB steganography, LSB matching, solves this issue by randomly
    incrementing or decrementing the pixel values by 1 in the case of an LSB bit mismatch.
    This avoids the issue of histogram imbalance and makes it difficult to perform
    steganalysis by using simple statistical methods alone.
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LSB隐写术的第二种方法，LSB匹配，通过在LSB位不匹配的情况下随机增加或减少像素值1来解决这个问题。这避免了直方图不平衡的问题，并使得仅仅使用简单的统计方法进行隐写分析变得困难。
- en: The following images showcase an instance of LSB steganography.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像展示了LSB隐写术的一个实例。
- en: 'The following image will be represented as the cover image:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像将被表示为封面图像：
- en: '![](assets/5bd5edf5-8377-4c3b-9da4-d7ee6d1e17df.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/5bd5edf5-8377-4c3b-9da4-d7ee6d1e17df.png)'
- en: 'The following image will be represented as the secret image:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像将被表示为秘密图像：
- en: '![](assets/7367064b-4bb2-43e9-9e47-2a5a0aa99418.jpg)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/7367064b-4bb2-43e9-9e47-2a5a0aa99418.jpg)'
- en: 'The following image will be represented as the container image:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像将被表示为容器图像：
- en: '![](assets/5bd5edf5-8377-4c3b-9da4-d7ee6d1e17df.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/5bd5edf5-8377-4c3b-9da4-d7ee6d1e17df.png)'
- en: 'The following image will be shown as the recovered secret image:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像将被显示为恢复的秘密图像：
- en: '![](assets/14495d48-9d6f-4046-84d7-771a68b60620.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/14495d48-9d6f-4046-84d7-771a68b60620.png)'
- en: Getting ready
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'It is recommended that you complete this recipe on a Linux machine. Follow
    these steps to get everything set up:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐你在Linux机器上完成此配方。按照以下步骤设置好环境：
- en: 'Install `octave`, as well as its packages, `image` and `signal`:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装` octave `以及其包` image `和` signal `：
- en: '[PRE20]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Clone the repository for `aletheia`, as shown in the following code:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 克隆` aletheia `的代码库，如以下代码所示：
- en: '[PRE21]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Download a `BOSS` dataset, which you can download via the following link:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载`BOSS`数据集，你可以通过以下链接下载：
- en: '[PRE22]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: This will retrieve a database of grayscale images.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这将检索一个灰度图像数据库。
- en: 'Unzip the dataset and rename the `BOSSbase` folder:'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解压数据集并重命名` BOSSbase `文件夹：
- en: '[PRE23]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: For your convenience, the processed datasets, namely `bossbase.7z` and `bossbase_lsb.7z`,
    can be found in this book's repository.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 为了方便你，处理过的数据集，即` bossbase.7z `和` bossbase_lsb.7z `，可以在本书的代码库中找到。
- en: How to do it...
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'In this recipe, we will curate an LSB dataset and then train and test an ML
    model to detect the presence of LSB steganography in an image. Let''s get started:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在本配方中，我们将策划一个LSB数据集，然后训练和测试一个机器学习模型，检测图像中是否存在LSB隐写术。让我们开始吧：
- en: 'Create an LSB database using the following command:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令创建一个LSB数据库：
- en: '[PRE24]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The result is a new folder named `bossbase_lsb`, which contains the BOSS images
    with embeddings. It does this using an LSB matching simulator.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是一个名为` bossbase_lsb `的新文件夹，包含了带有嵌入的BOSS图像。它通过LSB匹配模拟器完成此操作。
- en: 'Featurize the `BOSS` dataset, as shown in the following code:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对` BOSS `数据集进行特征化，如以下代码所示：
- en: '[PRE25]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Featurize the LSB dataset, as shown in the following code:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对LSB数据集进行特征化，如以下代码所示：
- en: '[PRE26]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The remaining steps can be run in a Python environment for your convenience.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 剩余的步骤可以在Python环境中运行，方便你使用。
- en: 'Create some variables that point to the path of the extracted features:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一些指向提取特征路径的变量：
- en: '[PRE27]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Collect the features and labels and put them in arrays:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 收集特征和标签并将它们放入数组中：
- en: '[PRE28]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Perform a train-test split:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行训练-测试集划分：
- en: '[PRE29]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Instantiate a `RandomForestClassifier` and train it:'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化一个` RandomForestClassifier `并进行训练：
- en: '[PRE30]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Score the classifier on the test set:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在测试集上对分类器进行评分：
- en: '[PRE31]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The following is the output:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是输出结果：
- en: '[PRE32]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: How it works…
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: 'We start this recipe by creating a large dataset of LSB steganography container
    images using the software known as Aletheia (*step 1*). Aletheia offers a wide
    array of functionality. Run the following command with no arguments:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从使用被称为Aletheia的软件创建一个大型LSB隐写容器图像数据集开始（*步骤1*）。Aletheia提供了广泛的功能。运行以下命令，不带任何参数：
- en: '[PRE33]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The preceding command prints out the following information about `aletheia`:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 上述命令将打印出关于` aletheia `的以下信息：
- en: '[PRE34]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: In *steps 2* and *3*, we employ the `srm` command of Aletheia to extract features
    of the plain images and container images. The `srm` command extracts a full and
    spatially rich feature set. Other alternative feature sets are available as well.
    Next, we create variables pointing to the paths of our dataset (*step 4*) and
    then collect our features and our labels into arrays (*step 5*). In *steps 6*-*8*,
    we create a train-test split, train a classifier, and then test it. Looking at
    the performance of 80% on the balanced dataset, we can see that the features do
    help us to distinguish between plain and container images. In other words, we
    can conclude that ML can detect steganography.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤2*和*步骤3*中，我们使用Aletheia的` srm `命令提取原始图像和容器图像的特征。` srm `命令提取了完整且空间丰富的特征集。还有其他替代的特征集可供选择。接下来，我们创建指向数据集路径的变量（*步骤4*），然后将我们的特征和标签收集到数组中（*步骤5*）。在*步骤6*至*步骤8*中，我们创建训练集和测试集，训练分类器，并进行测试。通过查看在平衡数据集上80%的表现，我们可以看出这些特征确实有助于我们区分原始图像和容器图像。换句话说，我们可以得出结论：机器学习可以检测隐写术。
- en: ML attacks on PUFs
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 针对PUF的机器学习攻击
- en: Classical cryptography offers several measures for securing electronic devices.
    These mainly rely on a secret key and expensive resources due to the device permanently
    storing a piece of digital information that's unknown to our adversaries. In practice,
    it is difficult to keep this information confidential. This problem motivated
    the invention of PUF – physical devices that produce an output that's quick to
    evaluate yet hard to predict.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 经典密码学提供了多种保护电子设备的措施。这些措施主要依赖于一个秘密密钥和昂贵的资源，因为设备会永久存储一段对我们的对手未知的数字信息。实际上，很难保持这些信息的机密性。这个问题促使了PUF的发明——物理设备，它能快速评估输出，但却难以预测。
- en: 'To authenticate using a PUF, we need to construct a database of **Challenge-Response
    Pairs (CRPs)**. A challenge is a binary string (for example, 1100101...01) of
    length *n*, and a response is some other binary string of length *m*. To find
    out whether an unknown device is the aforementioned PUF, we need to issue it a
    number of challenges, verifying that it produces the correct responses until we
    reach the desired probability that it is indeed the same PUF. Note that PUFs themselves
    are not 100% reliable, and the same challenge may yield different responses due
    to varying environmental conditions and noise:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用PUF进行身份验证，我们需要构建一个**挑战-响应对（CRP）**的数据库。挑战是一个二进制字符串（例如，1100101...01），长度为*n*，响应是另一个二进制字符串，长度为*m*。为了判断一个未知设备是否为前述的PUF，我们需要向其发出多个挑战，验证它是否产生正确的响应，直到我们达到所期望的概率，确认它确实是同一个PUF。请注意，PUF本身并不是100%可靠的，相同的挑战可能由于环境条件和噪声的变化而产生不同的响应：
- en: '![](assets/66824f3c-08c0-42ca-9e80-269d0a8574d3.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/66824f3c-08c0-42ca-9e80-269d0a8574d3.png)'
- en: 'Figure 8: PUF-based commercial RFID tag'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 图8：基于PUF的商业RFID标签
- en: In this recipe, we will be attacking a specific PUF using ML. Note that the
    field is ever-evolving, and other, more secure, PUFs have been proposed, as well
    as methods to increase the reliability and security of PUFs using ML.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在此食谱中，我们将使用机器学习攻击一个特定的PUF。请注意，该领域不断发展，已经提出了其他更安全的PUF，以及利用机器学习提高PUF可靠性和安全性的方法。
- en: Getting ready
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'For this recipe, we need to install `pandas`, `sklearn`, and `xgboost` in `pip`.
    Use the following code to do so:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 对于此食谱，我们需要通过`pip`安装`pandas`、`sklearn`和`xgboost`。使用以下代码来安装：
- en: '[PRE35]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: In addition, the `CRPDataset.csv` dataset has been provided for this recipe.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，已为此食谱提供了`CRPDataset.csv`数据集。
- en: How to do it...
  id: totrans-173
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Let''s learn how to crack a PUF with ML:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们学习如何用机器学习破解一个PUF：
- en: 'Load a CRP dataset, in this case, `CRPDataset.csv`:'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载一个CRP数据集，在本例中为`CRPDataset.csv`：
- en: '[PRE36]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: The data is made up of pairs (*x*,*y*), where *x* is a binary string that's
    64 in length and *y* is a binary digit. Here, *x* is a challenge and *y* is a
    response.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 数据由对（*x*,*y*）组成，其中*x*是长度为64的二进制字符串，*y*是一个二进制数字。这里，*x*是挑战，*y*是响应。
- en: 'Convert the `pandas` dataframe into a NumPy array of features and labels:'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`pandas`数据框转换为NumPy特征和标签数组：
- en: '[PRE37]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Perform a train-test split:'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行训练-测试拆分：
- en: '[PRE38]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Instantiate and train an XGBoost classifier:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化并训练XGBoost分类器：
- en: '[PRE39]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The following is the output:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是输出结果：
- en: '[PRE40]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Test the classifier, as shown in the following code:'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测试分类器，如以下代码所示：
- en: '[PRE41]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The following is the output:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是输出结果：
- en: '[PRE42]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: How it works…
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: We start by reading a CRP dataset into a dataframe (*step 1*). In *step 2*,
    we create x and y NumPy arrays to hold the features and labels. Next, we train-test
    split our data (*step 3*) and then train and test a classifier for CRPs (*steps
    4* and *5*). Based on performance, we can see that ML can accurately predict responses
    to PUF challenges. The implications are that, while using our trained model, we
    can build a software clone of the PUF and use it to (falsely) authenticate.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先将一个CRP数据集读取到一个数据框中（*步骤1*）。在*步骤2*中，我们创建x和y的NumPy数组来保存特征和标签。接下来，我们对数据进行训练-测试拆分（*步骤3*），然后训练和测试一个针对CRP的分类器（*步骤4*和*步骤5*）。根据性能结果，我们可以看到，机器学习可以准确预测PUF挑战的响应。其意义在于，在使用我们训练好的模型时，我们可以构建一个PUF的软件克隆，并用它来（虚假地）进行身份验证。
- en: There's more
  id: totrans-192
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多
- en: The original unprocessed dataset for this recipe can be found at [https://archive.ics.uci.edu/ml/datasets/Physical+Unclonable+Functions](https://archive.ics.uci.edu/ml/datasets/Physical+Unclonable+Functions).
    Additional background information can be found in the paper, *A Machine Learning-Based
    Security Vulnerability Study* *on XOR PUFs for Resource-Constraint Internet of
    Things*, by Aseeri, A. O., Zhuang, Y., and Alkatheiri, M. S. (July 2018) in 2018
    IEEE International Congress on Internet of Things (ICIOT) (pp. 49-56). IEEE.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 该食谱的原始未处理数据集可以在[https://archive.ics.uci.edu/ml/datasets/Physical+Unclonable+Functions](https://archive.ics.uci.edu/ml/datasets/Physical+Unclonable+Functions)找到。更多背景信息可以在论文《*基于机器学习的资源受限物联网XOR
    PUF安全漏洞研究*》（Aseeri, A. O.，Zhuang, Y.，和Alkatheiri, M. S.，2018年7月，发表于2018年IEEE国际物联网大会（ICIOT）（第49-56页），IEEE）中找到。
- en: Encryption using deep learning
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用深度学习进行加密
- en: Encryption is the process of converting information into code to prevent unauthorized
    access. In this recipe, we will utilize a convolutional neural network to encrypt
    and decrypt data.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 加密是将信息转换为代码以防止未经授权的访问的过程。在此食谱中，我们将利用卷积神经网络对数据进行加密和解密。
- en: Getting ready
  id: totrans-196
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'For this recipe, you will need to install the `click`, `keras`, `tensorflow`,
    and `tqdm` packages in `pip`. Use the following code to do so:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个食谱，你需要在`pip`中安装`click`、`keras`、`tensorflow`和`tqdm`包。使用以下代码来安装：
- en: '[PRE43]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Additionally, clone the repository using the following command:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，请使用以下命令克隆该仓库：
- en: '[PRE44]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: How to do it...
  id: totrans-201
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'The following steps will guide you through how to use ConvCrypt in order to
    encrypt an image. Let''s get started:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤将指导你如何使用ConvCrypt来加密图片。让我们开始吧：
- en: 'Run the `encrypt.py` script against the image or file you would like to encrypt:'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行`encrypt.py`脚本，对你希望加密的图片或文件进行加密：
- en: '[PRE45]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'The output of the preceding code is displayed in the following screenshot:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码的输出显示在以下截图中：
- en: '![](assets/30ee7e0b-5535-40d2-99a1-07f8799ed0a9.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/30ee7e0b-5535-40d2-99a1-07f8799ed0a9.png)'
- en: 'To see that the file has been encrypted, attempt to open it. We will see that
    it cannot be opened due to it being encrypted:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 若要确认文件已被加密，尝试打开它。你会发现它无法打开，因为它已经被加密：
- en: '![](assets/3ea4a5e5-e897-46ae-aa0a-c93e60eb77e4.png)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/3ea4a5e5-e897-46ae-aa0a-c93e60eb77e4.png)'
- en: 'To decrypt the file, execute the `decrypt.py` script against the encrypted
    file and the key file:'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 若要解密文件，执行`decrypt.py`脚本，传入加密文件和密钥文件：
- en: '[PRE46]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: The result is the original file.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是原始文件。
- en: How it works...
  id: totrans-212
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: We begin this recipe by encrypting our image using ConvCrypt (*step 1*). ConvCrypt
    is a proof-of-concept experimental encryption algorithm that uses *n*-dimensional
    convolutional neural networks. Currently, it only supports three-dimensional convolutions.
    Then, in *step 2*, we reverse the encryption and test it to ensure that the result
    is the original file. Success!
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过使用ConvCrypt对图片进行加密开始这个食谱（*步骤1*）。ConvCrypt是一种概念验证实验性加密算法，使用*n*维卷积神经网络。目前，它仅支持三维卷积。然后，在*步骤2*中，我们将逆向解密并进行测试，以确保结果是原始文件。成功！
- en: For those of you who are interested, the first thing the ConvCrypt algorithm
    does is separate the data into blocks. Then, a key is generated for 3D convolutions;
    this is a randomly generated cube of bits that are the same size as a data block.
    Lastly, a convolutional neural network is trained to convolve the key into each
    data block so that each data block gets its own trained network. The resulting
    encrypted data is the weights of each of the networks (the values of the kernel
    tensors).
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 对于有兴趣的朋友，ConvCrypt算法首先做的事情是将数据分成块。然后，为3D卷积生成一个密钥；这是一个随机生成的比特立方体，大小与数据块相同。最后，训练一个卷积神经网络，将密钥卷积到每个数据块中，这样每个数据块就会有自己训练好的网络。加密后的数据是每个网络的权重（即核张量的值）。
- en: HIPAA data breaches – data exploration and visualization
  id: totrans-215
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: HIPAA数据泄露——数据探索与可视化
- en: Data exploration is the initial step in data analysis, whereby visual exploration
    is used to understand a dataset and the characteristics of the data. Data visualization
    helps us understand the data by placing it in an optical context so that our powerful
    visual processing centers can quickly find patterns and correlations in the data.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 数据探索是数据分析的初步步骤，通过可视化探索来理解数据集及其特点。数据可视化帮助我们通过将数据置于光学背景中，利用我们强大的视觉处理中心快速发现数据中的模式和相关性。
- en: In this recipe, you will explore and visualize a public domain dataset regarding
    breaches of HIPAA confidential information.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，你将探索并可视化一个关于HIPAA机密信息泄露的公共数据集。
- en: Getting ready
  id: totrans-218
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备开始
- en: 'For this recipe, you will need to install `pandas` and `sklearn` in `pip`.
    Use the following code to do so:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个食谱，你需要在`pip`中安装`pandas`和`sklearn`。使用以下代码来安装：
- en: '[PRE47]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: In addition, the `HIPAA-breach-report-2009-to-2017.csv` dataset has been provided
    so that you can use it in this recipe.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，提供了`HIPAA-breach-report-2009-to-2017.csv`数据集，供你在本食谱中使用。
- en: How to do it…
  id: totrans-222
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'In the following steps, you will visualize the HIPAA breaches dataset in pandas
    and use TF-IDF to extract important keywords from the descriptions of the breaches.
    Let''s get started:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的步骤中，你将使用pandas可视化HIPAA泄露数据集，并使用TF-IDF从泄露描述中提取重要关键词。让我们开始吧：
- en: 'Load and clean the HIPAA breaches dataset using `pandas`:'
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`pandas`加载并清洗HIPAA泄露数据集：
- en: '[PRE48]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'The output of the preceding code is shown in the following screenshot:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码的输出显示在以下截图中：
- en: '![](assets/133b7dea-b456-493c-8e1b-cbe49fc4d724.png)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/133b7dea-b456-493c-8e1b-cbe49fc4d724.png)'
- en: 'Plot a histogram of the number of individuals who have been affected by a breach
    against the frequency of such breaches by using the following code:'
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码绘制受泄露影响的个人数量与泄露事件频率的直方图：
- en: '[PRE49]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The following output shows the **Breach Size Distribution**:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 以下输出展示了**泄露大小分布**：
- en: '![](assets/ccf17feb-3001-4bcd-96df-3078bd46ed04.png)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/ccf17feb-3001-4bcd-96df-3078bd46ed04.png)'
- en: 'Plot the average breach size based on the entity type:'
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于实体类型绘制平均泄露大小：
- en: '[PRE50]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'The following screenshot shows the output of the **Average Breach Size by Entity
    Type**:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了**按实体类型划分的平均泄露大小**：
- en: '![](assets/f2334834-2312-4aa3-b473-605bed345fa0.png)'
  id: totrans-235
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/f2334834-2312-4aa3-b473-605bed345fa0.png)'
- en: 'Plot a pie chart that shows the number of individuals affected by breaches
    per state, filtered by the top 20 states:'
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制一个饼图，显示按州划分的每个州受泄露影响的个人数量，并筛选出前20个州：
- en: '[PRE51]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The following chart shows us those individuals who are affected by breaches
    per state:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表展示了每个州受泄露影响的个人数量：
- en: '![](assets/15bcd509-6467-4dee-bea0-d8c5661a70fa.png)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/15bcd509-6467-4dee-bea0-d8c5661a70fa.png)'
- en: 'Plot the average breach size against the type of breach (theft, loss, hacking,
    and so on):'
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制平均泄露大小与泄露类型（盗窃、丢失、黑客攻击等）之间的关系：
- en: '[PRE52]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'The following graph shows the **Type of Breach**:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表显示了**泄露类型**：
- en: '![](assets/9f179346-054d-4a70-b5c8-49e184c2daac.png)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/9f179346-054d-4a70-b5c8-49e184c2daac.png)'
- en: 'Instantiate a TF-IDF vectorizer:'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化TF-IDF向量化器：
- en: '[PRE53]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Fit the vectorizer to the breach descriptions and vectorize them:'
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将向量化器拟合到泄露描述，并进行向量化：
- en: '[PRE54]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Select the 15 most important features in the breach descriptions based on TF-IDF:'
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据TF-IDF选择泄露描述中最重要的15个特征：
- en: '[PRE55]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'The output is as follows:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE56]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Print out a couple of breach descriptions containing the `review` keyword:'
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印出包含`review`关键词的几个泄露描述：
- en: '[PRE57]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'The following are some of the snippets of the output:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是部分输出片段：
- en: '[PRE58]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: How it works…
  id: totrans-256
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: We begin by reading the HIPAA dataset into a dataframe and dropping any rows
    that contain NAs (*step 1*). Next, in *step 2*, we can see that most breaches
    are relatively small scale, but a small number of breaches are massive. This is
    consistent with Pareto's principle. In *step 3*, we plot breaches by sector to
    ensure that the largest breaches occur in Business Associates. Then, we examine
    which states have the most HIPAA breaches in *step 4*. In *step 5*, we learn that
    the cause of the largest breaches is usually unknown! In *steps 6* and *7*, we
    perform a basic NLP on the descriptions of the breaches. This will allow us to
    extract additional information of interest. In *step 8*, we can see that TF-IDF
    was able to find some very informative keywords, such as *ransomware* and *driver*.
    Finally, in *step 9*, we print out breach description containing the keyword *review*.
    The word, review turns out to be an extremely important word as it appears as
    part of quality control and as an incidence response tool.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先将HIPAA数据集读取到数据框中，并删除包含NAs的行（*步骤1*）。接下来，在*步骤2*中，我们可以看到大多数泄露规模相对较小，但少数泄露事件规模巨大。这与帕累托原则一致。在*步骤3*中，我们按行业绘制泄露事件，以确保最大规模的泄露发生在商业合作伙伴中。然后，在*步骤4*中，我们检查哪些州发生了最多的HIPAA泄露事件。在*步骤5*中，我们得知最大规模的泄露原因通常未知！在*步骤6*和*7*中，我们对泄露描述进行基本的自然语言处理（NLP）。这将帮助我们提取更多感兴趣的信息。在*步骤8*中，我们可以看到TF-IDF能够找到一些非常有信息量的关键词，比如*ransomware*（勒索软件）和*driver*（驱动程序）。最后，在*步骤9*中，我们打印出包含关键词*review*的泄露描述。结果表明，*review*（回顾）是一个极其重要的词，它在质量控制和事件响应工具中经常出现。
