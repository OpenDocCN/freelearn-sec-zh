- en: '13'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '13'
- en: Pentest Reporting with Bash
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Bash进行渗透测试报告
- en: In this chapter, we explore the role Bash can play in streamlining the **reporting**
    phase of pentesting. As security professionals know, the final report is a critical
    deliverable that communicates findings, risks, and recommendations to stakeholders.
    However, compiling these reports can be time-consuming and prone to inconsistencies.
    We’ll examine how Bash scripting can automate and enhance various aspects of the
    reporting process, from data collection to report generation.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨Bash如何在简化渗透测试报告阶段中发挥作用。正如安全专家所知，最终报告是一个关键的交付物，它向利益相关者传达发现、风险和建议。然而，编写这些报告可能非常耗时，并且容易出现不一致的情况。我们将讨论Bash脚本如何自动化并增强报告过程中的各个方面，从数据收集到报告生成。
- en: Throughout the chapter, we’ll cover techniques for automating data extraction
    from tool outputs, generating preliminary reports, and integrating Bash with other
    reporting tools. You’ll learn how to create scripts that can parse raw data and
    populate report templates.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论从工具输出中自动提取数据、生成初步报告以及将Bash与其他报告工具集成的技术。你将学习如何创建可以解析原始数据并填充报告模板的脚本。
- en: By the end of this chapter, you’ll have a solid foundation in using Bash to
    create efficient, accurate, and professional pentest reports. These skills will
    not only save time but also enhance the quality and consistency of your deliverables,
    allowing you to focus more on analysis and less on manual report compilation.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章结束时，你将掌握使用Bash创建高效、准确和专业的渗透测试报告的基础。这些技能不仅能节省时间，还能提高交付物的质量和一致性，让你能更多地专注于分析，而不是手动编写报告。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要内容：
- en: Automating data collection for reporting with Bash
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Bash自动化数据收集进行报告
- en: Storing and managing pentest data with SQLite
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用SQLite存储和管理渗透测试数据
- en: Integrating Bash with reporting tools
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将Bash与报告工具集成
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: The code for this chapter can be found at [https://github.com/PacktPublishing/Bash-Shell-Scripting-for-Pentesters/tree/main/Chapter13](https://github.com/PacktPublishing/Bash-Shell-Scripting-for-Pentesters/tree/main/Chapter13)
    .
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码可以在[https://github.com/PacktPublishing/Bash-Shell-Scripting-for-Pentesters/tree/main/Chapter13](https://github.com/PacktPublishing/Bash-Shell-Scripting-for-Pentesters/tree/main/Chapter13)找到。
- en: 'Enter the following commands to install prerequisites on your Kali Linux system:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的Kali Linux系统上输入以下命令来安装先决条件：
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The following commands assume that you have Go installed. See [https://go.dev/doc/install](https://go.dev/doc/install)
    :'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令假设你已安装Go。请参见[https://go.dev/doc/install](https://go.dev/doc/install)：
- en: '[PRE1]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: With the prerequisites out of the way, it’s time to dive into reporting, every
    pentester’s favorite subject!
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成先决条件后，正式进入报告环节，这是每个渗透测试人员最喜欢的话题！
- en: Automating data collection for reporting with Bash
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Bash自动化数据收集进行报告
- en: Efficient data collection is a pillar of effective pentesting reporting. This
    section explores how to leverage Bash scripting to automate the gathering and
    organization of critical information from various phases of a pentest.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 高效的数据收集是有效渗透测试报告的支柱。本节将探讨如何利用Bash脚本自动化从渗透测试的各个阶段收集和组织关键信息。
- en: 'By automating data collection, pentesters can do the following:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 通过自动化数据收集，渗透测试人员可以做到以下几点：
- en: Reduce manual errors in data gathering
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 减少数据收集中的人工错误
- en: Standardize the format of collected information
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标准化收集信息的格式
- en: Save time on repetitive data extraction tasks
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 节省重复数据提取任务的时间
- en: Ensure consistency across multiple tests and reports
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保多个测试和报告的一致性
- en: We’ll examine techniques for identifying key data points, extracting information
    from tool outputs, cleaning raw data, storing data in a database, and templating
    reports. These methods will help streamline the reporting process and allow testers
    to focus more on analysis and less on data management.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将研究识别关键数据点、从工具输出中提取信息、清理原始数据、将数据存储在数据库中以及报告模板化的技术。这些方法将帮助简化报告过程，让测试人员能更多地专注于分析，而不是数据管理。
- en: Let’s begin by looking at how to identify and extract the most relevant data
    for pentest reports using Bash.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从使用Bash识别和提取渗透测试报告中最相关的数据开始。
- en: Identifying key data points
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 识别关键数据点
- en: '**Key data points** are essential pieces of information that provide a comprehensive
    overview of the test findings, vulnerabilities, and overall security posture of
    the target system or network. These data points form the backbone of an effective
    pentest report.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**关键数据点**是提供测试发现、漏洞以及目标系统或网络整体安全态势的全面概述的必要信息。这些数据点构成了有效渗透测试报告的核心。'
- en: 'Key data points typically include the following:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 关键数据点通常包括以下内容：
- en: '**Executive** **summary data** :'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高层摘要数据**：'
- en: Total number of vulnerabilities by severity
  id: totrans-29
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 按严重性分类的漏洞总数
- en: Key findings and critical issues
  id: totrans-30
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关键发现和关键问题
- en: Overall risk rating
  id: totrans-31
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 总体风险评级
- en: '**Compliance information** :'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**合规信息**：'
- en: Relevant compliance standards (e.g., PCI DSS and HIPAA)
  id: totrans-33
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相关的合规性标准（例如，PCI DSS和HIPAA）
- en: Specific compliance violations or gaps
  id: totrans-34
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特定的合规性违规或差距
- en: '**Test metadata** :'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测试元数据**：'
- en: Date and duration of the test
  id: totrans-36
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试的日期和持续时间
- en: Scope of the assessment
  id: totrans-37
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估范围
- en: Tester information
  id: totrans-38
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试者信息
- en: Tools used during the assessment
  id: totrans-39
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估过程中使用的工具
- en: '**Successful attacks** **or exploits** :'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**成功的攻击** **或利用**：'
- en: Description of successful penetration attempts
  id: totrans-41
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 成功渗透尝试的描述
- en: Data accessed or exfiltrated
  id: totrans-42
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 访问或外泄的数据
- en: Potential real-world consequences
  id: totrans-43
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 潜在的现实世界后果
- en: '**Vulnerability information** :'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**漏洞信息**：'
- en: Vulnerability name and description
  id: totrans-45
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 漏洞名称和描述
- en: Severity rating (e.g., Critical, High, Medium, or Low)
  id: totrans-46
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 严重性评级（例如，关键、高、中或低）
- en: '**Common Vulnerability Scoring System** ( **CVSS** ) score'
  id: totrans-47
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**常见漏洞评分系统**（**CVSS**）评分'
- en: Affected systems or components
  id: totrans-48
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 受影响的系统或组件
- en: '**Technical details** :'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**技术细节**：'
- en: IP addresses and hostnames of affected systems
  id: totrans-50
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 受影响系统的IP地址和主机名
- en: Port numbers and services running
  id: totrans-51
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 端口号和运行的服务
- en: Software versions and patch levels
  id: totrans-52
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 软件版本和补丁级别
- en: Exploit methods or proof of concept
  id: totrans-53
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 漏洞利用方法或概念验证
- en: '**Risk assessment** :'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**风险评估**：'
- en: Potential impact of each vulnerability
  id: totrans-55
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个漏洞的潜在影响
- en: Likelihood of exploitation
  id: totrans-56
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 漏洞被利用的可能性
- en: Business impact analysis
  id: totrans-57
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 业务影响分析
- en: '**Testing artifacts** :'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测试文档**：'
- en: Screenshots of vulnerabilities or exploits
  id: totrans-59
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 漏洞或利用的截图
- en: Log file excerpts
  id: totrans-60
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日志文件摘录
- en: Command outputs from tools
  id: totrans-61
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 工具的命令输出
- en: '**Remediation information** :'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**修复信息**：'
- en: Recommended fixes or mitigations
  id: totrans-63
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推荐的修复或缓解措施
- en: Priority of remediation
  id: totrans-64
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修复的优先级
- en: Estimated effort for remediation
  id: totrans-65
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修复所需的估计努力
- en: Parsing and cleaning raw data using Bash
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Bash解析和清理原始数据
- en: Pentest tool’s primary report output formats include plain text files ( **.txt**
    ), **Comma-Separated Values** ( **CSV** ), **Extensible Markup Language** ( **XML**
    ), and **JavaScript Object Notation** ( **JSON** ). Since plain text output isn’t
    organized into any specific format, it won’t be covered in this section and what
    you previously learned about regular expressions in [*Chapter 4*](B22229_04.xhtml#_idTextAnchor073)
    will suffice. The rest of this section will include strategies for parsing the
    other data formats.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 渗透测试工具的主要报告输出格式包括纯文本文件（**.txt**）、**逗号分隔值**（**CSV**）、**可扩展标记语言**（**XML**）和**JavaScript对象表示法**（**JSON**）。由于纯文本输出没有特定的格式，因此本节不会涵盖，您之前在[*第4章*](B22229_04.xhtml#_idTextAnchor073)中学习的正则表达式足以应对。本节将包括解析其他数据格式的策略。
- en: 'Let’s begin with CSV data. The best tool in the Bash toolbox for parsing tabular
    data is undoubtedly **awk** . The basic syntax for **awk** is a s follows:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从CSV数据开始。Bash工具箱中解析表格数据的最佳工具无疑是**awk**。**awk**的基本语法如下：
- en: '[PRE2]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Here, please note the following:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意以下几点：
- en: '**pattern** is an optional condition to match.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**pattern** 是一个可选的匹配条件。'
- en: '**action** is what to do when the pattern matches.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**action** 是当模式匹配时要执行的操作。'
- en: '**input_file** is the file to process.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**input_file** 是要处理的文件。'
- en: Of course, you can remove the **input_file** variable if you are piping ( **|**
    ) data because awk can accept input from **stdin** or input files.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，如果你正在通过管道（**|**）传输数据，你可以移除**input_file**变量，因为awk可以从**stdin**或输入文件接受数据。
- en: 'Let’s say we have a CSV file with the following content named **scan_results.csv**
    . You can find this file in this chapter’s GitHub repository:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个名为**scan_results.csv**的CSV文件。你可以在本章的GitHub仓库中找到这个文件：
- en: '[PRE3]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Here’s how to extract only the IP and P ort columns:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这是提取IP和端口列的方法：
- en: '[PRE4]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This is the output:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这是输出：
- en: '[PRE5]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The explanation is as follows:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 解释如下：
- en: '**-F'',''** sets the field separator to a comma.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**-F'',''** 将字段分隔符设置为逗号。'
- en: '**$1** and **$3** refer to the first and third fields, respectively.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**$1**和**$3**分别指代第一和第三个字段。'
- en: '**","** prints a comma between the **$1** and **$** **3** fields.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**","** 在 **$1** 和 **$3** 字段之间打印一个逗号。'
- en: 'Here’s how to show only entries with open web ports ( **80** or **443** ):'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这是如何仅显示具有开放 Web 端口（ **80** 或 **443** ）的条目：
- en: '[PRE6]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The output is as follows:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE7]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'To add a header and a footer to our output, do th e following:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 要为我们的输出添加头部和尾部，请执行以下操作：
- en: '[PRE8]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'This is the resultant output:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这是最终的输出：
- en: '[PRE9]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Since we’re adding something new here, let’s review an explanation:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们这里添加了一些新内容，让我们回顾一下这个解释：
- en: The awk pattern is **awk 'pattern {** **action}' input_file** .
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AWK 模式是 **awk 'pattern {** **action}' input_file** 。
- en: The pattern is **$3 == 80 || $3 ==** **443** .
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模式是 **$3 == 80 || $3 ==** **443** 。
- en: The action is **{print $1 "," $2 "," $** **3}** .
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 操作是 **{print $1 "," $2 "," $3}** 。
- en: The **BEGIN** code prints **Open Web Servers:** and goes before the pattern.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**BEGIN** 代码打印 **开放的 Web 服务器：** 并在模式之前执行。'
- en: The **END** code prints **End of list** and goes after the action.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**END** 代码打印 **列表结束** 并在操作之后执行。'
- en: 'Let’s examine an example showing how to calculate statistics. Let’s say we
    have a **vulnerability_scan.csv** file with se verity levels:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个例子来看如何计算统计数据。假设我们有一个带有严重性级别的 **vulnerability_scan.csv** 文件：
- en: '[PRE10]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Here’s how to count vulnerabilities by severity:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 这是如何按严重性统计漏洞的：
- en: '[PRE11]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'This is the output:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这是输出结果：
- en: '[PRE12]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Here’s the explanation:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这是解释：
- en: '**-F'',''** : This option sets the field separator to a comma. The option tells
    awk to split each line into fields using commas as delimiters.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**-F'',''** ：这个选项将字段分隔符设置为逗号。该选项告诉 awk 使用逗号作为分隔符来拆分每一行。'
- en: '**''...''** : The single quotes contain the awk program itself.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**''...''** ：单引号中包含了 awk 程序本身。'
- en: '**NR>1** : This condition checks whether the current record (line) number is
    greater than 1. It effectively skips the first line (header) of the CSV file.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**NR>1** ：这个条件检查当前记录（行）的编号是否大于 1。它有效地跳过了 CSV 文件的第一行（表头）。'
- en: '**{...}** : This block contains the main processing logic for each line that
    meets the **NR>1** condition.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**{...}** ：这个块包含了针对每一行满足 **NR>1** 条件的主要处理逻辑。'
- en: '**gsub(/\r/,"")** : This function globally substitutes ( **gsub** ) any carriage
    return characters ( **\r** ) with an empty string, effectively removing them from
    the line. This helps handle potential Windows-style line endings.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**gsub(/\r/,"")** ：这个函数全局替换（**gsub**）所有的回车符（**\r**）为空字符串，有效地将其从行中移除。这有助于处理可能的
    Windows 风格行结束符。'
- en: '**if($3!="")** : This condition checks whether the third field (severity level)
    is empty or not.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**if($3!="")** ：这个条件检查第三个字段（严重性级别）是否为空。'
- en: '**count[$3]++** : If the condition is **true** , this increments the count
    for the severity level found in the third field. It uses an associative array
    named **count** with the severity level as the key.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**count[$3]++** ：如果条件为 **true** ，则会增加第三个字段中找到的严重性级别的计数。它使用一个名为 **count** 的关联数组，严重性级别作为键。'
- en: '**END {...}** : This block specifies actions to be performed after processing
    all lines.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**END {...}** ：这个块指定在处理完所有行后要执行的操作。'
- en: '**for (severity in count)** : This loop iterates over all unique severity levels
    stored as keys in the **count** array.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**for (severity in count)** ：这个循环遍历 **count** 数组中存储的所有唯一严重性级别作为键。'
- en: '**print severity ": " count[severity]** : For each severity level, this prints
    the severity followed by a colon and space, then the count of occurrences.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**print severity ": " count[severity]** ：对于每个严重性级别，它会打印严重性后跟一个冒号和空格，然后是出现次数。'
- en: '**vulnerability_scan.csv** : This is the input file that the AWK command processes.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**vulnerability_scan.csv** ：这是 AWK 命令处理的输入文件。'
- en: In summary, this AWK command reads a CSV file, skips the header, removes carriage
    returns, counts the occurrences of each non-empty severity level, and then prints
    out a summary of these counts. It’s designed to handle potential issues such as
    Windows line endings and empty fields, making it more robust for processing real-world
    CSV data.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，这条 AWK 命令读取 CSV 文件，跳过头部，移除回车符，计算每个非空严重性级别的出现次数，然后打印出这些计数的汇总。它设计时考虑了 Windows
    行结束符和空字段等潜在问题，使其在处理实际的 CSV 数据时更加稳健。
- en: 'In another example, we may need to combine multiple files. Here we have another
    fil e, **asset_info.csv** :'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在另一个例子中，我们可能需要合并多个文件。这里有另一个文件，**asset_info.csv** ：
- en: '[PRE13]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We can combine this with our v ul nerability data:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将其与我们的漏洞数据结合使用：
- en: '[PRE14]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This is the resultant output:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 这是最终的输出：
- en: '[PRE15]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'This script first reads **asset_info.csv** into memory, then processes **vulnerability_scan.csv**
    , adding the owner and department information to each line. Let’s look at the
    explanation:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 该脚本首先将**asset_info.csv**读取到内存中，然后处理**vulnerability_scan.csv**，为每一行添加所有者和部门信息。让我们来看一下这个解释：
- en: '**-F'',''** : This option sets the field separator to a comma, which is appropriate
    for CSV files.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**-F'',''** : 此选项将字段分隔符设置为逗号，适用于CSV文件。'
- en: '**NR==FNR** : This condition is true only when processing the first file (
    **asset_info.csv** ). **NR** is the current record number across all files, while
    **FNR** is the record number in the current file.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**NR==FNR** : 此条件仅在处理第一个文件（**asset_info.csv**）时为真。**NR**是所有文件中的当前记录号，而**FNR**是当前文件中的记录号。'
- en: '**{owner[$1]=$2; dept[$1]=$3; next}** : This block executes for **asset_info.csv**
    :'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**{owner[$1]=$2; dept[$1]=$3; next}** : 该块在处理**asset_info.csv**时执行：'
- en: '**owner[$1]=$2** : Creates an associative array, **owner** , where the key
    is the first field (an asset ID) and the value is the second field ( owner name)'
  id: totrans-128
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**owner[$1]=$2** : 创建一个关联数组**owner**，其中键是第一个字段（资产ID），值是第二个字段（所有者名称）。'
- en: '**dept[$1]=$3** : Creates an associative array, **dept** , where the key is
    the first field and the value is the third field ( department name)'
  id: totrans-129
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**dept[$1]=$3** : 创建一个关联数组**dept**，其中键是第一个字段，值是第三个字段（部门名称）。'
- en: '**next** : Skips to the next record without executing th e rest of the script'
  id: totrans-130
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**next** : 跳过当前记录并继续执行脚本的下一条记录。'
- en: '**{print $1 "," $2 "," $3 "," owner[$1] "," dept[$1]}** : This block executes
    for **vulnerability_scan.csv** :'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**{print $1 "," $2 "," $3 "," owner[$1] "," dept[$1]}** : 该块在处理**vulnerability_scan.csv**时执行：'
- en: Prints the first three fields from the current line of **vulnerability_scan.csv**
  id: totrans-132
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 打印当前行的前三个字段，来自**vulnerability_scan.csv**。
- en: Adds the owner and department information by looking up the first field (asset
    ID) in the **owner** and **dept** arrays
  id: totrans-133
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过查找第一个字段（资产ID）在**owner**和**dept**数组中的信息，添加所有者和部门信息。
- en: '**asset_info.csv vulnerability_scan.csv** : These are the input files. **asset_info.csv**
    is processed first, then **vulnerability_scan.csv** .'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**asset_info.csv vulnerability_scan.csv** : 这些是输入文件。首先处理**asset_info.csv**，然后处理**vulnerability_scan.csv**。'
- en: These examples demonstrate how **awk** can be used to process and analyze CSV
    data from pentesting activities. By combining these techniques, you can create
    powerful scripts to automate data parsing and report generation for your pentest
    findings.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 这些示例展示了如何使用**awk**来处理和分析来自渗透测试活动的CSV数据。通过结合这些技巧，您可以创建强大的脚本来自动化数据解析和渗透测试结果的报告生成。
- en: Bash provides several tools that can be used to parse XML data. We’ll focus
    on using **xmllint** and **xpath** , which are commonly available on Linux systems.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: Bash提供了几种可以用来解析XML数据的工具。我们将重点使用**xmllint**和**xpath**，这两个工具在Linux系统中通常是可用的。
- en: 'First, let’s take a look at the structure of our Nmap XML report. The Nmap
    XML file can be found in this chapter’s GitHub repository as **nmap.xml** . The
    following is the abbreviated content of this file, showing the XML nodes:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们来看一下我们的Nmap XML报告的结构。Nmap XML文件可以在本章的GitHub仓库中找到，文件名为**nmap.xml**。以下是该文件的简化内容，展示了XML节点：
- en: '[PRE16]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Let’s extract all the IP addresses from the scan using the following command:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用以下命令提取扫描结果中的所有IP地址：
- en: '[PRE17]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: I strongly recommend you have the **nmap.xml** file open in GitHub and compare
    it to the following explanation as we step through it.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我强烈建议您在GitHub中打开**nmap.xml**文件，并在我们逐步讲解时，将其与以下解释进行对比。
- en: This command uses XPath to select all **addr** attributes of **address** elements
    that are children of **host** elements and have an **addrtype** of **ipv4** .
    With this information in mind, go back and read the XML data again to see this
    XML structure.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 该命令使用XPath选择所有**host**元素的子元素中，**addrtype**为**ipv4**的**address**元素的**addr**属性。了解了这些信息后，请回过头来再读一下XML数据，以查看这个XML结构。
- en: 'Here’s the explanation:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 这是解释：
- en: '**//host** : This selects all host elements anywhere in the document.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**//host** : 选择文档中的所有**host**元素。'
- en: '**/address** : This selects address elements that are direct children of the
    host elements.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**/address** : 选择作为宿主元素直接子元素的地址元素。'
- en: '**[@addrtype=''ipv4'']** : This is a predicate that filters for address elements
    where the **addrtype** attribute equals **ipv4** .'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**[@addrtype=''ipv4'']** : 这是一个谓词，用于过滤出**addrtype**属性等于**ipv4**的地址元素。'
- en: '**/@addr** : This selects the **addr** attribute of the matching address elements.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**/@addr** : 选择匹配的地址元素的**addr**属性。'
- en: 'The output can be seen in the following figure:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 输出可以在以下图中看到：
- en: '![Figure 13.1 – The output of the Nmap XML filter](image/B22229_13_01.jpg)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.1 – Nmap XML 筛选器的输出](image/B22229_13_01.jpg)'
- en: Figure 13.1 – The output of the Nmap XML filter
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.1 – Nmap XML 筛选器的输出
- en: Let’s create a more complex filter using two criteria from the Nmap XML data.
    We’ll find all hosts that have port **80** open and are running Microsoft IIS.
    This combines filtering on port status and service information.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用来自 Nmap XML 数据的两个标准，创建一个更复杂的筛选器。我们将找到所有端口 **80** 开放且运行 Microsoft IIS 的主机。这将端口状态和服务信息进行筛选结合。
- en: 'H ere’s how we can do this:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是我们如何操作的：
- en: '[PRE18]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Here, you can see the output of the preceding command:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，您可以看到前面命令的输出：
- en: '![Figure 13.2 – The output of the command](image/B22229_13_02.jpg)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.2 – 命令的输出](image/B22229_13_02.jpg)'
- en: Figure 13.2 – The output of the command
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.2 – 命令的输出
- en: As you can see, this is as simple as combining multiple XML queries separated
    by **and** . If you want to include ports **80** or **443** , separate them with
    an **or** keyword.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，这与将多个 XML 查询通过 **and** 连接起来一样简单。如果您想包含端口 **80** 或 **443**，则使用 **or** 关键字将它们分开。
- en: 'Next, let’s examine how to parse JSON data. In these examples, I’m using the
    **mapcidr** and **httpx** tools from ProjectDiscovery. My lab network has the
    network address **10.2.10.0/24** . I run the following command to fingerprint
    HTTP/S se rvers on my lab network:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们检查如何解析 JSON 数据。在这些示例中，我使用的是 ProjectDiscovery 的 **mapcidr** 和 **httpx**
    工具。我的实验室网络的网络地址是 **10.2.10.0/24**。我运行以下命令来识别实验室网络上的 HTTP/S 服务器：
- en: '[PRE19]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The **httpx.json** file can be found in this chapter’s directory in the GitHub
    repository.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '**httpx.json** 文件可以在本章的 GitHub 仓库目录中找到。'
- en: 'Let’s look at the explanation:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下说明：
- en: '**echo 10.2.10.0/24 |** : This simply sends the **10.2.10.0/24** string into
    the pipeline ( **|** ) and suppresses the program’s banner ( **-silent** ).'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**echo 10.2.10.0/24 |**：这仅将 **10.2.10.0/24** 字符串传入管道（**|**），并抑制程序的横幅（**-silent**）。'
- en: '**mapcidr -silent |** : This takes the input, expands it into individual IP
    addresses, and passes them into the pipeline.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**mapcidr -silent |**：这会将输入扩展为单独的 IP 地址，并将它们传入管道。'
- en: '**httpx -silent -j** : This takes the IP addresses passed in as **stdin** input,
    fingerprints any webservers listening on default ports, and prints the output
    in JSON format.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**httpx -silent -j**：这会将传入的 IP 地址作为 **stdin** 输入，指纹识别所有在默认端口上监听的 Web 服务器，并以
    JSON 格式输出结果。'
- en: 'The following shows the abbreviated output of this command:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是此命令的简略输出：
- en: '[PRE20]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The first thing you should do when examining JSON data structures is view the
    hierarchy by passing the data to **jq .** . The following example command uses
    JSON to output all data in the file in a format that’s easier to read to determine
    how the data is structured:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在检查 JSON 数据结构时，您应该做的第一件事是通过将数据传递给 **jq .** 来查看层次结构。以下示例命令使用 JSON 输出文件中的所有数据，并以更易读的格式展示，以确定数据的结构：
- en: '[PRE21]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The abbreviated output of this command can be seen in the following figure:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令的简略输出可以在下图中看到：
- en: '![Figure 13.3 – The JSON data structure from httpx](image/B22229_13_03.jpg)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.3 – 来自 httpx 的 JSON 数据结构](image/B22229_13_03.jpg)'
- en: Figure 13.3 – The JSON data structure from httpx
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.3 – 来自 httpx 的 JSON 数据结构
- en: 'The following script parses this JSON data and outputs each field, one per
    line. Let’s examine each line of the script to learn how to parse the JSON fields.
    This script can be found in this chapter’s GitHub repository as **ch13_parse_httpx.sh**
    :'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 以下脚本解析此 JSON 数据并逐行输出每个字段。让我们检查脚本中的每一行，学习如何解析 JSON 字段。此脚本可以在本章的 GitHub 仓库中找到，名为
    **ch13_parse_httpx.sh**：
- en: '[PRE22]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The output is shown in the following figure:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下图所示：
- en: '![Figure 13.4 – The output of script ch13_parse_httpx.sh](image/B22229_13_04.jpg)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.4 – 脚本 ch13_parse_httpx.sh 的输出](image/B22229_13_04.jpg)'
- en: Figure 13.4 – The output of script ch13_parse_httpx.sh
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.4 – 脚本 ch13_parse_httpx.sh 的输出
- en: 'Now, let’s discuss how to adapt this lesson to any JSON output:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们讨论如何将本课的内容适应任何 JSON 输出：
- en: '**Identify the structure** : First, examine your JSON output to understand
    its structure. Look for the key fields you want to extract.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**识别结构**：首先，检查您的 JSON 输出，以了解其结构。查找您要提取的关键字段。'
- en: '**Modify the** **parse_json** **function** : Update the function to extract
    the fields specific to your JSON structure. For example, if your JSON has a field
    called **user_name** , you add the following:'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**修改** **parse_json** **函数**：更新该函数以提取与您的 JSON 结构相关的字段。例如，如果您的 JSON 中有一个名为 **user_name**
    的字段，您可以添加以下内容：'
- en: '[PRE23]'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Modify the **echo** statements to print the fields you’ve extracted. If your
    JSON contains nested objects or arrays, you can use more complex **jq** queries.
    Here’s an example:'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修改**echo**语句，以打印你提取的字段。如果你的JSON包含嵌套的对象或数组，你可以使用更复杂的**jq**查询。以下是一个示例：
- en: '[PRE24]'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Before examining the preceding code, take a look at *Figure 13* *.3* and find
    the **tech** node. Using **.tech[0]** , we selected and returned the first result
    in the array. If you wanted to return all array results, you would instead use
    **.tech[]** , which is the whole array.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 在查看前面的代码之前，先查看*图13.3*并找到**tech**节点。使用**.tech[0]**，我们选择并返回了数组中的第一个结果。如果你想返回所有数组结果，可以使用**.tech[]**，这会返回整个数组。
- en: 'The following are quick tips to help you pa rse nested JSON data with **jq**
    :'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些快速提示，帮助你使用**jq**解析嵌套的JSON数据：
- en: 'For nested objects, use dot notation: **.parent.child** .'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于嵌套对象，使用点符号：**.parent.child**。
- en: 'For arrays, use brackets: **.array[]** .'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于数组，使用括号：**.array[]**。
- en: 'Combine these for deeply nested structures: **.parent.array[].child** .'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将这些组合用于深度嵌套结构：**.parent.array[].child**。
- en: 'Let’s expand on how to select nested data with examples. Review the following
    JSON data before moving on:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过示例扩展如何选择嵌套数据。在继续之前，请先查看以下JSON数据：
- en: '[PRE25]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Next, let’s examine some example **jq** queries for this nested structure:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们查看一些针对这个嵌套结构的示例**jq**查询：
- en: 'Get the parent name: **jq ''.parent.name''**'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取父节点名称：**jq '.parent.name'**
- en: 'Output: **"** **Family Tree"**'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出：**"** **Family Tree"**
- en: 'Get direct child’s name: **jq ''.parent.child.name''**'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取直接子节点的名称：**jq '.parent.child.name'**
- en: 'Output: **"John"**'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出：**"John"**
- en: 'Get all sibling names (array traversal): **jq ''.parent.siblings[].child.name''**'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取所有兄弟节点名称（数组遍历）：**jq '.parent.siblings[].child.name'**
- en: 'Output: **"** **Emma" "Michael"**'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出：**"** **Emma" "Michael"**
- en: 'Get all ages from both direct child and siblings: **jq ''.** **parent.child.age,
    .parent.siblings[].child.age''**'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取所有直接子节点和兄弟节点的年龄：**jq '.parent.child.age, .parent.siblings[].child.age'**
- en: 'Output: **10** **8 12**'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出：**10** **8 12**
- en: Armed with the knowledge needed to parse common pentest tool report formats,
    you’re prepared for the next step. In the next section, you’ll learn how to store
    data parsed from pentest tool reports into SQLite databases.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 掌握了解析常见渗透测试工具报告格式所需的知识后，你已经为下一步做好准备。在接下来的章节中，你将学习如何将从渗透测试工具报告中解析的数据存储到SQLite数据库中。
- en: Storing and managing pentest data with SQLite
  id: totrans-200
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用SQLite存储和管理渗透测试数据
- en: SQLite is a lightweight, serverless database engine that provides an efficient
    way to store and manage data collected during pentesting. This section explores
    how to leverage SQLite in conjunction with Bash scripting to create a system for
    organizing and querying pentest findings.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: SQLite是一个轻量级、无服务器的数据库引擎，提供了一种高效的方式来存储和管理在渗透测试过程中收集的数据。本节将探讨如何将SQLite与Bash脚本结合使用，创建一个用于组织和查询渗透测试结果的系统。
- en: 'SQLite offers several advantages for pentesters:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: SQLite为渗透测试人员提供了几个优势：
- en: '**Portability** : SQLite databases are self-contained files, making them easy
    to transfer and back up.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**便携性**：SQLite数据库是自包含的文件，便于转移和备份。'
- en: '**No setup required** : Unlike full-fledged database servers, SQLite doesn’t
    need installation or configuration.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无需设置**：与完整的数据库服务器不同，SQLite无需安装或配置。'
- en: '**Efficient querying** : SQLite supports SQL, allowing for complex data retrieval
    and analysis.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高效查询**：SQLite支持SQL，允许进行复杂的数据检索和分析。'
- en: '**Language integration** : Many programming languages, including Bash through
    command-line tools, can interact with SQLite databases.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语言集成**：许多编程语言，包括通过命令行工具的Bash，都可以与SQLite数据库进行交互。'
- en: 'In this section, we’ll cover the following topics:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将涵盖以下主题：
- en: How to create SQLite databases using Bash commands?
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何使用Bash命令创建SQLite数据库？
- en: How to write scripts that parse tool output and insert data into SQLite tables?
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何编写解析工具输出并将数据插入SQLite表格的脚本？
- en: How to run queries on SQLite databases to generate report content?
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何在SQLite数据库上运行查询以生成报告内容？
- en: By combining Bash scripting with SQLite, pentesters can create a flexible and
    powerful system for managing test data and streamlining the reporting process.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将Bash脚本与SQLite结合使用，渗透测试人员可以创建一个灵活而强大的系统来管理测试数据，并简化报告流程。
- en: 'First, let’s create an **SQLite3** database to store our Nmap scan results.
    The following script can be found in this chapter’s GitH ub repository as **ch13_create
    _db.sh** :'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们创建一个**SQLite3**数据库来存储我们的Nmap扫描结果。以下脚本可以在本章节的GitHub仓库中找到，文件名为**ch13_create_db.sh**：
- en: '[PRE26]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Here’s the explanation:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 这是解释：
- en: First, it defines the database name as **pentest_results.db** .
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，定义数据库名称为**pentest_results.db**。
- en: Then, it uses a heredoc ( **<<EOF** ) to pass SQL commands to **SQLite3** .
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，它使用heredoc（**<<EOF**）将SQL命令传递给**SQLite3**。
- en: Next, it creates a table named **nmap_scans** if it doesn’t already exist.
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，它会创建一个名为**nmap_scans**的表（如果表尚不存在的话）。
- en: Lastly, it defines columns for IP address, hostname, port, protocol, service,
    version, scan date, and vulnerability.
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，它定义了IP地址、主机名、端口、协议、服务、版本、扫描日期和漏洞的列。
- en: 'Next, let’s create a script that takes an Nmap scan as input and inserts the
    results into our database. The following script can be found in this chapter’s
    GitH ub repository as **ch13_nmap_to_db.sh** :'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们创建一个脚本，接受Nmap扫描作为输入，并将结果插入到我们的数据库中。以下脚本可以在本章的GitHub代码库中找到，文件名为**ch13_nmap_to_db.sh**：
- en: '[PRE27]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Execute the script as follows:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 执行脚本如下：
- en: '[PRE28]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: When the script completes, it will print **Data import completed** to the terminal.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 当脚本执行完毕，它会在终端打印**数据导入完成**。
- en: 'Let’s look at the explanation:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下这个解释：
- en: The **DB_NAME** variable defines the database name.
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**DB_NAME** 变量定义了数据库的名称。'
- en: It uses **xmlstarlet** to parse the XML Nmap report, extracting relevant information.
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它使用**xmlstarlet**解析XML格式的Nmap报告，提取相关信息。
- en: It then formats the extracted data with **|** as a delimiter.
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它然后使用**|**作为分隔符格式化提取的数据。
- en: A **while** loop is used to read the formatted data line by line.
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用**while**循环按行读取格式化后的数据。
- en: For each line, it inserts the data into the **nmap_scans** table using **sqlite3**
    .
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每一行，它使用**sqlite3**将数据插入到**nmap_scans**表中。
- en: You may have noticed that our database has a field for **vulnerability** , but
    we didn’t insert any data in this field because we were only populating data from
    the Nmap scan.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经注意到，我们的数据库中有一个**vulnerability**字段，但我们并没有向这个字段插入任何数据，因为我们仅仅是在填充来自Nmap扫描的数据。
- en: 'To update an existing record in the **nmap_scans** table to add a vulnerability
    where it was previously NULL, you can use the SQL UPDATE statement. Here’s how
    you can do this using Bash and the Sqlite3 command-line tool:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 要在**nmap_scans**表中更新现有记录，添加之前为NULL的漏洞信息，你可以使用SQL的UPDATE语句。以下是使用Bash和Sqlite3命令行工具的实现方法：
- en: '[PRE29]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Replace the placeholders with your actual data:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 用你的实际数据替换占位符：
- en: '**VULNERABILITY_DESCRIPTION** : The description of the vulnerability you want
    to add.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**VULNERABILITY_DESCRIPTION** ：你想要添加的漏洞描述。'
- en: '**IP_ADDRESS** : The IP address of the target system.'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**IP_ADDRESS** ：目标系统的IP地址。'
- en: '**PORT_NUMBER** : The port number where the vulnerability was found.'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**PORT_NUMBER** ：发现漏洞的端口号。'
- en: 'For example, if you want to update the record for the **10.2.10.10** IP on
    port **80** to add an **SQL Injection vulnerability** de scription, you will use
    the following:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你想更新**10.2.10.10** IP地址的**80**端口记录，添加**SQL注入漏洞**描述，你可以使用以下命令：
- en: '[PRE30]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: This command will update the vulnerability field for the record that matches
    the specified IP address and port, but only if the vulnerability field is currently
    **NULL** . This ensures you don’t overwrite any existing vulnerability descriptions.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令会更新与指定IP地址和端口匹配的记录中的漏洞字段，但前提是该漏洞字段当前为**NULL**。这可以确保你不会覆盖已有的漏洞描述。
- en: 'If you want to update the vulnerability regardless of whether it’s **NULL**
    or not, you can remove th e **AND vulnerability IS** **NULL** condition:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想无论**NULL**与否都更新漏洞信息，可以去掉**AND vulnerability IS** **NULL**条件：
- en: '[PRE31]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Now that we have data in our database, let’s create a script to query and display
    the results. The following script can be found in this chapter’s GitHub repository
    as **ch13_read_db.sh** :'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了数据库中的数据，让我们创建一个脚本来查询并显示结果。以下脚本可以在本章的GitHub代码库中找到，文件名为**ch13_read_db.sh**：
- en: '[PRE32]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The following figure shows the output from this script:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图显示了该脚本的输出结果：
- en: '![Figure 13.5 – The database contents](image/B22229_13_05.jpg)'
  id: totrans-245
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.5 – 数据库内容](image/B22229_13_05.jpg)'
- en: Figure 13.5 – The database contents
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.5 – 数据库内容
- en: 'Here’s an explanation of the code:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 这是对代码的解释：
- en: '**DB_NAME="pentest_results.db"** sets a variable with the name of the database
    file.'
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**DB_NAME="pentest_results.db"** 设置一个变量，存储数据库文件的名称。'
- en: 'The **truncate()** function is defined. It takes two arguments: a string and
    a maximum length. It checks whether the string is longer than the maximum length.
    If it is, it cuts the string short and adds **...** at the end. If not, it pads
    the string with spaces to reach the maximum length. This function helps format
    the output to fit in fixed-width columns.'
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义了**truncate()**函数。它接受两个参数：一个字符串和一个最大长度。它检查字符串是否超过最大长度。如果超过，它会截断字符串并在末尾添加**...**。如果没有，它会使用空格填充字符串，直到达到最大长度。这个函数有助于将输出格式化为适应固定宽度的列。
- en: The script then prints a header row. **printf** is used to format the output.
    **%-15s** means left-align this string and pad it to 15 characters. The **|**
    characters are used to visually separate columns. A line of equal signs is printed
    to separate the header from the data. **printf '=%.0s' {1..109}** prints 109 equal
    signs.
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 脚本接着打印出标题行。使用**printf**格式化输出。**%-15s** 表示将字符串左对齐，并将其填充为15个字符。**|** 字符用于在视觉上分隔列。打印一行等号来将标题与数据分隔开。**printf
    '=%.0s' {1..109}** 打印出109个等号。
- en: The script then queries the database. **sqlite3** is the command to interact
    with the SQLite database. **-separator "|"** tells SQLite to use pipe characters
    ( **|)** to separate columns in its output. The SQL query selects all columns
    from the **nmap_scans** table, ordered by IP address and port.
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 脚本然后查询数据库。**sqlite3** 是与SQLite数据库进行交互的命令。**-separator "|"** 告诉SQLite在输出中使用管道字符(**|**)来分隔列。SQL查询从**nmap_scans**表中选择所有列，按IP地址和端口排序。
- en: The output of the query is piped into a while loop. **IFS='|** ’ sets the **Internal
    Field Separator** to **|** , which tells the script how to split the input into
    fields. **read -r** reads a line of input and splits it into variables. Inside
    the loop, each field ( **ip** , **hostname** , etc.) is processed by the **truncate**
    function. This ensures each field fits within its designated column width. The
    formatted data is then printed using **printf** . This creates neatly aligned
    columns in the output.
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查询的输出被传递到一个 `while` 循环中。**IFS='|'** 设置**内部字段分隔符**为**|**，它告诉脚本如何将输入分割成各个字段。**read
    -r** 读取一行输入并将其分割成变量。在循环内部，**ip**、**hostname**等每个字段都由**truncate**函数处理。这确保了每个字段都适合其指定的列宽。然后，使用**printf**打印格式化后的数据。这将在输出中创建整齐对齐的列。
- en: After the loop ends, **Query completed.** is printed to indicate the script
    has finished running.
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 循环结束后，**Query completed.** 被打印出来，表示脚本已完成运行。
- en: This script takes data from an SQLite database and presents it in a neatly formatted
    table, making it easy to read and analyze the results of network scans.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 该脚本从SQLite数据库中获取数据，并将其以整齐格式的表格呈现，使网络扫描结果更加易于阅读和分析。
- en: By using these scriptdatabase andtomate the process of running Nmap scans, storing
    the results in a SQLite3 database, and querying the data for analysis. This approach
    allows for efficient data management and retrieval during pentesting activities.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用这些脚本数据库并自动化运行Nmap扫描、将结果存储到SQLite3数据库中以及查询数据以供分析。该方法允许在渗透测试活动中高效地管理和检索数据。
- en: In the next section, you’ll learn how to extract data from the database and
    integrate it with reporting tools.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，您将学习如何从数据库中提取数据，并将其与报告工具集成。
- en: Integrating Bash with reporting tools
  id: totrans-257
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将Bash与报告工具集成
- en: Writing a pentest report is both the most important as well as the least liked
    part of any pentest. Customers or system owners never get to see the work you
    do. Their opinion of how well you performed a pentest depends on the quality of
    the report. Pentesters usually dislike reporting because it’s not nearly as fun
    as *popping shells* .
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 撰写渗透测试报告是任何渗透测试过程中最重要也是最不受欢迎的部分。客户或系统所有者永远看不到你所做的工作。他们对你进行渗透测试表现如何的评价，取决于报告的质量。渗透测试员通常不喜欢写报告，因为它远没有*爆破shell*那样有趣。
- en: Automating data normalization and report generation can significantly improve
    report quality while reducing time spent on reporting. This section provides Bash
    tools and techniques to streamline your reporting process. While not creating
    a comprehensive pentest report, it offers adaptable examples you can tailor to
    your standards and workflow.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化数据规范化和报告生成可以显著提高报告质量，同时减少报告所花费的时间。本节提供了Bash工具和技术，用于简化报告过程。虽然不创建完整的渗透测试报告，但它提供了可以根据您的标准和工作流程调整的可适应示例。
- en: This section will cover the basics of LaTeX, explain how to interact with the
    SQLite3 database using Bash, and demonstrate how to generate a PDF report.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将介绍LaTeX的基础知识，解释如何使用Bash与SQLite3数据库进行交互，并演示如何生成PDF报告。
- en: LaTeX is a high-quality typesetting system designed for the production of technical
    and scientific documentation. It is widely used in academia and professional settings
    for creating complex documents with consistent formatting, mathematical equations,
    and cross-references.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: LaTeX 是一个高质量的排版系统，旨在生成技术和科学文档。它在学术界和专业领域被广泛使用，用于创建格式一致、包含数学公式和交叉引用的复杂文档。
- en: 'For pentesters, LaTeX offers several advantages:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 对于渗透测试人员来说，LaTeX 提供了几个优势：
- en: Consistent formatting across large documents
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在大文档中保持一致的格式
- en: Easy integration of code snippets and command outputs
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代码片段和命令输出的轻松集成
- en: Ability to generate professional-looking reports programmatically
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 能够程序化生成专业外观的报告
- en: Support for complex tables and figures
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持复杂的表格和图形
- en: 'Let’s start by creating a Bash script to query our **SQLite3** database and
    format the results for use in our LaTeX document. The following script can be
    found in this chapter’s GitHub repository as **ch13_generate_report.sh** :'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先创建一个 Bash 脚本，用于查询我们的 **SQLite3** 数据库并格式化结果以便在 LaTeX 文档中使用。以下脚本可以在本章的 GitHub
    仓库中找到，文件名为 **ch13_generate_report.sh**：
- en: '[PRE33]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Let’s look at the explanation:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下解释：
- en: '**query_db()** : This creates a function to query the database.'
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**query_db()** : 这个函数用于查询数据库。'
- en: '**sqlite3 -header -csv $DB_NAME "$1"** : This function executes SQLite queries.
    It uses the **-header** option to include column names and **-csv** to output
    in CSV format.'
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**sqlite3 -header -csv $DB_NAME "$1"** : 这个函数执行 SQLite 查询。它使用 **-header** 选项以包括列名，使用
    **-csv** 选项以 CSV 格式输出。'
- en: '**escape_latex()** : This function escapes special LaTeX characters to prevent
    compilation errors.'
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**escape_latex()** : 这个函数转义特殊的 LaTeX 字符以防止编译错误。'
- en: '**ip_addresses=$(query_db "SELECT DISTINCT ip_address FROM nmap_scans WHERE
    vulnerability IS NOT NULL AND vulnerability != '''';" | tail -n +2)** : This query
    fetches all unique IP addresses with vulnerabilities, skipping the header row.'
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ip_addresses=$(query_db "SELECT DISTINCT ip_address FROM nmap_scans WHERE
    vulnerability IS NOT NULL AND vulnerability != '''';" | tail -n +2)** : 这个查询获取所有有漏洞的独特
    IP 地址，跳过表头行。'
- en: '**create_latex_content()** : This function generates the LaTeX document structure.'
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**create_latex_content()** : 这个函数生成 LaTeX 文档结构。'
- en: '**for ip in $ip_addresses; do** : This loop processes each IP address, creating
    a subsection for each.'
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**for ip in $ip_addresses; do** : 这个循环处理每个 IP 地址，为每个 IP 创建一个子章节。'
- en: '**query_db "SELECT hostname,…** : This nested loop processes each vulnerability
    for a given IP address, formatting it for the LaTeX table.'
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**query_db "SELECT hostname,…** : 这个嵌套循环处理给定 IP 地址的每个漏洞，并将其格式化为 LaTeX 表格。'
- en: 'These commands generate the LaTeX file and compile it into a PDF:'
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这些命令生成 LaTeX 文件并将其编译为 PDF：
- en: '**create_latex_content >** **pentest_report.tex**'
  id: totrans-278
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**create_latex_content >** **pentest_report.tex**'
- en: '**pdflatex -** **interaction=nonstopmode pentest_report.tex**'
  id: totrans-279
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**pdflatex -** **interaction=nonstopmode pentest_report.tex**'
- en: 'To generate your pente st report, simply run the Bash script:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 若要生成渗透测试报告，只需运行 Bash 脚本：
- en: '[PRE34]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: This will create a file named **pentest_report.pdf** in your current directory.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 这将会在当前目录下创建一个名为 **pentest_report.pdf** 的文件。
- en: 'The following figure shows our very simple pentest report:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图展示了我们非常简单的渗透测试报告：
- en: '![Figure 13.6 – Our simple pentest report PDF](image/B22229_13_06.jpg)'
  id: totrans-284
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.6 – 我们简单的渗透测试报告 PDF](image/B22229_13_06.jpg)'
- en: Figure 13.6 – Our simple pentest report PDF
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.6 – 我们简单的渗透测试报告 PDF
- en: You can further customize your report by adding more sections, such as an executive
    summary or recommendations, including graphics or charts to visualize data, using
    LaTeX packages for syntax highlighting of code snippets.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过添加更多章节来进一步自定义您的报告，例如执行摘要或建议，包含图形或图表以可视化数据，使用 LaTeX 包对代码片段进行语法高亮。
- en: 'For example, to add an executive summary, you could modify the **create_latex_content**
    function:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，若要添加执行摘要，您可以修改 **create_latex_content** 函数：
- en: '[PRE35]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: This section explored methods for using Bash scripts to streamline the creation
    of professional pentesting reports. It covered techniques for interfacing Bash
    with document preparation systems such as LaTeX to generate polished PDF reports.
    Adapt the provided methodology to your own standards to streamline your reporting
    process.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 本节探讨了使用 Bash 脚本来简化专业渗透测试报告创建的方法。内容包括将 Bash 与文档准备系统（如 LaTeX）结合使用，以生成精美的 PDF 报告。根据提供的方法调整以符合您的标准，从而简化报告过程。
- en: Summary
  id: totrans-290
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter focused on using Bash to streamline the reporting phase of pentesting.
    It covered techniques for automating data collection, organizing findings, and
    generating comprehensive reports. We explored how to extract relevant information
    from tool outputs, parse and clean data, and store it efficiently using SQLite
    databases. We also addressed integrating Bash scripts with reporting tools such
    as LaTeX to create professional PDF reports. By leveraging Bash for these tasks,
    pentesters can significantly reduce the time and effort required for report generation
    while ensuring accuracy and consistency in their findings.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 本章重点介绍了使用Bash简化渗透测试报告阶段的过程。内容涵盖了自动化数据收集、组织发现结果和生成全面报告的技术。我们探讨了如何从工具输出中提取相关信息，解析和清理数据，并使用SQLite数据库高效存储数据。我们还讨论了如何将Bash脚本与报告工具如LaTeX集成，以创建专业的PDF报告。通过将Bash应用于这些任务，渗透测试人员可以显著减少生成报告所需的时间和精力，同时确保报告内容的准确性和一致性。
- en: The next chapter will examine methods for creating Bash scripts that can evade
    detection by endpoint security during pentesting engagements.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章将探讨在渗透测试过程中创建能够避开终端安全检测的Bash脚本的方法。
