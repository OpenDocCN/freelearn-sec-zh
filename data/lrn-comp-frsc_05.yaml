- en: '5'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '5'
- en: Computer Investigation Process
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算机调查流程
- en: Being a digital forensic examiner requires you to have a plan to conduct the
    investigation. For instance, there is the kitchen sink approach – where the person
    requesting the examination states, *I want it all*. However, this is not practical
    when the smallest drive might contain hundreds of thousands of pages or events.
    So while the kitchen sink approach is a plan, it may not be the most efficient.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 成为数字取证检查员需要你有一个调查计划。例如，有一种所谓的“厨房水槽方法”——即请求检查的人说，*我要所有的信息*。然而，这种方法并不实际，因为最小的驱动器可能包含数十万页或事件。因此，尽管“厨房水槽方法”是一个计划，但它可能不是最有效的。
- en: In reality, your search method will depend on the crime you are investigating
    and whether there are limitations to the scope of the search. For example, in
    some investigations, the judicial authority may restrict an investigator’s access
    to digital evidence to only email messages, or you may be limited to a specific
    date and time within the forensic image.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，你的搜索方法将取决于你正在调查的犯罪类型，以及搜索范围是否有限制。例如，在某些调查中，司法机关可能会限制调查员访问数字证据，只能查看电子邮件信息，或者你可能仅限于在法医镜像中查找特定日期和时间。
- en: This chapter will first go through timeline analysis, where a user’s activity
    is analyzed *temporally*. Then, we will examine the storage containers used by
    the user. You will also learn about string search, in which you search a dataset
    using matching strings of characters. Finally, in the last section, we will analyze
    data that has been deleted from the filesystem.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将首先讲解时间轴分析，分析用户活动的*时间性*。接下来，我们将检查用户使用的存储容器。你还将了解字符串搜索，即通过匹配字符字符串在数据集中进行搜索。最后，在最后一节中，我们将分析从文件系统中删除的数据。
- en: 'In this chapter, we will learn about the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将介绍以下内容：
- en: Timeline analysis
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间轴分析
- en: Media analysis
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 媒体分析
- en: String search
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 字符串搜索
- en: Recovering deleted data
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 恢复删除的数据
- en: Timeline analysis
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时间轴分析
- en: During the investigation, you may find artifacts that appear to show the accused’s
    guilt or innocence. However, we cannot construe the mere presence of the artifact
    as a sign of the suspect’s guilt or innocence. Instead, the artifact needs to
    be placed within the user and system activity context.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在调查过程中，你可能会发现看似显示被告有罪或无罪的遗留物。然而，我们不能仅凭遗留物的存在就推断嫌疑人有罪或无罪。相反，这些遗留物需要放在用户和系统活动的背景下进行分析。
- en: For example, I was brought in as a consultant on a case; they accused the suspect
    of physically abusing their child. One piece of evidence that was considered against
    the suspect was the high number of Google searches about how to treat an injury.
    They attributed the searches to the accused, who was the father. The most challenging
    piece of evidence is to prove the user’s identity behind the keyboard when the
    contested actions occurred. Since the items were present in the internet history
    (we will go into much greater detail in *Chapter 9*, *Internet Artifacts*), I
    wanted to check the context of when the searches were made. The wife was the primary
    owner of the laptop, but the husband was also a frequent user of the laptop. So,
    how do you attribute the searches to a specific user, especially when you have
    multiple people using the same laptop with the same user account?
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我被聘为一个案件的顾问；他们指控嫌疑人身体虐待自己的孩子。作为反对嫌疑人的证据之一是关于如何处理伤害的 Google 搜索次数过多。他们将这些搜索归咎于被告，即父亲。最具挑战性的证据是，在争议行为发生时，如何证明键盘背后的用户身份。由于这些项目出现在互联网历史记录中（我们将在*第九章*，*互联网遗留物*中深入讨论），我想检查搜索发生的时间背景。妻子是这台笔记本电脑的主要拥有者，但丈夫也是这台笔记本的常用用户。那么，如何将这些搜索归因于特定用户，尤其是在有多个用户使用同一台笔记本并且使用相同账户的情况下？
- en: A person’s internet viewing habits can almost be as distinctive as a fingerprint.
    As I reviewed the one million-plus lines of internet history, I could differentiate
    the two different users on the laptop. I could correlate social media use with
    each user and attribute the Google searches to the child’s mother. When she was
    confronted with the findings, the mother admitted that she searched for how to
    treat her child’s injuries. After being presented with the evidence and testimony
    of the mother, the jury found the client not guilty of child abuse.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 一个人的互联网浏览习惯几乎可以像指纹一样具有独特性。当我查看超过一百万行的互联网历史记录时，我能够区分笔记本电脑上的两个不同用户。我能够将社交媒体的使用与每个用户相关联，并将Google搜索归因于孩子的母亲。当她面对这些发现时，母亲承认她曾搜索如何处理孩子的伤势。在出示了证据和母亲的证词后，陪审团判定客户无罪，不构成虐待儿童罪。
- en: Suppose they had done a timeline analysis before making the charging decision.
    In that case, I believe the father would not have been charged, as the only evidence
    against him was the digital evidence found on the wife’s laptop.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 假设在做出起诉决定之前他们进行了时间线分析，我相信父亲不会被起诉，因为唯一针对他的证据是从妻子的笔记本电脑中发现的数字证据。
- en: Your ability to create a timeline to analyze the system and actions of the user
    allows you to develop a much deeper and more thorough understanding of digital
    evidence. When I first started in the field, timelines were rudimentary and were
    typically based on the MAC times of the filesystem. **MAC** times refer to the
    **Modified, Accessed, and Created** times that are records created by the filesystem
    as created, edited, or accessed. The downside to only using MAC times for timeline
    analysis is that the recorded times may not be accurate. For example, this can
    happen when files are moved from one volume to another or if a user uses a third-party
    tool to change the timestamps and the timestamps are dependent on the system time.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 你创建时间线以分析系统和用户行为的能力，让你能够对数字证据有更深入、更全面的理解。当我刚开始从事这个领域时，时间线是初步的，通常基于文件系统的MAC时间。**MAC**时间指的是**修改时间、访问时间和创建时间**，这些记录由文件系统在文件创建、编辑或访问时生成。仅使用MAC时间进行时间线分析的缺点是记录的时间可能不准确。例如，当文件从一个卷移动到另一个卷，或者用户使用第三方工具更改时间戳，并且时间戳依赖于系统时间时，就可能发生这种情况。
- en: We will now use multiple sources to help us to determine the context of what
    is happening on a system regarding a specific artifact. These additional sources
    may not be as easily manipulated as the MAC times and can determine any irregularities
    in the timestamps. For example, using multiple resources found within the forensic
    image, we can see when the user logs in, launches an executable, and accesses
    a file associated with the executable. This method of accessing multiple sources
    helps us confirm and validate the information provided by the MAC times.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将使用多个来源来帮助我们确定系统中与特定证据相关的事件上下文。这些附加来源可能不像MAC时间那样容易被篡改，并且能够确定时间戳中的任何异常。例如，使用法医镜像中的多个资源，我们可以看到用户登录、启动可执行文件，并访问与可执行文件相关联的文件。这种访问多个来源的方法有助于我们确认并验证MAC时间提供的信息。
- en: Applying multiple frames of reference to the event being investigated allows
    us to support our hypothesis about the event. For example, can we determine whether
    the investigated incident results from user activity or is it a system process?
    In addition, using all of the available sources such as event logs, filesystem
    logs, or internet history captured by the system allows us to get into the small
    details to see the context of the event.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 将多个参考框架应用于正在调查的事件，能帮助我们支持对事件的假设。例如，我们是否能够判断调查事件是由用户活动引起的，还是系统进程的结果？此外，使用所有可用的资源，如事件日志、文件系统日志或系统捕获的互联网历史记录，可以帮助我们深入细节，了解事件的上下文。
- en: By gathering data points from multiple sources, you can create what Rob Lee
    from the SANS Institute calls a super timeline because of the sheer amount of
    data points you will have to sort through.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 通过从多个来源收集数据点，你可以创建出罗布·李（Rob Lee）在SANS研究所所称的超级时间线，因为你需要筛选的大量数据点会使得这一过程更加复杂。
- en: Hard drive capacity is not getting smaller. Instead, it is increasing at a phenomenal
    rate. Users and developers use this increased capacity to store more data and
    increase the number of logs that can track what occurs in a system. In some investigations,
    you may not need to examine the content of the files; for example, in an investigation
    dealing with illicit images, I need not see the visual depiction of the file.
    Instead, to answer whether a user knew about the existence of a specific file,
    I can use timeline analysis to make that determination.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 硬盘容量并没有变小，反而以惊人的速度在增长。用户和开发人员利用这种增加的容量来存储更多的数据，并增加可以追踪系统中发生事件的日志数量。在某些调查中，你可能不需要检查文件的内容；例如，在涉及非法图片的调查中，我无需查看文件的视觉内容。相反，为了回答一个用户是否知道某个特定文件的存在，我可以使用时间线分析来做出这个判断。
- en: Commercial forensic (and open-source) tools have made many advances when it
    comes to creating timelines. For example, at one time, you had to use many tools
    to extract data to create a timeline. Now you can use just a single tool to create
    a timeline.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 商业取证工具（以及开源工具）在创建时间线方面取得了许多进展。例如，曾经你需要使用多个工具来提取数据以创建时间线。现在，你只需使用一个工具就可以创建时间线。
- en: '**Note**'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: In this chapter, we will be discussing date-times, which will be converted into
    UTC/GMT. Always be aware of which time zone your dataset is operating in and the
    time zone it is stored. I use GMT/UTC as a standard when conducting an examination.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论日期和时间，这些将被转换为UTC/GMT。始终注意你的数据集操作的时区以及它存储的时区。我在进行审查时使用GMT/UTC作为标准。
- en: In this chapter, I will demonstrate the use of several tools for you to see
    the difference in the outputs and discuss where the tools pull the information
    from.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我将演示使用几种工具，让你了解它们输出的区别，并讨论这些工具从哪里获取信息。
- en: X-Ways
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: X-Ways
- en: X-Ways Forensics has a very robust timeline-creation utility built in, called
    an **event list**. X-Ways compiles multiple sources such as timestamps at the
    filesystem level, internal timestamps, browser histories, event logs, registry
    hives, emails, and many other sources. When you start an event list, the data
    will be presented chronologically, creating a timeline. The event list is a very
    detailed timeline with copious amounts of information, which allows you to see
    the sequence of events of the incident you are investigating.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: X-Ways Forensics内置了一个非常强大的时间线创建工具，叫做**事件列表**。X-Ways整合了多个来源的数据，如文件系统级别的时间戳、内部时间戳、浏览器历史记录、事件日志、注册表配置单元、电子邮件等。当你启动事件列表时，数据将按时间顺序呈现，形成时间线。事件列表是一条非常详细的时间线，包含大量信息，允许你看到你正在调查的事件的时间顺序。
- en: '**Note**'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: As you explore the features of a new tool, remember to validate the tool against
    a known dataset. We will use a forensic image offered by Digital Corpora for this
    lab. You can visit [https://digitalcorpora.org/](https://digitalcorpora.org/)
    and go to the 2008 M–57 Jean scenario for more information.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在你探索新工具的功能时，记得用已知的数据集来验证工具。我们将在本实验中使用Digital Corpora提供的取证镜像。你可以访问[https://digitalcorpora.org/](https://digitalcorpora.org/)并查看2008年M–57
    Jean案例，获取更多信息。
- en: In this scenario, you are investigating a data leak. Someone has posted a spreadsheet
    containing an organization’s confidential information onto a competitor’s website,
    and the spreadsheet came from the computer of the CFO, Jean. During her interview,
    Jean stated that she emailed the spreadsheet to the president, Allison, at her
    request. The spreadsheet is `m57plan.xls` and can be found on the desktop of Jean’s
    account. It has an MD5 hash value of `e23a4eb7f2562f53e88c9dca8b26a153` and a
    modified time of **2008-JUL-20 01:28:03 GMT** that also corresponds to Jean’s
    statement regarding when she emailed the spreadsheet.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，你正在调查一起数据泄露事件。有人将一份包含某组织机密信息的电子表格发布到竞争对手的网站上，而这份电子表格来自首席财务官（CFO）Jean的计算机。在她的面谈中，Jean表示她根据总裁Allison的要求，将这份电子表格通过邮件发送给了她。电子表格名为`m57plan.xls`，可以在Jean账户的桌面上找到。该文件的MD5哈希值为`e23a4eb7f2562f53e88c9dca8b26a153`，修改时间为**2008-JUL-20
    01:28:03 GMT**，这与Jean关于她何时发送电子表格的陈述相符。
- en: 'The filename and time frame give us a starting point for conducting the timeline
    analysis. When you are in the user environment of X-Ways Forensics, select the
    icon for the event list:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 文件名和时间范围为我们提供了进行时间线分析的起点。当你进入X-Ways Forensics的用户环境时，选择事件列表图标：
- en: '![](img/B18329_05_01.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18329_05_01.png)'
- en: 'Figure 5.1: X-Ways'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.1：X-Ways
- en: As you can see in the preceding screenshot, when you select the **Calendar**
    option, it will show you the calendar interface so that you can drill down to
    a specific day. If I do not filter any of the results on the event list, I have
    over one million entries that I will need to parse through. My preferred workflow
    method is to start big and then filter the results to meet the needs of my investigation.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，当你选择**日历**选项时，它会显示日历界面，方便你深入查看特定日期。如果我不对事件列表中的结果进行筛选，那么会有超过一百万条记录需要我逐一解析。我的首选工作流程是从大的数据集开始，然后逐步筛选结果，以满足调查的需求。
- en: When I filter down to July 20, I have reduced my results to a much more manageable
    4,052 events.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 当我将筛选范围缩小到 7 月 20 日时，我将结果减少到了 4,052 个事件，更加易于管理。
- en: 'Once we filter the results, let’s search for the filename and see what activity
    has occurred. One of the first results shows that at 01:27:42, the system created
    a link file for the spreadsheet. In the following screenshot, you can see the
    user activity from 01:27 to 01:28\. A pre-fetch file (`EXCEL.EXE-1C75F8D6.pf`)
    was created for Excel at 01:27, which shows the user starting the Excel program
    and then opening the spreadsheet, which corresponds to the creation of a link
    file:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦筛选了结果，我们可以搜索文件名，看看发生了什么活动。第一个结果显示，在 01:27:42，系统为电子表格创建了一个链接文件。在接下来的截图中，你可以看到从
    01:27 到 01:28 的用户活动。在 01:27 时，创建了一个预取文件（`EXCEL.EXE-1C75F8D6.pf`），这表示用户启动了 Excel
    程序并打开了电子表格，正好对应了链接文件的创建。
- en: '![](img/B18329_05_02.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18329_05_02.png)'
- en: 'Figure 5.2: Filter results'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.2：筛选结果
- en: When you view the event list, you can see where the forensic tool is getting
    the information that is being displayed. The creation of the pre-fetch file starts
    with a change in the NT `user.dat` file. The tool follows along from gathering
    information from the internal file metadata to the operating system artifact.
    We can follow along and observe what occurs at the user and system levels as the
    user activity is being recorded.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 查看事件列表时，你可以看到法医工具获取并展示信息的来源。预取文件的创建始于 NT `user.dat` 文件的变更。工具会跟踪从内部文件元数据到操作系统工件的整个过程。我们可以跟踪并观察用户和系统层面的活动，记录下用户操作的全过程。
- en: 'If you look at timestamp 01:28:00, you can see that Jean sent a message out.
    In the **Name** column, we can see the subject of the email, and when we double-click
    on it, we can view the email itself:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你查看时间戳 01:28:00，可以看到 Jean 发送了一条消息。在**名称**列中，我们可以看到邮件的主题，双击后可以查看邮件内容：
- en: '![](img/B18329_05_03.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18329_05_03.png)'
- en: 'Figure 5.3: Jean’s email'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.3：Jean 的邮件
- en: 'We can see that Jean has emailed what appears to be `allison@M57.biz`, but,
    in reality, it is going to `tuckgorge@gmail.com`. We can then filter by file type,
    in this case, the `.eml` files, and you can see the results as follows:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到 Jean 发出了邮件，收件人看似是 `allison@M57.biz`，但实际上是发送到了 `tuckgorge@gmail.com`。然后，我们可以根据文件类型进行筛选，在这种情况下是
    `.eml` 文件，筛选结果如下：
- en: '![Graphical user interface, text, application, email  Description automatically
    generated](img/B18329_05_04.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![图形用户界面，文本，应用程序，电子邮件 说明自动生成](img/B18329_05_04.png)'
- en: 'Figure 5.4: Jean’s email header'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.4：Jean 的邮件头
- en: When you look at the **Sender** and **Recipients** columns, and when the data
    is sorted chronologically, you can get a good idea about the email communication
    between the attacker and Jean. It appears they have compromised Allison’s account,
    as we can see the name “Alex” and the email account `tuckgorge@gmail.com` associated
    with the account.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 查看**发件人**和**收件人**列，并按时间顺序排列数据，你可以大致了解攻击者与 Jean 之间的邮件通讯。看起来他们已经入侵了 Allison 的账户，因为我们可以看到“Alex”这个名字和与该账户关联的邮件地址
    `tuckgorge@gmail.com`。
- en: Using the event list feature of X-Ways Forensics allows us to pinpoint when
    the file was compromised and from what vector. Now we can direct our investigation
    to Allison’s computer to determine whether the attacker compromised her system.
    Based on these initial results, I believe the attacker targeted Jean in a phishing
    attack.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 X-Ways Forensics 的事件列表功能可以帮助我们准确定位文件何时被篡改以及通过什么途径。现在我们可以将调查方向指向 Allsion 的计算机，以确定攻击者是否侵入了她的系统。根据这些初步结果，我认为攻击者通过网络钓鱼攻击瞄准了
    Jean。
- en: What I like about X-Ways Forensics is its ability to gather the dates and times
    from traditional sources and combine them with the actual artifacts, in this case,
    the emails. This gives you another level of granularity and context for your investigation.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我喜欢X-Ways Forensics的一点是，它能够从传统来源收集日期和时间，并将这些信息与实际的证据（在本例中为电子邮件）结合起来。这为你的调查提供了更高的细节层次和背景。
- en: 'The X-Ways Forensics documentation lists the following as sources of information
    for the event list feature:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: X-Ways Forensics文档列出了以下内容作为事件列表功能的信息来源：
- en: '![Table  Description automatically generated](img/B18329_05_05.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![图表 描述自动生成](img/B18329_05_05.png)'
- en: As you can see, this shows a very diverse list of sources. However, when used
    for analysis, it can give the investigator the confidence to rely on the date
    timestamps they are reporting in their investigation.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，这展示了一个非常多样化的信息来源列表。然而，在用于分析时，它可以使调查员更加信赖他们在调查中报告的日期时间戳。
- en: 'I have found that forensic suites also include timeline analysis with their
    products. I have discussed X-Ways Forensics and its ability to create a timeline
    for analysis with its event list feature. I have included a list of some additional
    forensic suites that you may use to analyze timeline data. The following list
    is not inclusive of all the forensic suites that are available:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我发现法医套件也包含了时间线分析功能。我曾讨论过X-Ways Forensics及其通过事件列表功能创建时间线进行分析的能力。我列出了你可以用来分析时间线数据的一些其他法医套件。以下列表并不包含所有可用的法医套件：
- en: 'Belkasoft Evidence Center: [belkasoft.com/ec](https://belkasoft.com/ec)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Belkasoft Evidence Center: [belkasoft.com/ec](https://belkasoft.com/ec)'
- en: 'Autopsy: [www.sleuthkit.org/autopsy](https://www.sleuthkit.org/autopsy)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Autopsy: [www.sleuthkit.org/autopsy](https://www.sleuthkit.org/autopsy)'
- en: 'Recon Lab: [sumuri.com/software/recon-lab](https://sumuri.com/software/recon-lab)'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Recon Lab: [sumuri.com/software/recon-lab](https://sumuri.com/software/recon-lab)'
- en: 'PALADIN: [sumuri.com/software/paladin](https://sumuri.com/software/paladin)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'PALADIN: [sumuri.com/software/paladin](https://sumuri.com/software/paladin)'
- en: X-Ways is not the only tool you can use to create timelines; there are also
    several open-source tools that you can utilize. One of the most common is **Plaso/log2timeline**,
    which we will discuss next.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: X-Ways并不是唯一可以用来创建时间线的工具；你还可以使用一些开源工具。最常见的工具之一是**Plaso/log2timeline**，我们接下来将讨论它。
- en: Plaso (Plaso Langar Að Safna Öllu)
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Plaso（Plaso Langar Að Safna Öllu）
- en: Plaso (Plaso Langar Að Safna Öllu) is a Python backend and framework for the
    `log2timeline` tool. `log2timeline` is a forensic tool that pulls out timestamps
    from a system and creates a database of all the events, also known as a super
    timeline.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: Plaso（Plaso Langar Að Safna Öllu）是一个Python后端和`log2timeline`工具的框架。`log2timeline`是一个法医工具，它从系统中提取时间戳并创建一个所有事件的数据库，也叫超级时间线。
- en: '**Note**'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: You can download Plaso at [https://github.com/log2timeline/plaso](https://github.com/log2timeline/plaso).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从[https://github.com/log2timeline/plaso](https://github.com/log2timeline/plaso)下载Plaso。
- en: Plaso will work on most operating systems and was initially designed to replace
    the Perl version of `log2timeline`. However, the development has now shifted to
    modules, and they have created several CLI tools supported by the Plaso backend.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: Plaso适用于大多数操作系统，最初设计用于替代Perl版本的`log2timeline`。然而，开发现在已经转向模块化，并且他们创建了多个由Plaso后台支持的CLI工具。
- en: 'The tools supported by Plaso are activated by the **command-line interface**
    (**CLI**). While the CLI can intimidate the user, if you take your time and proceed
    slowly, you will take the mystique out of the CLI. Many open-source tools use
    the CLI instead of the **graphical user interface** (**GUI**). The very core of
    the CLI consists of two parts: the executable and the modifiers. Once you learn
    the specific modifiers for the CLI command, you will see that it all falls into
    place.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: Plaso支持的工具是通过**命令行界面**（**CLI**）激活的。尽管CLI可能会让用户感到害怕，但如果你慢慢来，逐步进行操作，你会发现CLI并不神秘。许多开源工具使用CLI而不是**图形用户界面**（**GUI**）。CLI的核心由两部分组成：可执行文件和修饰符。一旦你掌握了CLI命令的特定修饰符，你会发现一切都能井然有序地运作。
- en: 'Let’s talk about the tools included with Plaso:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来谈谈Plaso中包含的工具：
- en: '`image_export`'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_export`'
- en: '`log2timeline`'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`log2timeline`'
- en: '`pinfo`'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pinfo`'
- en: '`psort`'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`psort`'
- en: '`psteal`'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`psteal`'
- en: image_export
  id: totrans-68
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: image_export
- en: '`image_export` will export file content from a device, media image, or forensic
    image. There are several parameters that you can use to define the information
    you wish to extract.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '`image_export` 将从设备、媒体镜像或法医镜像中导出文件内容。你可以使用多个参数来定义你希望提取的信息。'
- en: In the Windows version of the executable, the executable will end with `.exe`.
    With macOS, you may see it end in `.sh`.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在Windows版本的可执行文件中，可执行文件以`.exe`结尾。而在macOS中，可能会看到它以`.sh`结尾。
- en: 'Using `–h` or `--help` will give you the full list of parameters:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`–h`或`--help`将给出完整的参数列表：
- en: '![](img/B18329_05_06.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18329_05_06.png)'
- en: 'Figure 5.5: image_export'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.5：image_export
- en: 'Further down the screen, you will see detailed explanations for the modifiers.
    Note that I will only cover the most used options; there is additional documentation
    that we will not discuss here:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在屏幕下方，你将看到修饰符的详细解释。请注意，我只会涵盖最常用的选项；这里有更多的文档，我们将不再讨论：
- en: '`--names NAMES`: The filter on filenames. This option accepts a comma-separated
    string denoting all filenames, for example, `x NTUSER.DAT,UsrClass.dat`.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--names NAMES`：对文件名的过滤。此选项接受一个用逗号分隔的字符串，表示所有文件名，例如，`x NTUSER.DAT, UsrClass.dat`。'
- en: '`-w PATH`, `--write PATH`: The directory in which extracted files should be
    stored.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-w PATH`, `--write PATH`：提取的文件应存储的目录。'
- en: '`--data PATH`: The path to a directory containing the data files.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--data PATH`：包含数据文件的目录路径。'
- en: '`-x EXTENSIONS`, `--extensions EXTENSIONS`: The filter on filename extensions.
    This option accepts multiple comma-separated values, for example, `csv`, `docx`,
    and `pst`.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-x EXTENSIONS`, `--extensions EXTENSIONS`：对文件名扩展名的过滤。此选项接受多个用逗号分隔的值，例如，`csv`，`docx`，和`pst`。'
- en: 'If you use the following command, it will export the `.xls` file to the `files`
    folder:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 如果使用以下命令，它将把`.xls`文件导出到`files`文件夹中：
- en: '[PRE0]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'You can see the breakdown of the preceding command as follows:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到前面命令的分解如下：
- en: '![](img/B18329_05_07.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18329_05_07.png)'
- en: 'Figure 5.6: CLI map'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.6：CLI 映射
- en: Here, with the `image_export` command, we are using the `names` modifier to
    look for a specific file. In this case, it is `M57plan.xls`.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，使用`image_export`命令，我们使用`names`修饰符来查找特定文件。在此情况下，它是`M57plan.xls`。
- en: Now, you can tell the executable where to search; in this command, we are searching
    in the forensic image, `jean.001` (make sure that you include the full path to
    where the forensic image is located). Next, you can indicate where you want the
    exported files to be sent. The `-w` modifier will specify the write location.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可以告诉可执行文件在哪里进行搜索；在此命令中，我们在取证镜像`jean.001`中进行搜索（确保包含取证镜像所在位置的完整路径）。接下来，你可以指定将导出的文件发送到哪里。`-w`修饰符将指定写入位置。
- en: You will find that the modifiers have some commonality with the commands within
    the Plaso framework.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 你会发现，这些修饰符与Plaso框架中的命令有一些共通之处。
- en: log2timeline
  id: totrans-87
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: log2timeline
- en: '`log2timeline` is a CLI tool that is designed to extract chronological-based
    events from files, directories, forensic images, and devices. It will create a
    database file (`.plaso`) that can then be analyzed by a variety of tools.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '`log2timeline`是一个命令行工具，旨在从文件、目录、取证镜像和设备中提取基于时间的事件。它将创建一个数据库文件（`.plaso`），然后可以通过各种工具进行分析。'
- en: 'As you can see in the following screenshot, the `-h` modifier (help) will display
    the options for the command. As before, there are detailed explanations not displayed
    that will give you additional context for these commands. You should be able to
    recognize some of them from the previous command we looked at:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 如下图所示，`-h`修饰符（帮助）将显示命令的选项。与之前一样，虽然有些详细解释没有显示，但它们能为这些命令提供额外的上下文。你应该能够从我们之前看的命令中识别出一些：
- en: '![](img/B18329_05_08.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18329_05_08.png)'
- en: 'Figure 5.7: log2timeline'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.7：log2timeline
- en: 'Try using the `info` modifier, as follows:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试使用`info`修饰符，如下所示：
- en: '[PRE1]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'You will get a list of all of the supported plugins, parsers, and output modules:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 你将看到所有支持的插件、解析器和输出模块的列表：
- en: '![](img/B18329_05_09.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18329_05_09.png)'
- en: 'Figure 5.8: Results of the info modifier'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.8：info修饰符的结果
- en: From the preceding output, you can see that some of the presets include collecting
    artifacts from many filesystems.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的输出中，你可以看到一些预设包括从多个文件系统中收集工件。
- en: 'At a very basic level, you can use the following command structure:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个非常基础的层面上，你可以使用以下命令结构：
- en: '[PRE2]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'One idiosyncrasy of `log2timeline` is that the output file is the first modifier
    to the executable and then you specify the input:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '`log2timeline`的一个特点是，输出文件是可执行文件的第一个修饰符，然后你再指定输入：'
- en: '[PRE3]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'When the command executes, you should see the following output on the screen:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 当命令执行时，你应该在屏幕上看到以下输出：
- en: '![](img/B18329_05_10.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18329_05_10.png)'
- en: 'Figure 5.9: Output'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.9：输出
- en: As the command executes, it locates the data folder that contains the dependencies
    for the executable, and then it searches for the files that contain the information
    about the artifacts that may be stored within the system. This is a default folder
    and is installed when you install `plaso`.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 当命令执行时，它会定位包含可执行文件依赖项的数据文件夹，然后搜索包含可能存储在系统中的工件信息的文件。这是一个默认文件夹，在你安装 `plaso` 时会自动安装。
- en: We now have a `.plaso` file that we can find in the `files` folder. In some
    cases, you might not want to create the database file with every option, that
    is, the kitchen sink. Rather, you may wish to do a targeted examination of the
    timeline, in which case you would need to employ filters. Using the `-f` modifier
    will allow you to do that.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了一个 `.plaso` 文件，可以在 `files` 文件夹中找到它。在某些情况下，你可能不希望为每个选项都创建数据库文件，即不想“厨房水槽式”地处理所有内容。相反，你可能希望对时间线进行有针对性的检查，这时你需要使用过滤器。使用
    `-f` 修饰符可以实现这一点。
- en: '**Note**'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: If you want to download some premade filters, you can do so at [https://github.com/mark-hallman/plaso_filters](https://github.com/mark-hallman/plaso_filters).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想下载一些预制的过滤器，可以访问 [https://github.com/mark-hallman/plaso_filters](https://github.com/mark-hallman/plaso_filters)。
- en: 'I downloaded the premade filters and created a folder, named `filter`, within
    the path of the `plaso` installation. As you see from the following screenshot,
    I have installed `plaso` in a folder called `tools` at the root of my `C` drive:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我下载了预制的过滤器，并在 `plaso` 安装路径下创建了一个名为 `filter` 的文件夹。如以下截图所示，我将 `plaso` 安装在了 `C`
    盘根目录下的一个名为 `tools` 的文件夹中：
- en: '[PRE4]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'And, as you can see in the following screenshot, the tool was able to locate
    my filter within the `artifacts` folder and created a new Plaso database file:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 如以下截图所示，工具能够在 `artifacts` 文件夹中找到我的过滤器，并创建了一个新的 Plaso 数据库文件：
- en: '![](img/B18329_05_11.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18329_05_11.png)'
- en: 'Figure 5.10: Filter'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.10：过滤器
- en: So far, we have covered several commands; however, we still have more to cover.
    The next command in the framework is `pinfo`.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经介绍了几个命令；然而，我们还有更多内容要讲解。框架中的下一个命令是 `pinfo`。
- en: pinfo
  id: totrans-115
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: pinfo
- en: '`pinfo` is a command line that is used to display information about the Plaso
    database file (`.plaso`).'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '`pinfo` 是一个命令行，用于显示关于 Plaso 数据库文件（`.plaso`）的信息。'
- en: 'The `plaso` database file will contain the following information:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '`plaso` 数据库文件将包含以下信息：'
- en: When the user executed the tool
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户执行工具时
- en: What options were used when the tool was run
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行工具时使用的选项
- en: What information was obtained by the tool during the pre-processing stage
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 工具在预处理阶段获取的信息
- en: The database metadata
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据库元数据
- en: What was parsed and the parameters that were used
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解析了什么内容以及使用的参数
- en: The number of events extracted
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提取的事件数量
- en: Tagged events
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标记事件
- en: 'To learn more about the preceding options, execute the command with the `-h`
    modifier. While the options are similar, you will have a far smaller selection
    than with the other tools, as shown in the following screenshot:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于前述选项的信息，请使用 `-h` 修饰符执行命令。虽然这些选项相似，但与其他工具相比，你的选择会少得多，正如下图所示：
- en: '![](img/B18329_05_12.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18329_05_12.png)'
- en: 'Figure 5.11: pinfo'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.11：pinfo
- en: 'When you use the `pinfo` command in its simplest form, you will get the following
    results:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 当你以最简单的形式使用 `pinfo` 命令时，将获得以下结果：
- en: '[PRE5]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: As you can see in the preceding output, you get the storage information about
    the file and how many sessions were used to create it.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 如前面的输出所示，你可以查看文件的存储信息以及创建该文件所用的会话数量。
- en: You can send the results to the standard output, that is, the monitor, or you
    can use the `-w` modifier to create a text file with the results. The use of the
    additional tools on the `.plaso` file will create the GUID and the date timestamp
    of when the analysis was conducted.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将结果发送到标准输出，也就是显示器，或者使用 `-w` 修饰符将结果保存到一个文本文件中。对 `.plaso` 文件使用额外工具将生成 GUID
    以及分析进行时的日期时间戳。
- en: 'The tool can also provide system information about the source system you are
    now examining:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 该工具还可以提供你正在检查的源系统的系统信息：
- en: '[PRE6]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: After verifying the information in the database file, you can move on to the
    next command.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在验证数据库文件中的信息后，你可以继续执行下一个命令。
- en: psort
  id: totrans-135
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: psort
- en: '`psort` is a CLI tool that allows you to filter, sort, and conduct analysis
    on the contents of the `plaso` database file. Just like with the previous commands,
    the `-h` modifier will show you all the options for the command. In the following
    `psort` screenshot, you can see the available options, and you should be able
    to recognize the commonality of the options between all of the commands in the
    `plaso` architecture:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '`psort` 是一个命令行工具，允许你筛选、排序并分析 `plaso` 数据库文件的内容。就像其他命令一样，`-h` 修饰符将显示该命令的所有选项。在下面的
    `psort` 截图中，你可以看到可用选项，并且你应该能识别出所有 `plaso` 架构中命令选项的共性：'
- en: '![](img/B18329_05_13.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18329_05_13.png)'
- en: 'Figure 5.12: psort'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.12：psort
- en: 'Let’s discuss some of the new options:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们讨论一些新的选项：
- en: '[PRE7]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Below is a list of the available output formats:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是可用的输出格式列表：
- en: '| **Name** | **Description** |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| **名称** | **描述** |'
- en: '| --- | --- |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `dynamic` | Output events to a delimiter (comma by default) separated value
    output format, that supports a dynamic selection of fields. |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| `dynamic` | 将事件输出为分隔符（默认是逗号）分隔的值格式，支持动态选择字段。 |'
- en: '| `elastic` | Output events to an ElasticSearch database.Requires elasticsearch-py.
    |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| `elastic` | 将事件输出到 ElasticSearch 数据库。需要 elasticsearch-py。 |'
- en: '| `elastic_ts` | Output events to an ElasticSearch database for use with Timesketch.
    Requires elasticsearch-py.Solely intended to be used by the Timesketch backend.
    |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| `elastic_ts` | 将事件输出到 ElasticSearch 数据库，以供 Timesketch 使用。需要 elasticsearch-py。仅供
    Timesketch 后端使用。 |'
- en: '| `json` | Output events to JSON format. |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| `json` | 将事件输出为 JSON 格式。 |'
- en: '| `json_line` | Output events to JSON line format. |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| `json_line` | 将事件输出为 JSON 行格式。 |'
- en: '| `kml` | Output events with geography data into a KML format. |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| `kml` | 将含有地理数据的事件输出为 KML 格式。 |'
- en: '| `l2tcsv` | Output events to `log2timeline.pl` legacy CSV format, with 17
    fixed fields. |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| `l2tcsv` | 将事件输出为 `log2timeline.pl` 的传统 CSV 格式，包含 17 个固定字段。 |'
- en: '| `l2ttln` | Output events to `log2timeline.pl` extended TLN format, with 7
    fixed fields. |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| `l2ttln` | 将事件输出为 `log2timeline.pl` 的扩展 TLN 格式，包含 7 个固定字段。 |'
- en: '| `null` | Do not output events. |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| `null` | 不输出事件。 |'
- en: '| `rawpy` | Output events in “raw” (or native) Python format. |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| `rawpy` | 以“原始”（或本地）Python 格式输出事件。 |'
- en: '| `tln` | Output events to TLN format, with 5 fixed fields. |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| `tln` | 将事件输出为 TLN 格式，包含 5 个固定字段。 |'
- en: '| `xlsx` | Output events to an Excel spreadsheet (XLSX). |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| `xlsx` | 将事件输出为 Excel 电子表格（XLSX）。 |'
- en: As you are processing with `psort`, you can export your findings outside of
    the `plaso` database. There are a wide variety of options that you can use to
    export the data for analysis. One of the more common formats for exporting is
    `l2tcsv`, which is the legacy format for `log2timeline` and is a `.csv` worksheet.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 当你使用 `psort` 进行处理时，可以将结果导出到 `plaso` 数据库之外。你可以使用多种选项导出数据以便分析。一个常见的导出格式是 `l2tcsv`，它是
    `log2timeline` 的传统格式，采用 `.csv` 工作表格式。
- en: A potential issue you may run into when creating the `.csv` worksheet is that
    if the file you create is too large, some tools may not analyze it, nor will you
    be able to open it with your favorite spreadsheet program.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建 `.csv` 工作表时，你可能会遇到一个潜在问题，即如果你创建的文件太大，一些工具可能无法分析它，或者你无法用你喜欢的电子表格程序打开它。
- en: '`--analysis list`: `psort` comes with analysis plugins installed by default
    (you can still create your own custom plugins) to allow you to go through the
    database file and extract and analyze the contents.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '`--analysis list`：`psort` 默认安装了分析插件（你仍然可以创建自定义插件），允许你浏览数据库文件并提取和分析内容。'
- en: 'You can use the `--analysis` `list` modifier to view the complete list of plugins:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用 `--analysis` `list` 修饰符查看完整的插件列表：
- en: '![](img/B18329_05_14.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18329_05_14.png)'
- en: 'Figure 5.13: List of analysis plugins'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.13：分析插件列表
- en: 'If we run the command, it will go through the `plaso` database file, tagging
    the specific events that have been identified in the `tag_windows.txt` file (which
    is part of the default installation and can be found in the `data` directory):'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们运行该命令，它会遍历 `plaso` 数据库文件，标记在 `tag_windows.txt` 文件中已识别的特定事件（该文件是默认安装的一部分，可以在
    `data` 目录中找到）：
- en: '[PRE8]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'On completion of the process, it will show you how many tags were applied to
    the database:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 处理完成后，它会显示已应用于数据库的标签数量：
- en: '[PRE9]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Additionally, you can filter out extraneous data using the `--slice` modifier.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，你还可以使用 `--slice` 修饰符过滤掉多余的数据。
- en: '**Note**'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: 5 minutes is the default value. If you want a longer or shorter time slice,
    you can add the amount after `DATE TIME` with `--slice_size <VALUE>`.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 5分钟是默认值。如果你想要更长或更短的时间切片，可以在`DATE TIME`后添加`--slice_size <VALUE>`来指定。
- en: 'If you find the `GET` event, you may want to place that event into context
    by observing what occurred before and afterward:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你发现了`GET`事件，你可能希望通过观察发生在之前和之后的事件来为其提供上下文：
- en: '[PRE10]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The command will create a `csv` file, which contains events 5 minutes before
    and 5 minutes after the timestamp placed in the CLI.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 该命令将创建一个`csv`文件，包含时间戳前后各5分钟的事件。
- en: The final tool in the framework is `psteal`, which we will discuss next.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 框架中的最后一个工具是`psteal`，我们接下来会讨论它。
- en: psteal
  id: totrans-173
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: psteal
- en: '`psteal` is the final CLI command in the plaso framework. It combines the `log2timeline`
    and `psort` commands to extract and process events in a single step. It is very
    much the kitchen sink approach, otherwise known as “I want it ALLLLLL”, and it
    has a limited selection of modifiers when compared to the other CLI commands within
    the framework.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '`psteal`是plaso框架中的最终CLI命令。它将`log2timeline`和`psort`命令结合在一起，通过一步操作提取和处理事件。这是一种典型的“万金油”方法，也可以称为“我想要所有的”，与框架中其他CLI命令相比，它有一个有限的修饰符选择。'
- en: 'Once again, `-h` will provide you with a list of options for the command, which
    are displayed in the following screenshot:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 再次提醒，`-h`会为你提供命令的选项列表，具体内容如下截图所示：
- en: '![](img/B18329_05_15.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18329_05_15.png)'
- en: 'Figure 5.14: psteal'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.14：psteal
- en: At a minimum, specify the source and the output. The process will create the
    plaso database file and place it in the root of the plaso installation. This location
    allows you to perform additional tagging, filtering, or analysis after the command
    completes. The naming convention for the database file created is `<timestamp>-<source>.plaso`.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 至少需要指定源和输出。该过程将创建plaso数据库文件，并将其放置在plaso安装目录的根目录中。此位置允许你在命令完成后执行额外的标记、筛选或分析。创建的数据库文件的命名约定为`<timestamp>-<source>.plaso`。
- en: 'Here’s the command. It creates a `.csv` file that is almost 1 GB in size. However,
    if I change the output to `.xlsx`, it reduces the size to 35 MB. So, keep in mind
    that you are processing and analyzing your datasets:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 这是命令。它创建了一个几乎1GB大小的`.csv`文件。然而，如果我将输出更改为`.xlsx`，文件大小会减少到35MB。所以，请记住，你正在处理和分析你的数据集：
- en: '[PRE11]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: I am using a relatively small forensic image of a 20 GB hard drive. Just imagine
    if you were using a 500 GB or a 1 TB hard drive and it had been active for an
    extended period.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我正在使用一个相对较小的20GB硬盘的法医镜像。试想一下，如果你使用的是500GB或1TB的硬盘，并且该硬盘已经使用了较长时间，会是什么情况。
- en: Now that we have created our database file and have exported the datasets we
    find relevant to the investigation, what do we do now? It is time to analyze the
    datasets to find the evidence that will either prove or disprove the allegation.
    The tools you use for analysis can simply be the spreadsheet reader of your favorite
    Office suite or a commercial open-source tool designed for that specific purpose.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经创建了数据库文件并导出了与调查相关的数据集，接下来该做什么呢？是时候分析数据集，找出能够证明或反驳指控的证据了。你用来分析的工具可以是你喜欢的Office套件中的电子表格阅读器，也可以是专门为此目的设计的商业开源工具。
- en: It is not possible to cover all the tool options that are available to an examiner
    in this book. I will highlight several options that are available and summarize
    the tools for you. Ultimately, the analysis of the data is where the examiner
    eyeballs the dataset and reviews the findings. Once again, it comes back to the
    verification/validation of your forensic tools to ensure they are providing accurate
    results.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 本书无法涵盖所有可供检查员使用的工具选项。我将突出显示一些可用的选项并为你总结这些工具。最终，数据的分析是检查员通过查看数据集并审查结果来完成的。再次强调，这都归结于对法医工具的验证/确认，确保它们提供准确的结果。
- en: 'Here are a few tools:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些工具：
- en: '**ELK stack**: This can be found at [https://www.elastic.co](https://www.elastic.co).
    It is an acronym for three open-source projects: Elasticsearch, Logstash, and
    Kibana. Elasticsearch is the search and analytical engine. Logstash is the data
    processor and ingest engine, while Kibana is the visualizer. You have the option
    to download the three engines and install them in the operating system of your
    choice. You have options for macOS, Windows, and Linux. There is also the option
    to pay for the cloud environment if you do not wish to host the systems within
    your environment.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ELK堆栈**：可以在[https://www.elastic.co](https://www.elastic.co)找到。它是三个开源项目的缩写：Elasticsearch、Logstash和Kibana。Elasticsearch是搜索和分析引擎，Logstash是数据处理和摄取引擎，而Kibana是可视化工具。您可以选择下载这三个引擎并安装到您选择的操作系统中。提供了macOS、Windows和Linux版本。如果您不希望在自己的环境中托管这些系统，还可以选择付费使用云环境。'
- en: '**TimelineMaker Pro**: This can be found at [www.timelinemaker.com](https://www.timelinemaker.com).
    It is a commercial product specifically designed for creating timeline charts.
    With this tool, you can import the CSV files created with the plaso framework.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**TimelineMaker Pro**：可以在[www.timelinemaker.com](https://www.timelinemaker.com)找到。它是一个专门设计用于创建时间轴图表的商业产品。通过这个工具，您可以导入使用plaso框架创建的CSV文件。'
- en: '**TimeSketch**: This can be found at [https://github.com/google/timesketch](https://github.com/google/timesketch).
    It is an open-source forensic timeline-analysis tool. It is Linux-based. I have
    installed it in a virtual environment so that I can use it as needed. It can also
    be worked on collaboratively by different members of your team. You can also import
    from a variety of plaso framework output options.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**TimeSketch**：可以在[https://github.com/google/timesketch](https://github.com/google/timesketch)找到。它是一个开源的取证时间轴分析工具。它是基于Linux的。我已经将它安装在一个虚拟环境中，这样我就可以根据需要使用它。不同团队成员也可以共同使用它。您还可以从各种plaso框架输出选项中导入数据。'
- en: '**Aeon Timeline**: This can be found at [www.aeontimeline.com](https://www.aeontimeline.com).
    It is a commercial product specifically designed for creating visual timelines.
    It will allow you to view relationships among events. It was initially designed
    for authors, but it can also be used to analyze super timelines. You can import
    the CSV files created using the plaso framework.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Aeon Timeline**：可以在[www.aeontimeline.com](https://www.aeontimeline.com)找到。它是一个专门设计用于创建可视化时间轴的商业产品。它将帮助您查看事件之间的关系。最初是为作家设计的，但也可以用来分析超时间轴。您可以导入使用plaso框架创建的CSV文件。'
- en: '**Timeline Explorer**: This can be found at [ericzimmerman.github.io/#!index.md](https://ericzimmerman.github.io#%252521index.md).
    Timeline Explorer is an open-source platform created by Eric Zimmerman, who wanted
    a tool to read MAC time and plaso-generated CSV files without the need to use
    Microsoft Excel. It is not designed to examine very large CSV files; in fact,
    Zimmerman recommends explicitly that it is best to open smaller, targeted timelines
    than one giant one.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Timeline Explorer**：可以在[ericzimmerman.github.io/#!index.md](https://ericzimmerman.github.io#%252521index.md)找到。Timeline
    Explorer是由Eric Zimmerman创建的开源平台，旨在提供一个无需使用Microsoft Excel即可读取MAC时间和plaso生成的CSV文件的工具。它并不是专门设计来查看非常大的CSV文件；事实上，Zimmerman明确建议，最好打开较小且有针对性的时间轴，而不是一个巨大的时间轴。'
- en: Media analysis
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 媒体分析
- en: You can use timeline analysis on several vectors, such as network analysis,
    media analysis, software analysis, and hardware analysis. Network analysis is
    where you analyze log files, trace files, and the communication content between
    users and their devices. Media analysis is analyzing physical storage devices
    such as hard drives, SSD drives, thumb drives, or optical storage disks. You will
    examine the content, allocated space, and slack space. Finally, when performing
    software analysis, you reverse-engineer malicious code and analyze the protection
    code for potential exports.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在多个维度上使用时间轴分析，例如网络分析、媒体分析、软件分析和硬件分析。网络分析是分析日志文件、跟踪文件以及用户与其设备之间的通信内容。媒体分析是分析物理存储设备，如硬盘、SSD驱动器、U盘或光盘存储。您将检查内容、分配的空间以及空闲空间。最后，在进行软件分析时，您将逆向工程恶意代码并分析保护代码，以防止潜在的外泄。
- en: So, let’s look at media analysis. The primary source for your digital investigation
    will be the forensic images of storage devices such as hard drives, SSDs, USB
    devices, optical disks, and mobile devices such as smartphones. Depending on your
    organization, you may be the person responsible for creating the forensic image,
    or the forensic image may be provided to you from another part of the organization.
    Remember, the forensic image is a bit-for-bit copy of the source device. In most
    cases, you do not want to use a backup as the source of your digital forensic
    investigation because a backup will not contain all of the information on the
    storage device.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，让我们来看看媒体分析。您的数字调查的主要来源将是存储设备（如硬盘、SSD、USB设备、光盘以及智能手机等移动设备）的取证映像。根据您的组织，您可能是负责创建取证映像的人，或者取证映像可能是由组织的其他部门提供给您的。请记住，取证映像是源设备的逐位复制。在大多数情况下，您不希望使用备份作为数字取证调查的源，因为备份不会包含存储设备上的所有信息。
- en: 'The storage device may contain four different data types that you want to examine:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 存储设备可能包含四种不同类型的数据，您可能需要检查：
- en: '**Allocated space**: This is the space on the storage device that a file occupies.
    The filesystem recognizes the storage space as being used.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**已分配空间**：这是存储设备上被文件占用的空间。文件系统将该存储空间识别为已使用。'
- en: '**Unallocated space**: This is the space on the storage device that is not
    occupied by a file. The filesystem recognizes the storage space as being available
    for use.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**未分配空间**：这是存储设备上未被文件占用的空间。文件系统将该存储空间识别为可用空间。'
- en: '**Slack space**: When the data is stored in a cluster, if the file does not
    completely fill a cluster, the remaining space not used by the file is referred
    to as slack space.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**空闲空间**：当数据存储在一个簇中时，如果文件没有完全填满簇，未被文件占用的剩余空间被称为空闲空间。'
- en: '**Bad blocks/sectors/clusters**: This is the space on the disk that has been
    marked bad by the filesystem because of a defect. It can also be used by a user
    to hide data from a casual inspection.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**坏块/扇区/簇**：这是磁盘上由于缺陷而被文件系统标记为坏的空间。它也可以被用户用来隐藏数据，以防被随意检查。'
- en: 'Brian Carrier describes the progression of media analysis in his paper “Defining
    Digital Forensic Examination and Analysis Tools” as follows:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: Brian Carrier在他的论文《定义数字取证检查和分析工具》中描述了媒体分析的进展，内容如下：
- en: '**Disk**: Physical storage devices such as a hard disk drive, SSD, or flash
    media.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**磁盘**：物理存储设备，如硬盘、SSD或闪存介质。'
- en: '**Volume**: A container comprising a single disk or multiple disks. You may
    find numerous volumes on a single disk or a volume may span across multiple discs.
    You may see the term “volume” used interchangeably with the term “partition.”
    Brian Carrier defines a partition as being restricted to a single physical disk,
    whereas a volume is a collection of one or more partitions.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**卷**：一个容器，由单个磁盘或多个磁盘组成。您可能会在单个磁盘上找到多个卷，或者一个卷可能跨越多个磁盘。您可能会看到“卷”一词与“分区”一词互换使用。Brian
    Carrier将分区定义为仅限于单个物理磁盘，而卷是一个或多个分区的集合。'
- en: '**Filesystem**: This is used within the boundaries of a volume and tracks file
    allocation and cluster use.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文件系统**：这是在卷的边界内使用的，跟踪文件分配和簇的使用情况。'
- en: '**Data unit**: The smallest allocation unit available to the filesystem. In
    most cases, this will be clusters, or, in a UNIX-based system, it will be blocks.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据单元**：文件系统可用的最小分配单元。在大多数情况下，这将是簇，或者在基于UNIX的系统中，它将是块。'
- en: '**Metadata**: This is the data about data. This includes the modified, accessed,
    and created date-time stamps, as well as any other information about the file
    that the filesystem and some applications track.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**元数据**：这是关于数据的数据。它包括修改、访问和创建的日期时间戳，以及文件系统和某些应用程序跟踪的关于文件的其他信息。'
- en: The goal of media analysis in your digital forensic investigation is to find
    relevant artifacts that will either prove or disprove the allegations you are
    investigating. In addition, as you conduct the digital forensic investigation,
    you may find artifacts that will direct your focus to other locations.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在数字取证调查中的媒体分析目标是找到相关的证据，这些证据将支持或反驳您正在调查的指控。此外，在进行数字取证调查时，您可能会发现一些证据，它们会将您的注意力引导到其他位置。
- en: We will now discuss some different analysis techniques that you might use during
    your digital forensic investigation.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将讨论在数字取证调查过程中可能使用的一些不同分析技术。
- en: String search
  id: totrans-206
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 字符串搜索
- en: A search method you might use during your digital forensic investigation is
    a string or byte search. This search technique is utilized when you have a keyword
    list of specific terms that you wish to search for. Most commercial and open-source
    forensic tools allow for string searches and will search the allocated, unallocated,
    and file slack spaces. You can use specific words, symbols, or strings of letters
    as the search criteria. Generally, you will want to have some predefined keyword
    lists before you start your digital forensic investigation.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的数字取证调查过程中，可能会使用字符串或字节搜索。这个搜索技术在你有一个特定的关键词列表时使用。大多数商业和开源的取证工具都允许进行字符串搜索，并会搜索分配区、未分配区和文件空闲区。你可以使用特定的单词、符号或字母组合作为搜索条件。一般来说，你会希望在开始数字取证调查之前，先准备一些预定义的关键词列表。
- en: 'Your keyword lists will fall into one of the following categories:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 你的关键词列表将属于以下类别之一：
- en: '**Generic keyword list**: This is a keyword list that you will use in every
    case. This list can also be further categorized by the subject of the investigation.
    For example, you may have one keyword list for digital forensic investigations
    into fraudulent activity and a different keyword list for digital forensic investigations
    into illicit images.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**通用关键词列表**：这是你在每个案件中都会使用的关键词列表。这个列表还可以根据调查的主题进一步分类。例如，你可能会有一个用于调查欺诈活动的数字取证案件的关键词列表，也有一个用于调查非法图像的数字取证案件的关键词列表。'
- en: '**Case-specific keyword list**: This is a keyword list that you will use for
    a specific digital forensic investigation. As you prepare to conduct your digital
    forensic investigation, you will identify keywords based on the participants,
    locations, and, sometimes, the slang used by the participants. For example, you
    could have keywords based on usernames, email addresses, physical addresses, phone
    numbers, credit card numbers, and more.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特定案件关键词列表**：这是你将在特定数字取证调查中使用的关键词列表。在你准备进行数字取证调查时，你将根据参与者、地点以及有时参与者使用的俚语来确定关键词。例如，你可以有基于用户名、电子邮件地址、物理地址、电话号码、信用卡号码等的关键词。'
- en: '**Note**'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '**备注**'
- en: You should avoid keyword terms that are generic or have additional meanings.
    For example, if you were investigating a homicide, the word “kill” seems to be
    a valid term to search for. Unfortunately, “kill” is also a term used in the programming
    language(s) you will find in a computer system. This will leave you with a large
    number of false positives. Ideally, the goal is to have the keyword list to help
    filter out non-pertinent data so that you can focus your efforts efficiently.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该避免使用那些通用的或具有其他含义的关键词。例如，如果你正在调查一起凶杀案，“kill”这个词看似是一个有效的搜索词。不幸的是，“kill”也是你在计算机系统中可能遇到的编程语言中的一个术语。这会导致大量的假阳性。理想情况下，目标是通过关键词列表帮助过滤掉无关数据，以便高效集中精力。
- en: 'You may encounter different encoding schemes as you are conducting your searches
    on forensic images, such as the following:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在你进行数字取证图像搜索时，可能会遇到不同的编码方案，例如以下几种：
- en: '**American Standard Code for Information Interchange** (**ASCII**) is a character-encoding
    scheme based initially on U.S. English and is limited to 256-character codes.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**美国信息交换标准代码** (**ASCII**) 是一种最初基于美国英语的字符编码方案，且限制为256个字符代码。'
- en: '**Unicode** was developed to overcome the limitations of ASCII. Each character
    has a unique 2-byte value resulting in the ability to define over 65,000 characters.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Unicode** 是为了克服ASCII的限制而开发的。每个字符都有一个独特的2字节值，从而能够定义超过65,000个字符。'
- en: While keyword searching can be very powerful, there is a downside to this, as
    it is very literal when searching for content based on the keyword. For example,
    if you search for a word, it will not find an alternative spelling; that is, if
    you are searching for `ally`, the filter will not find `alley`. Luckily, there
    is an alternative search methodology known as pattern matching/regular expressions.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管关键词搜索非常强大，但它也有一个缺点，因为在根据关键词搜索内容时，它是非常字面上的。例如，如果你搜索一个单词，它不会找到替代拼写；也就是说，如果你搜索`ally`，过滤器不会找到`alley`。幸运的是，还有一种替代的搜索方法，叫做模式匹配/正则表达式。
- en: 'A regular expression uses character strings to create a search pattern, and
    it will find all instances that match the pattern. Here are some common symbols
    and their meanings when used to create a regular expression:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 正则表达式使用字符字符串来创建搜索模式，并找到所有与该模式匹配的实例。以下是一些常用符号及其在创建正则表达式时的含义：
- en: '**The asterisk symbol (**`*`**)**: Match the preceding character(s) for `X`
    amount of times. For example, `ca*t` will cause positive hits for `ct`, `cat`,
    `caat`, and `caaat`.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**星号符号（**`*`**）**：匹配前面的字符（或字符集）重复 `X` 次。例如，`ca*t` 将返回匹配 `ct`、`cat`、`caat` 和
    `caaat` 的结果。'
- en: '**The pound sign (**`#`**)**: This will match a number (0-9).'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**井号（**`#`**）**：这将匹配一个数字（0-9）。'
- en: '**The backslash (**`\`**)**: The following character will be interpreted literally.
    `\.` will be construed as a period.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**反斜杠（**`\`**）**：接下来的字符将按字面意思解释。`\.` 将被解释为句点。'
- en: '**Caret (**`^`**)**: Match the start of the text. For example, `^123` will
    cause the positive hits to start with `123`.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**脱字符（**`^`**）**：匹配文本的开始。例如，`^123` 会使匹配的结果以 `123` 开头。'
- en: '**The dollar sign (**`$`**)**: Match the end of the text. For example, `123$`
    will cause positive hits to end with `123`.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**美元符号（**`$`**）**：匹配文本的结束。例如，`123$` 将导致匹配结果以 `123` 结尾。'
- en: '**Plus symbol (**`+`**)**: Repeat the preceding character(s) for one or more
    times. For example, `ca+t` will cause positive hits for `cat`, `caat`, and `caaat`.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**加号符号（**`+`**）**：重复前面的字符（或字符集）一次或多次。例如，`ca+t` 将返回匹配 `cat`、`caat` 和 `caaat`
    的结果。'
- en: '**Curly brackets** `{…}`: Repeat the preceding character(s) for `X` times (depending
    on the value in the bracket).'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**大括号（**`{…}`**）**：重复前面的字符（或字符集）`X` 次（取决于大括号中的值）。'
- en: '**Brackets** `[...]`: This will match a single character in the brackets. For
    example, `[b,c,d]` will match on b, c, or d.'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**方括号（**`[...]`**）**：这将匹配方括号中的任何单个字符。例如，`[b,c,d]` 将匹配 b、c 或 d。'
- en: '**Brackets w/ ^ [^...]**: This will match any single character not in the brackets.
    For example, `[^b,c,d]` will match any character other than b, c, or d.'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**方括号 w/ ^ [^...]**：这将匹配方括号中不包含的任何单个字符。例如，`[^b,c,d]` 将匹配除 b、c 或 d 以外的任何字符。'
- en: '**Brackets (range) [..-..]**: This will match any character within the given
    range. `[0-9]` will match any character from 0 to 9.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**方括号（范围）[..-..]**：这将匹配给定范围内的任何字符。`[0-9]` 将匹配从 0 到 9 的任何字符。'
- en: '**Dot** (`.`): The dot can take the place of any character.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**点号（**`.`**）**：点号可以代替任何字符。'
- en: '**Question mark (**`?`**)**: The preceding character may/may not be present.
    For example, `.e01?` will return `.e0(x)` values. `x` shows it may find any value
    after`.e0`.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**问号（**`?`**）**：前面的字符可能会出现也可能不会出现。例如，`.e01?` 将返回 `.e0(x)` 值。`x` 表示它可能会找到 `.e0`
    后的任何值。'
- en: '**Pipe (**`|`**)**: This matches any one-character set separated by the pipe
    (`|`) character. For example, `br(ead|ake|east)` will return matches for bread
    or brake or breast.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**管道符号（**`|`**）**：这匹配由管道符号（`|`）分隔的任何一个字符集。例如，`br(ead|ake|east)` 将返回匹配 `bread`
    或 `brake` 或 `breast` 的结果。'
- en: The following are some common examples of pattern matching that you may find
    helpful.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些常见的模式匹配示例，可能对你有所帮助。
- en: 'To search for an IP address, you can use the following regular expression:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 要搜索 IP 地址，你可以使用以下正则表达式：
- en: '[PRE12]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The `\d` specifies that the following will match on a digit (number). The curly
    brackets, `{1,3}`, indicate the number can be from one to three digits. `\.` specifies
    a search for the `.` character. The `\d{1,3}` pattern then repeats an additional
    three times until it has the value for an IPv4 address.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '`\d` 表示接下来的内容将匹配一个数字。大括号 `{1,3}` 表示数字可以是 1 到 3 位。`\.` 表示搜索 `.` 字符。`\d{1,3}`
    模式将重复三次，直到获得 IPv4 地址的值。'
- en: 'To search for a US phone number, you can use the following expression:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 要搜索美国电话号码，你可以使用以下表达式：
- en: '[PRE13]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The `\(` will match the open bracket. `\d{3}` will match on a three-digit number.
    `\)` will match on the closed bracket. This pattern will give you the area code,
    `(###)`, in this format. The remaining regular expression will give you the first
    three digits, `\d{3}`, the dash, `-`, and the final four digits, `\d{4}`, of the
    US phone number. If the phone number is not formatted as `(###) ###-####` or `###-###-####`,
    you will not get a hit.'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '`\(` 将匹配开括号。`\d{3}` 将匹配三位数。`\)` 将匹配闭括号。这个模式将给出区域代码 `(###)`，格式为 `(###)`。其余的正则表达式将提供前面三位数字
    `\d{3}`、破折号 `-` 和最后四位数字 `\d{4}`，这是美国电话号码的格式。如果电话号码不是按照 `(###) ###-####` 或 `###-###-####`
    格式提供的，你将无法得到匹配。'
- en: Regular expressions are a powerful tool, but they can also be very complicated
    to craft. I like to use the regular expression library (which can be found at
    [http://regexlib.com/Default.aspx](http://regexlib.com/Default.aspx)) to help
    me with my regular expression skills.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 正则表达式是一个强大的工具，但它们也可能非常复杂。我喜欢使用正则表达式库（可以在 [http://regexlib.com/Default.aspx](http://regexlib.com/Default.aspx)
    找到）来帮助我提升正则表达式技能。
- en: So, what happens when the user deletes a file or folder from the media? Let’s
    discuss what happens when a file or folder is deleted next.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，当用户从媒体中删除一个文件或文件夹时会发生什么呢？接下来我们来讨论当文件或文件夹被删除时会发生什么。
- en: Recovering deleted data
  id: totrans-240
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 恢复已删除的数据
- en: When a file is deleted in the FAT filesystem, the data itself does not get changed.
    The first character of the directory entry will have it changed to a `xE5` and
    the file allocation table entries are reset to `x00`. When the filesystem reads
    the directory entries, and it encounters the `xE5`, it will skip that entry and
    start reading from the subsequent entries.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 当文件在 FAT 文件系统中被删除时，数据本身并没有被改变。目录条目的第一个字符会被更改为`xE5`，并且文件分配表条目会被重置为`x00`。当文件系统读取目录条目时，如果遇到`xE5`，它将跳过该条目，并开始读取后续条目。
- en: 'To recover deleted files, we need to reverse the process the filesystem used
    to delete the files. Remember, it has not changed the file contents; they still
    physically reside in their assigned clusters. We now need to reverse-engineer
    the deletion and recreate the file entry and the entries in the file allocation
    table. To do this, we need to find the first cluster of the file, the size of
    the file, and the size of the clusters in the volume:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 要恢复已删除的文件，我们需要逆转文件系统删除文件的过程。记住，它并没有改变文件内容；它们仍然物理存在于它们分配的簇中。现在我们需要逆向工程删除操作，并重新创建文件条目和文件分配表中的条目。为此，我们需要找到文件的第一个簇、文件的大小以及卷中簇的大小：
- en: '![](img/B18329_05_16.png)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18329_05_16.png)'
- en: 'Figure 5.15: Deleted entry'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.15：已删除的条目
- en: In the preceding screenshot, we have a directory entry showing that a file has
    been deleted. We see the `xE5` at the start of the directory entry. (This will
    require the use of a hex editor to make the changes.) Then, we have to determine
    the starting cluster, `x00 x08` (which is shown as `x08 x00`), which is cluster
    number `8`. To determine the file size, look at the last four bytes (remember
    that the FAT filesystem stores data in little-endian format, which means that
    the least-significant byte is on the left, so we would read that value as `x00
    x00 x00 x27`, not as it is displayed, `x27 x00 x00 x00`), and when we convert
    the hexadecimal value to a decimal, we get the value of 39 bytes for the file
    size.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的截图中，我们有一个目录条目，显示一个文件已被删除。我们看到目录条目开头的`xE5`。（这需要使用十六进制编辑器进行修改。）接下来，我们必须确定起始簇，`x00
    x08`（显示为`x08 x00`），即簇号`8`。要确定文件大小，请查看最后四个字节（记住，FAT 文件系统以小端格式存储数据，这意味着最不重要的字节在左侧，因此我们读取的值是`x00
    x00 x00 x27`，而不是显示的`x27 x00 x00 x00`），当我们将十六进制值转换为十进制时，得到文件大小为 39 字节。
- en: 'Now we have to determine how many sectors make up a cluster and what the sector
    size is. You will need to go to the boot record to get that information. The boot
    record shows that there are 512 bytes per sector, and there are 8 sectors per
    cluster, which gives us a cluster size of 4,096 bytes:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要确定一个簇由多少个扇区组成以及每个扇区的大小。你需要查看引导记录以获取这些信息。引导记录显示每个扇区有 512 字节，每个簇有 8 个扇区，这意味着簇大小为
    4,096 字节：
- en: '![](img/B18329_05_17.png)'
  id: totrans-247
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18329_05_17.png)'
- en: 'Figure 5.16: Boot record'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.16：引导记录
- en: 'This means that our file will only occupy a single cluster. We then go to the
    file allocation table and look at the entry for cluster 8 and see that it is zeroed
    out:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们的文件只占用一个簇。接下来，我们查看文件分配表，并查看簇号 8 的条目，发现它已被清零：
- en: '![](img/B18329_05_18.png)'
  id: totrans-250
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18329_05_18.png)'
- en: 'Figure 5.17: Deleted FAT'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.17：已删除的 FAT
- en: 'To recover the deleted file, perform the following steps:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 要恢复已删除的文件，请执行以下步骤：
- en: You need to change the entry in the file allocation table from `x0000 x0000`
    to `xFFFF FFF8` or `xFFFF FF0F`. If this were a larger file, you would need to
    change the file allocation table entry to point to the next cluster until you
    reach the cluster that contains the end of the file. Should you find an entry
    marked as allocated before you reach the end of the file, you may be dealing with
    a fragmented file. Another possibility is when the clusters were made available
    for use when the file was deleted, the data from a new file was placed in the
    available space. This would cause the old data to be overwritten with the data
    from the new file.
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你需要将文件分配表中的条目从`x0000 x0000`更改为`xFFFF FFF8`或`xFFFF FF0F`。如果这是一个较大的文件，你需要将文件分配表条目更改为指向下一个簇，直到你到达包含文件末尾的簇。如果你在到达文件末尾之前找到标记为已分配的条目，可能是你在处理一个碎片化的文件。另一种可能性是，在文件被删除时，簇被释放，新的文件数据被放置在这些可用空间中，这样就会导致旧数据被新文件的数据覆盖。
- en: The next step is to go back to the directory entry and replace `xE5` with another
    character. When replacing the `xE5` character of the filename in the directory
    entry, be careful not to guess what the character is. If you select an incorrect
    character, you could change the meaning or create a bias with the new filename,
    and that would be improper.
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是返回目录条目并将`xE5`替换为另一个字符。在替换目录条目中文件名的`xE5`字符时，要小心不要猜测字符是什么。如果选择了错误的字符，可能会改变其含义或使新文件名产生偏差，这样是不正确的。
- en: I recommend that when you recover a deleted file, you replace that first character
    with an underscore or a dash so there is no misunderstanding about the filename.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 我建议在恢复删除的文件时，将第一个字符替换为下划线或破折号，以避免对文件名的误解。
- en: When recovering a file with a long filename, it is important to relink the long
    filename to the short filename. This is because when the additional directories
    are created to accommodate the long filename, the system creates a checksum based
    on the data of the short filename. When you changed the `xE5` value on the short
    filename entry, you also want to use the same replacement character for the subsequent
    `xE5` entries for the long filename directory entries. The reason for linking
    the long filename to the short filename is that the short filename directory entry
    contains information such as the date and times, the starting cluster, and the
    file size.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 在恢复长文件名的文件时，重要的是要将长文件名与短文件名重新链接。这是因为当为适应长文件名而创建附加目录时，系统会基于短文件名的数据生成校验和。当你更改了短文件名条目的`xE5`值时，你还需要为长文件名目录条目的后续`xE5`条目使用相同的替换字符。将长文件名与短文件名链接的原因是，短文件名目录条目包含诸如日期和时间、起始簇和文件大小等信息。
- en: As we discussed in *Chapter 4*, *Computer Systems**,* when a file/directory
    is created on an NTFS volume, the system creates an entry in the `$MFT` file.
    The MFT record will contain the metadata about the file/directory; if the contents
    of the file are non-resident, then the `$Bitmap` file will be updated to show
    the clusters occupied by the file are allocated.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在*第4章*中讨论的，*《计算机系统》*，当在 NTFS 卷上创建文件/目录时，系统会在`$MFT`文件中创建一个条目。MFT 记录将包含关于文件/目录的元数据；如果文件内容是非驻留的，那么`$Bitmap`文件将更新，显示文件占用的簇已被分配。
- en: When a file/directory is deleted, then the sequence count in the MFT file record’s
    header is incremented by one digit. The allocation status for the record will
    change from allocated to unallocated. If the file data is non-resident, the system
    will update the `$Bitmap` file to show the clusters occupied by the file are now
    unallocated.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 当文件/目录被删除时，MFT 文件记录头中的序列计数会增加一位。记录的分配状态将从已分配更改为未分配。如果文件数据是非驻留的，系统会更新`$Bitmap`文件，显示文件占用的簇现在是未分配的。
- en: Every MFT file entry will start with the file signature of the file, which you
    can use as a search term to locate MFT file entries in unallocated space. Until
    the clusters containing the data on the disk are overwritten, we can recover the
    data.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 每个 MFT 文件条目将以文件的文件签名开始，你可以使用它作为搜索词，在未分配空间中定位 MFT 文件条目。直到磁盘上包含数据的簇被覆盖，我们才能恢复数据。
- en: If the MFT file record is unused, then you can reverse the steps and recover
    the file. You can decipher the file record, as we discussed in *Chapter 4*, *Computer
    Systems*. If the file is resident within the file record, you will recover the
    data when you retrieve the MFT file record. If the data is non-resident, then
    you will have to decipher the MFT file record to determine whether the data runs
    and identify the occupied clusters.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 MFT 文件记录未使用，则可以反向操作并恢复该文件。您可以解密文件记录，如我们在*第4章*，*计算机系统*中讨论的那样。如果文件存在于文件记录中，当您恢复
    MFT 文件记录时，将恢复数据。如果数据是非驻留的，那么您将需要解密 MFT 文件记录，以确定数据是否连续并识别占用的簇。
- en: If the system has overwritten the MFT file record, then you cannot recover the
    deleted MFT file record data or any resident data. You may recover the non-resident
    data, but that will depend on the size of the files and the fragmentation. Once
    the MFT record has been overwritten, you will lose any information regarding the
    data runs and which clusters contain the data.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 如果系统已覆盖 MFT 文件记录，则无法恢复已删除的 MFT 文件记录数据或任何驻留数据。您可能可以恢复非驻留数据，但这取决于文件的大小和碎片化程度。一旦
    MFT 记录被覆盖，您将失去有关数据运行和哪些簇包含数据的任何信息。
- en: Summary
  id: totrans-262
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we discussed, in detail, timeline creation and timeline analysis
    with open-source and commercial forensic tools. We took an in-depth look at utilizing
    the commercial forensic tool, X-Ways Forensics, and the open-source plaso framework
    for `log2timeline`. We also touched upon using the kitchen sink approach or a
    targeted examination of the dataset. Remember, we are not analyzing the contents
    of files, just the timelines associated with the files and other events within
    the operating system and filesystems.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们详细讨论了使用开源和商业取证工具进行时间线创建和时间线分析。我们深入探讨了利用商业取证工具 X-Ways Forensics 和开源 plaso
    框架进行`log2timeline`的使用。我们还提到使用“厨房水槽法”或针对数据集的定向检查。记住，我们不是分析文件的内容，而是分析与文件和操作系统及文件系统内的其他事件相关的时间线。
- en: In the next chapter, we will discuss the contents of files, specifically, Windows
    artifacts.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将讨论文件的内容，具体来说，是 Windows 工件。
- en: Questions
  id: totrans-265
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: It is important for the examiner to know the time zone in which the evidence
    was collected.
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对考察员来说，了解证据收集时的时区非常重要。
- en: 'True'
  id: totrans-267
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 正确
- en: 'False'
  id: totrans-268
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 错误
- en: You can do timeline analysis with X-Way Forensics when you create a(n) ______
    list.
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在创建_________列表时，您可以使用 X-Way Forensics 进行时间线分析。
- en: Timeline
  id: totrans-270
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 时间线
- en: Date/time
  id: totrans-271
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 日期/时间
- en: Event
  id: totrans-272
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 事件
- en: Party
  id: totrans-273
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 方
- en: Plaso is a framework for how many tools?
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Plaso 是一个包含多少个工具的框架？
- en: One
  id: totrans-275
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一
- en: Three
  id: totrans-276
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 三
- en: Five
  id: totrans-277
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 五
- en: Seven
  id: totrans-278
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 七
- en: '`pinfo` will give you what information?'
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`pinfo`会给你提供什么信息？'
- en: Information about the examiner
  id: totrans-280
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 考察员信息
- en: Information about the database file
  id: totrans-281
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据库文件信息
- en: Information about the forensic machine
  id: totrans-282
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 取证机器信息
- en: Information about the suspect
  id: totrans-283
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 嫌疑人信息
- en: '`log2timeline` is a ___________ -based tool.'
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`log2timeline`是一个基于___________的工具。'
- en: CLI
  id: totrans-285
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: CLI
- en: GUI
  id: totrans-286
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: GUI
- en: VFD
  id: totrans-287
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: VFD
- en: XYZ
  id: totrans-288
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: XYZ
- en: '`psort` will give you the ___________.'
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`psort`将给你___________。'
- en: Ability to sort
  id: totrans-290
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 排序能力
- en: Ability to filter
  id: totrans-291
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 过滤能力
- en: Ability to connect
  id: totrans-292
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 连接能力
- en: All of the above
  id: totrans-293
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以上所有
- en: You can do a timeline analysis with an Excel spreadsheet.
  id: totrans-294
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您可以使用 Excel 电子表格进行时间线分析。
- en: 'True'
  id: totrans-295
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 正确
- en: 'False'
  id: totrans-296
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 错误
- en: Further reading
  id: totrans-297
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'You can refer to the following links for more information on the topics covered
    in this chapter:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以参考以下链接，获取更多关于本章内容的信息：
- en: '*T. P. P. A. (2019, July 8). Plaso Documentation. Retrieved from The Plaso
    Project*: [https://buildmedia.readthedocs.org/media/pdf/plaso/latest/plaso.pdf](https://buildmedia.readthedocs.org/media/pdf/plaso/latest/plaso.pdf)'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*T. P. P. A. (2019年7月8日). Plaso文档. 取自Plaso项目*: [https://buildmedia.readthedocs.org/media/pdf/plaso/latest/plaso.pdf](https://buildmedia.readthedocs.org/media/pdf/plaso/latest/plaso.pdf)'
- en: '*Carvey, H. (2014). Windows forensic analysis toolkit: Advanced analysis techniques
    for Windows 8; Waltham, MA: Syngress*. Available at: [https://www.abebooks.com/servlet/SearchResults?sts=t&cm_sp=SearchF-_-home-_-Results&an=&tn=Windows+forensic+analysis+toolkit&kn=&isbn=](https://www.abebooks.com/servlet/SearchResults?sts=t&cm_sp=SearchF-_-home-_-Results&an=&tn=Windows+forensic+analysis+toolkit&kn=&isbn=
    )'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Carvey, H. (2014). Windows 取证分析工具包：针对 Windows 8 的高级分析技术；马萨诸塞州沃尔瑟姆：Syngress*.
    可在以下网址获取：[https://www.abebooks.com/servlet/SearchResults?sts=t&cm_sp=SearchF-_-home-_-Results&an=&tn=Windows+forensic+analysis+toolkit&kn=&isbn=](https://www.abebooks.com/servlet/SearchResults?sts=t&cm_sp=SearchF-_-home-_-Results&an=&tn=Windows+forensic+analysis+toolkit&kn=&isbn=
    )'
- en: Exercise
  id: totrans-301
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 练习
- en: Data set
  id: totrans-302
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据集
- en: '`Chapter 5 Emails.xlsx`'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: '`Chapter 5 Emails.xlsx`'
- en: '`Chapter 5 Carving.dd`'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: '`Chapter 5 Carving.dd`'
- en: Software needed
  id: totrans-305
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 所需软件
- en: Timeline Explorer - [https://ericzimmerman.github.io/#!index.md](https://ericzimmerman.github.io/#!index.md)
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 时间线探索器 - [https://ericzimmerman.github.io/#!index.md](https://ericzimmerman.github.io/#!index.md)
- en: Microsoft .NET 6 or newer is required. You will get errors without at least
    .NET 6\. When in doubt, install it! Make sure you get the **Desktop** runtime
    if you plan on running any of the GUI programs.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 需要Microsoft .NET 6或更高版本。如果没有至少.NET 6，您会遇到错误。若有疑问，请安装它！如果计划运行任何GUI程序，请确保安装**桌面**运行时。
- en: Autopsy - [https://www.autopsy.com/](https://www.autopsy.com/)
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: Autopsy - [https://www.autopsy.com/](https://www.autopsy.com/)
- en: Email exercise
  id: totrans-309
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 邮件练习
- en: An individual outside of m57.biz purchased a laptop from Craigslist. The laptop
    the individual purchased contained child pornography and they decided to inform
    the police about it.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 一名m57.biz外部人员从Craigslist购买了一台笔记本电脑。这台笔记本电脑包含儿童色情内容，该人员决定向警方报告。
- en: Investigators were able to trace the laptop back to m57.biz. When the police
    contacted the CEO of m57.biz, the CEO reported that the laptop, as well as other
    items, had been stolen from the m57 inventory.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 调查人员能够追踪到这台笔记本电脑属于m57.biz。当警方联系m57.biz的CEO时，CEO报告称该笔记本电脑以及其他物品已从m57的库存中被盗。
- en: The m57 CEO gave consent for the police investigators to search m57.biz and
    image all of the m57.biz computers, company phones, as well as USB drives.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: m57的CEO同意让警方调查员搜索m57.biz并对所有m57.biz电脑、公司电话及USB驱动器进行成像。
- en: Analyze the emails found in the `Chapter 5 emails.xlsx` spreadsheet and identify
    potential suspects and a timeline of their activity.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 分析在`Chapter 5 emails.xlsx`电子表格中找到的电子邮件，识别潜在嫌疑人及其活动时间线。
- en: Data carving exercise
  id: totrans-314
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据切割练习
- en: Load Autopsy and start a new case.
  id: totrans-315
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动Autopsy并开始一个新案件。
- en: Select **Disk Image** or **VM file** for the data source.
  id: totrans-316
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择**磁盘映像**或**虚拟机文件**作为数据源。
- en: 'Navigate to the folder where you stored the image `Chapter 5 Carving.dd`. Select
    only the following Ingest Modules:'
  id: totrans-317
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到存储图像`Chapter 5 Carving.dd`的文件夹。仅选择以下导入模块：
- en: PhotoRec Carver Embedded File Extractor
  id: totrans-318
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: PhotoRec Carver 嵌入式文件提取器
- en: From the drop-down menu, select **All files**, **Directory**, and **Unallocated
    Space**.
  id: totrans-319
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从下拉菜单中选择**所有文件**、**目录**和**未分配空间**。
- en: Analyze the results.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 分析结果。
- en: Join our community on Discord
  id: totrans-321
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们社区的Discord
- en: 'Join our community’s Discord space for discussions with the author and other
    readers:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们社区的Discord空间，与作者和其他读者进行讨论：
- en: '[https://packt.link/CyberSec](https://packt.link/CyberSec)'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/CyberSec](https://packt.link/CyberSec)'
- en: '![](img/QR_Code3852467292877112093.png)'
  id: totrans-324
  prefs: []
  type: TYPE_IMG
  zh: '![](img/QR_Code3852467292877112093.png)'
