- en: Automatic Intrusion Detection
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动入侵检测
- en: An intrusion detection system monitors a network or a collection of systems
    for malicious activity or policy violations. Any malicious activity or violation
    caught is stopped or reported. In this chapter, we will design and implement several
    intrusion detection systems using machine learning. We will begin with the classical
    problem of detecting spam email. We will then move on to classifying malicious
    URLs. We will take a brief detour to explain how to capture network traffic, so
    that we may tackle more challenging network problems, such as botnet and DDoS
    detection. We will construct a classifier for insider threats. Finally, we will
    address the example-dependent, cost-sensitive, radically imbalanced, and challenging
    problem of credit card fraud.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 入侵检测系统监控网络或一组系统，以发现恶意活动或政策违规行为。任何被捕获的恶意活动或违规行为都将被阻止或报告。在本章中，我们将设计并实现几个使用机器学习的入侵检测系统。我们将从检测垃圾邮件这一经典问题开始。然后我们将转向分类恶意URL。接下来，我们将简要介绍如何捕获网络流量，以便解决更具挑战性的网络问题，如僵尸网络和DDoS检测。我们将构建一个针对内部威胁的分类器。最后，我们将解决信用卡欺诈这一依赖示例、成本敏感、极度不平衡且具有挑战性的问题。
- en: 'This chapter contains the following recipes:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章包含以下内容：
- en: Spam filtering using machine learning
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用机器学习进行垃圾邮件过滤
- en: Phishing URL detection
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络钓鱼URL检测
- en: Capturing network traffic
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 捕获网络流量
- en: Network behavior anomaly detection
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络行为异常检测
- en: Botnet traffic detection
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 僵尸网络流量检测
- en: Feature engineering for insider threat detection
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内部威胁检测的特征工程
- en: Employing anomaly detection for insider threats
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用异常检测进行内部威胁检测
- en: Detecting DDoS
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检测DDoS攻击
- en: Credit card fraud detection
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 信用卡欺诈检测
- en: Counterfeit bank note detection
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 伪造银行票据检测
- en: Ad blocking using machine learning
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用机器学习进行广告拦截
- en: Wireless indoor localization
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无线室内定位
- en: Technical requirements
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'The following are the technical prerequisites for this chapter:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的技术前提如下：
- en: Wireshark
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wireshark
- en: PyShark
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyShark
- en: costcla
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: costcla
- en: scikit-learn
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: scikit-learn
- en: pandas
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: pandas
- en: NumPy
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NumPy
- en: Code and datasets may be found at [https://github.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/tree/master/Chapter06](https://github.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/tree/master/Chapter06).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 代码和数据集可以在[https://github.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/tree/master/Chapter06](https://github.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/tree/master/Chapter06)找到。
- en: Spam filtering using machine learning
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用机器学习进行垃圾邮件过滤
- en: Spam mails (unwanted mails) constitute around 60% of global email traffic. Aside
    from the fact that spam detection software has progressed since the first spam
    message in 1978, anyone with an email account knows that spam continues to be
    a time-consuming and expensive problem. Here, we provide a recipe for spam-ham
    (non-spam) classification using machine learning.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 垃圾邮件（不需要的邮件）约占全球电子邮件流量的60%。除了自1978年首次垃圾邮件出现以来，垃圾邮件检测软件取得的进展外，任何拥有电子邮件帐户的人都知道，垃圾邮件仍然是一个费时且昂贵的问题。在这里，我们提供一个使用机器学习进行垃圾邮件-非垃圾邮件（ham）分类的配方。
- en: Getting ready
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: 'Preparation for this recipe involves installing the `scikit-learn` package
    in `pip`. The command is as follows:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 为本配方的准备工作包括通过`pip`安装`scikit-learn`包。命令如下：
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In addition, extract `spamassassin-public-corpus.7z` into a folder named `spamassassin-public-corpus`.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，将`spamassassin-public-corpus.7z`解压到名为`spamassassin-public-corpus`的文件夹中。
- en: How to do it...
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何实现...
- en: 'In the following steps, we build a classifier for wanted and unwanted email:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下步骤中，我们构建一个用于分类垃圾邮件和非垃圾邮件的分类器：
- en: Unzip the `spamassassin-public-corpus.7z` dataset.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解压`spamassassin-public-corpus.7z`数据集。
- en: 'Specify the path of your `spam` and `ham` directories:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指定`spam`和`ham`目录的路径：
- en: '[PRE1]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Create labels for the two classes and read the emails into a corpus:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为两个类别创建标签并将电子邮件读取到语料库中：
- en: '[PRE2]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Train-test split the dataset:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对数据集进行训练-测试拆分：
- en: '[PRE3]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Train an NLP pipeline on the training data:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练数据上训练NLP管道：
- en: '[PRE4]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Evaluate the classifier on the testing data:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在测试数据上评估分类器：
- en: '[PRE5]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The following is the output:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是输出结果：
- en: '[PRE6]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: How it works…
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: We start by preparing a dataset consisting of raw emails (*Step 1*), which the
    reader can examine by looking at the dataset. In *Step 2*, we specify the paths
    of the spam and ham emails, as well as assign labels to their directories. We
    proceed to read all of the emails into an array, and create a labels array in
    *Step 3*. Next, we train-test split our dataset (*Step 4*), and then fit an NLP
    pipeline on it in *Step 5*. Finally, in *Step 6*, we test our pipeline. We see
    that accuracy is pretty high. Since the dataset is relatively balanced, there
    is no need to use special metrics to evaluate success.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先准备一个包含原始邮件的数据集（*步骤1*），读者可以通过查看数据集来进行检查。在*步骤2*中，我们指定垃圾邮件和正常邮件的路径，并为它们的目录分配标签。接着，我们将在*步骤3*中读取所有邮件到一个数组中，并创建一个标签数组。接下来，我们将数据集进行训练-测试拆分（*步骤4*），然后在*步骤5*中为其拟合一个NLP管道。最后，在*步骤6*中，我们测试我们的管道。我们发现准确率相当高。由于数据集相对平衡，因此无需使用特殊的评估指标来评估成功。
- en: Phishing URL detection
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 钓鱼URL检测
- en: A phishing website is a website that tries to obtain your account password or
    other personal information by making you think that you are on a legitimate website.
    Some phishing URLs differ from the intended URL in a single character specially
    chosen to increase the odds of a typo, while others utilize other channels to
    generate traffic.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 钓鱼网站是通过让你认为自己在一个合法网站上，从而试图获取你的账户密码或其他个人信息的网站。一些钓鱼URL与目标URL只有一个字符不同，这个字符特别选择以增加拼写错误的几率，而其他一些则利用其他渠道来生成流量。
- en: 'Here is an example of a phishing website attempting to obtain a user''s email
    address by pressuring a user into believing that their email will be shut down:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个钓鱼网站的示例，该网站通过让用户相信他们的电子邮件将被关闭，从而迫使用户提供电子邮件地址：
- en: '![](assets/a1e670df-c239-4c89-b24c-7251a90549ea.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/a1e670df-c239-4c89-b24c-7251a90549ea.png)'
- en: Since phishing is one of the most successful modes of attack, it is crucial
    to be able to identify when a URL is not legitimate. In this recipe, we will build
    a machine learning model to detect phishing URLs.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 由于钓鱼是最成功的攻击方式之一，因此能够识别URL是否合法至关重要。在本食谱中，我们将构建一个机器学习模型来检测钓鱼URL。
- en: Getting ready
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Preparation for this recipe involves installing `scikit-learn` and `pandas`
    in `pip`. The command is as follows:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 本食谱的准备工作包括在`pip`中安装`scikit-learn`和`pandas`。命令如下：
- en: '[PRE7]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: In addition, extract the archive named `phishing-dataset.7z`.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，提取名为`phishing-dataset.7z`的压缩文件。
- en: How to do it…
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何进行...
- en: In the following steps, we will read in a featurized dataset of URLs and train
    a classifier on it.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的步骤中，我们将读取一个特征化的URL数据集，并对其进行分类器训练。
- en: Download the phishing dataset from this chapter's directory.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从本章节的目录下载钓鱼数据集。
- en: 'Read in the training and testing data using `pandas`:'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`pandas`读取训练和测试数据：
- en: '[PRE8]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Prepare the labels of the phishing web pages:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准备钓鱼网页的标签：
- en: '[PRE9]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Prepare the features:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准备特征：
- en: '[PRE10]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Train, test, and assess a classifier:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练、测试和评估分类器：
- en: '[PRE11]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The following is the output:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是输出：
- en: '[PRE12]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: How it works…
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何工作...
- en: 'We begin by downloading the dataset, and then reading it into data frames (*Steps
    1* and *2*) for convenient examination and manipulation. Moving on, we place the
    dataset into arrays in preparation for machine learning (*Steps 3* and *4*). The
    dataset consists of several thousand feature vectors for phishing URLs. There
    are 30 features, whose names and values are tabulated here:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先下载数据集，然后将其读取到数据框中（*步骤1*和*步骤2*），以方便检查和操作。接下来，我们将数据集放入数组中，为机器学习做准备（*步骤3*和*步骤4*）。该数据集包含了数千个钓鱼URL的特征向量。这里列出了30个特征的名称和值：
- en: '| Attributes | Values | Column name |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| 属性 | 值 | 列名 |'
- en: '| Having an IP address | { 1,0 } | `has_ip` |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| 是否具有IP地址 | { 1,0 } | `has_ip` |'
- en: '| Having a long URL | { 1,0,-1 } | `long_url` |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| 是否具有长URL | { 1,0,-1 } | `long_url` |'
- en: '| Uses Shortening Service | { 0,1 } | `short_service` |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| 是否使用缩短服务 | { 0,1 } | `short_service` |'
- en: '| Having the ''@'' symbol | { 0,1 } | `has_at` |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| 是否具有''@''符号 | { 0,1 } | `has_at` |'
- en: '| Double slash redirecting | { 0,1 } | `double_slash_redirect` |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| 是否双斜杠重定向 | { 0,1 } | `double_slash_redirect` |'
- en: '| Having a prefix and suffix | { -1,0,1 } | `pref_suf` |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| 是否具有前后缀 | { -1,0,1 } | `pref_suf` |'
- en: '| Having a subdomain | { -1,0,1 } | `has_sub_domain` |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| 是否具有子域名 | { -1,0,1 } | `has_sub_domain` |'
- en: '| SSLfinal state | { -1,1,0 } | `ssl_state` |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| SSL最终状态 | { -1,1,0 } | `ssl_state` |'
- en: '| Domain registration length | { 0,1,-1 } | `long_domain` |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| 域名注册长度 | { 0,1,-1 } | `long_domain` |'
- en: '| Favicon | { 0,1 } | `favicon` |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| 网站图标 | { 0,1 } | `favicon` |'
- en: '| Is a standard port | { 0,1 } | `port` |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| 是否为标准端口 | { 0,1 } | `port` |'
- en: '| Uses HTTPS tokens | { 0,1 } | `https_token` |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| 是否使用HTTPS令牌 | { 0,1 } | `https_token` |'
- en: '| Request_URL | { 1,-1 } | `req_url` |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 请求 URL | { 1,-1 } | `req_url` |'
- en: '| Abnormal URL anchor | { -1,0,1 } | `url_of_anchor` |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| 异常 URL 锚点 | { -1,0,1 } | `url_of_anchor` |'
- en: '| Links_in_tags | { 1,-1,0 } | `tag_links` |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| 标签中的链接 | { 1,-1,0 } | `tag_links` |'
- en: '| SFH | { -1,1 } | `SFH` |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| SFH | { -1,1 } | `SFH` |'
- en: '| Submitting to email | { 1,0 } | `submit_to_email` |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 提交到邮件 | { 1,0 } | `submit_to_email` |'
- en: '| Abnormal URL | { 1,0 } | `abnormal_url` |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 异常 URL | { 1,0 } | `abnormal_url` |'
- en: '| Redirect | { 0,1 } | `redirect` |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 重定向 | { 0,1 } | `redirect` |'
- en: '| On mouseover | { 0,1 } | `mouseover` |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| 鼠标悬停 | { 0,1 } | `mouseover` |'
- en: '| Right-click | { 0,1 } | `right_click` |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 右键点击 | { 0,1 } | `right_click` |'
- en: '| Pop-up window | { 0,1 } | `popup` |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| 弹出窗口 | { 0,1 } | `popup` |'
- en: '| Iframe | { 0,1 } | `iframe` |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| 内嵌框架 | { 0,1 } | `iframe` |'
- en: '| Age of domain | { -1,0,1 } | `domain_age` |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| 域名年龄 | { -1,0,1 } | `domain_age` |'
- en: '| DNS record | { 1,0 } | `dns_record` |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| DNS 记录 | { 1,0 } | `dns_record` |'
- en: '| Web traffic | { -1,0,1 } | `traffic` |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| 网络流量 | { -1,0,1 } | `traffic` |'
- en: '| Page rank | { -1,0,1 } | `page_rank` |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| 页面排名 | { -1,0,1 } | `page_rank` |'
- en: '| Google index | { 0,1 } | `google_index` |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| Google 索引 | { 0,1 } | `google_index` |'
- en: '| Links pointing to page | { 1,0,-1 } | `links_to_page` |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| 指向页面的链接 | { 1,0,-1 } | `links_to_page` |'
- en: '| Statistical report | { 1,0 } | `stats_report` |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| 统计报告 | { 1,0 } | `stats_report` |'
- en: '| Result | { 1,-1 } | `target` |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| 结果 | { 1,-1 } | `target` |'
- en: In *Step 5*, we train and test a random forest classifier. The accuracy is pretty
    high, but depending on how balanced the dataset is, it might be necessary to consider
    an FP constraint. There are many ways to expand upon such a detector, such as
    by adding other features and growing the dataset. Given that most websites contain
    some images, an image classifier is just one way in which the model may improve
    its results.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *步骤 5* 中，我们训练并测试一个随机森林分类器。准确度相当高，但根据数据集的平衡情况，可能需要考虑 FP 约束。有许多方法可以扩展此类检测器，例如添加其他特征并扩大数据集。由于大多数网站包含一些图片，图像分类器只是模型改进结果的一种方式。
- en: Capturing network traffic
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 捕获网络流量
- en: Capturing network traffic is important for troubleshooting, analysis, and software
    and communications protocol development. For the security-minded individual, monitoring
    network traffic is crucial for detecting malicious activity or policy violation.
    In this recipe, we will demonstrate how to capture and inspect network traffic.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 捕获网络流量对于故障排除、分析、软件和通信协议开发非常重要。对于关注安全的个人来说，监控网络流量是检测恶意活动或政策违规的关键。在本教程中，我们将演示如何捕获和检查网络流量。
- en: Getting ready
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: 'In preparation for this recipe, observe the following steps:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 为了准备此教程，请遵循以下步骤：
- en: 'Install `pyshark`:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装 `pyshark`：
- en: '[PRE13]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Install `wireshark`. The latest version can be found at [https://www.wireshark.org/download.html](https://www.wireshark.org/download.html).
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装 `wireshark`。最新版本可以在 [https://www.wireshark.org/download.html](https://www.wireshark.org/download.html)
    找到。
- en: How to do it…
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作……
- en: In the following steps, we utilize a Python library named PyShark, along with
    Wireshark, to capture and examine network traffic.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的步骤中，我们将使用一个名为 PyShark 的 Python 库，并结合 Wireshark 捕获和检查网络流量。
- en: 'You must add `tshark` to PyShark''s configuration path. Tshark is a command-line
    variant of Wireshark. To do this, run the following command:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你必须将 `tshark` 添加到 PyShark 的配置路径中。Tshark 是 Wireshark 的命令行版本。为此，运行以下命令：
- en: '[PRE14]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Note the location of the package. In the `pyshark` directory in this location,
    find the file, `config.ini`. Edit `tshark_path` to the location of `tshark` inside
    your `wireshark` installation folder. Similarly, edit `dumpcap_path` to the location
    of `dumpcap` inside your `wireshark` installation folder.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意数据包的位置。在该位置的 `pyshark` 目录中，找到文件 `config.ini`。编辑 `tshark_path` 为 `wireshark`
    安装文件夹内 `tshark` 的路径。同样，编辑 `dumpcap_path` 为 `wireshark` 安装文件夹内 `dumpcap` 的路径。
- en: '*Steps 2* and *4* should be executed in a Python environment. Note that, as
    of the current version, `pyshark` may have some bugs when run in a Jupyter notebook.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤 2* 和 *步骤 4* 应在 Python 环境中执行。请注意，在当前版本中，`pyshark` 在 Jupyter notebook 中运行时可能存在一些
    bug。'
- en: 'Import `pyshark` and specify the duration of the capture:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 `pyshark` 并指定捕获的持续时间：
- en: '[PRE15]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Specify the name of the file to output the capture, `to`:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指定文件名以输出捕获内容，`to`：
- en: '[PRE16]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Capture network traffic:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 捕获网络流量：
- en: '[PRE17]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'To examine the capture, open the `pcap` file in Wireshark:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要检查捕获内容，请在 Wireshark 中打开 `pcap` 文件：
- en: '![](assets/f1bee8ed-2b47-411b-a417-3af9f6829a1d.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/f1bee8ed-2b47-411b-a417-3af9f6829a1d.png)'
- en: How it works…
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理……
- en: We start this recipe by configuring `tshark`, the command-line variant of Wireshark.
    Once we are finished configuring `tshark`, it is now accessible through `pyshark`.
    We import `pyshark` and specify the duration of the network capture (*Step 2*).
    Captured network traffic data can be overwhelming in size, so it is important
    to control the duration. Next, we specify the name of the output capture in a
    way that makes it unique and easily understandable (*Step 3*), and then, in *Step
    4*, we proceed to capture traffic. Finally, in *Step 6*, we employ Wireshark for
    its GUI to examine the captured network traffic. In able hands, such network traffic
    facilitates the detection of insecure IoT devices, misconfigurations, anomalous
    events, hacking attempts, and even data exfiltration.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从配置` tshark`（Wireshark的命令行版本）开始。完成配置后，可以通过`pyshark`进行访问。我们导入`pyshark`并指定网络捕获的持续时间（*步骤2*）。由于捕获的网络流量数据可能非常庞大，因此控制持续时间很重要。接下来，我们指定输出捕获的名称，使其既唯一又容易理解（*步骤3*），然后在*步骤4*中，开始捕获流量。最后，在*步骤6*中，我们使用Wireshark的图形界面来检查捕获的网络流量。在熟练的操作下，这样的网络流量有助于检测不安全的物联网设备、配置错误、异常事件、黑客攻击尝试，甚至数据泄露。
- en: Network behavior anomaly detection
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 网络行为异常检测
- en: '**Network behavior anomaly detection** (**NBAD**) is the continuous monitoring
    of a network for unusual events or trends. Ideally, an NBAD program tracks critical
    network characteristics in real time and generates an alarm if a strange event
    or trend is detected that indicates a threat. In this recipe, we will build an
    NBAD using machine learning.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '**网络行为异常检测**（**NBAD**）是对网络进行连续监控，寻找不寻常的事件或趋势。理想情况下，NBAD程序实时跟踪关键网络特征，并在检测到表明威胁的奇异事件或趋势时生成警报。在本教程中，我们将使用机器学习构建一个NBAD。'
- en: The dataset used is a modified subset from a famous dataset known as the KDD
    dataset, and is a standard set for testing and constructing IDS systems. This
    dataset contains a wide variety of intrusions simulated in a military network
    environment.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 使用的数据集是从著名的数据集KDD数据集中修改而来的子集，是测试和构建IDS系统的标准数据集。该数据集包含在军事网络环境中模拟的各种入侵。
- en: Getting ready
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Preparation for this recipe involves installing `scikit-learn`, `pandas`, and
    `matplotlib`. The command is as follows:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程的准备工作包括安装`scikit-learn`、`pandas`和`matplotlib`。命令如下：
- en: '[PRE18]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: In addition, extract the archive, `kddcup_dataset.7z`.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，解压`kddcup_dataset.7z`档案。
- en: How to do it…
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点…
- en: 'In the following steps, we will utilize isolation forest to detect anomalies
    in the KDD dataset:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的步骤中，我们将利用孤立森林在KDD数据集中检测异常：
- en: 'Import `pandas` and read the dataset into a data frame:'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`pandas`并将数据集读取到数据框中：
- en: '[PRE19]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Examine the proportion of types of traffic:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查流量类型的比例：
- en: '[PRE20]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The following output will be observed:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 将会观察到以下输出：
- en: '[PRE21]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Convert all non-normal observations into a single class:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将所有非正常观测值转换为单一类别：
- en: '[PRE22]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Obtain the ratio of anomalies to normal observations. This is the contamination
    parameter that will be used in our isolation forest:'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取异常数据与正常数据的比例。这是我们在孤立森林中使用的污染参数：
- en: '[PRE23]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Convert all categorical features into numerical form:'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将所有类别特征转换为数值形式：
- en: '[PRE24]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Split the dataset into normal and abnormal observations:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据集分为正常和异常观测值：
- en: '[PRE25]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Train-test split the dataset:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据集分为训练集和测试集：
- en: '[PRE26]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Instantiate and train an isolation forest classifier:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化并训练一个孤立森林分类器：
- en: '[PRE27]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Score the classifier on normal and anomalous observations:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对正常和异常观测值进行分类评分：
- en: '[PRE28]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Plot the scores for the normal set:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制正常数据集的分数：
- en: '[PRE29]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The following graph provides the output:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表提供了输出结果：
- en: '![](assets/e34915a8-d4cf-467a-bedd-25d7c7fe16d7.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/e34915a8-d4cf-467a-bedd-25d7c7fe16d7.png)'
- en: 'Similarly, plot the scores on the anomalous observations for a visual examination:'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 类似地，绘制异常观测值的分数以进行可视化检查：
- en: '[PRE30]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The following graph provides the output:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表提供了输出结果：
- en: '![](assets/8d5553be-1729-4ae1-b3bd-7b25c92c7fcd.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/8d5553be-1729-4ae1-b3bd-7b25c92c7fcd.png)'
- en: 'Select a cut-off so as to separate out the anomalies from the normal observations:'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择一个截断点，以将异常数据与正常数据分开：
- en: '[PRE31]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Examine this cut-off on the test set:'
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在测试集上检查此截断点：
- en: '[PRE32]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The following is the output:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是输出结果：
- en: '[PRE33]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: How it works…
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: We start by reading the `KDD cup` dataset into a data frame. Next, in *Step
    2*, we examine our data, to see that a majority of the traffic is normal, as expected,
    but a small amount is abnormal. Evidently, the problem is highly imbalanced. Consequently,
    this problem is a promising candidate for an anomaly detection approach. In *Steps
    3* and *5*, we transform all non-normal traffic into a single class, namely, **anomalous**.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先将`KDD cup`数据集读取到数据框中。接下来，在*步骤 2*中，我们检查数据，发现大多数流量是正常的，正如预期的那样，但少量是异常的。显然，这个问题是高度不平衡的。因此，这个问题非常适合使用异常检测方法。在*步骤
    3*和*步骤 5*中，我们将所有非正常流量转化为一个单一类别，即**异常**。
- en: We also make sure to compute the ratio of anomalies to normal observations (*Step
    4*), known as the contamination parameter. This is one of the parameters that
    facilitates setting of the sensitivity of isolation forest. This is optional,
    but is likely to improve performance. We split our dataset into normal and anomalous
    observations in *Step 6*, as well as split our dataset into training and testing
    versions of the normal and anomalous data (*Step 7*). We instantiate an isolation
    forest classifier, and set its contamination parameter (*Step 8*). The default
    parameters, `n_estimators` and `max_samples`, are recommended in the paper *Isolation
    Forest* by Liu et al. In *Steps 9* and *10*, we use the decision function of isolation
    forest to provide a score to the normal training set, and then examine the results
    in a plot. In *Step 11*, we similarly provide a score to the anomalous training
    set.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还确保计算异常值与正常观察值的比率（*步骤 4*），即污染参数。这是设置隔离森林灵敏度的参数之一。这个步骤是可选的，但可能会提高性能。我们在*步骤
    6*中将数据集分为正常和异常观察值，同时将数据集分为正常和异常数据的训练集和测试集（*步骤 7*）。我们实例化一个隔离森林分类器，并设置其污染参数（*步骤
    8*）。论文《Isolation Forest》中推荐使用的默认参数`n_estimators`和`max_samples`由Liu等人提出。在*步骤 9*和*步骤
    10*中，我们使用隔离森林的决策函数为正常训练集提供分数，然后在图表中检查结果。在*步骤 11*中，我们类似地为异常训练集提供分数。
- en: Knowing that the decision function is a measure of how simple a point is to
    describe, we would like to separate out simple points from complicated points
    by picking a numerical cut-off that gives clear separation. A visual examination
    suggests the value chosen in *Step 12*.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 知道决策函数是衡量一个点描述简单程度的指标后，我们希望通过选择一个数值截断点，将简单点与复杂点分离开来，从而获得明显的区分。通过可视化检查，建议选择在*步骤
    12*中选定的值。
- en: Finally, we can use our model to make predictions and provide an assessment
    of its performance. In *Step 13*, we see that the model was able to pick up on
    a large number of anomalies without triggering too many false positives (instances
    of normal traffic), speaking proportion-wise.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以使用模型进行预测并评估其性能。在*步骤 13*中，我们看到模型能够捕捉到大量异常，而不会触发过多的假阳性（正常流量的实例），按比例而言。
- en: Botnet traffic detection
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 僵尸网络流量检测
- en: A botnet is a network of internet-connected compromised devices. Botnets can
    be used to perform a distributed **denial-of-service attack** (**DDoS attack**),
    steal data, send spam, among many other creative malicious uses. Botnets can cause
    absurd amounts of damage. For example, a quick search for the word botnet on Google
    shows that 3 days before the time of writing, the Electrum Botnet Stole $4.6 Million
    in cryptocurrencies. In this recipe, we build a classifier to detect botnet traffic.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 僵尸网络是由被攻击的互联网设备组成的网络。僵尸网络可用于执行分布式**拒绝服务攻击**（**DDoS攻击**）、窃取数据、发送垃圾邮件，以及其他各种创意恶意用途。僵尸网络可以造成巨大的损害。例如，在写作时，快速搜索“僵尸网络”一词显示，3天前，Electrum僵尸网络窃取了460万美元的加密货币。在本教程中，我们构建一个分类器来检测僵尸网络流量。
- en: The dataset used is a processed subset of a dataset called **CTU-13**, and consists
    of botnet traffic captured in Czechia, at the CTU University in 2011\. The dataset
    is a large capture of real botnet traffic mixed with normal and background traffic.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 使用的数据集是一个处理过的子集，名为**CTU-13**，包含了2011年捷克CTU大学捕获的僵尸网络流量。该数据集包含大量真实的僵尸网络流量，混合了正常流量和背景流量。
- en: Getting ready
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Preparation for this recipe involves installing `scikit-learn` in `pip`. The
    command is as follows:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程的准备工作包括在`pip`中安装`scikit-learn`。命令如下：
- en: '[PRE34]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'In addition, extract `CTU13Scenario1flowData.7z`. To unpickle the `CTU13Scenario1flowData.pickle`
    file, you will need to use Python 2:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，解压`CTU13Scenario1flowData.7z`。要反序列化`CTU13Scenario1flowData.pickle`文件，需要使用Python
    2：
- en: How to do it…
  id: totrans-182
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'Begin by reading in the pickled data:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先读取已序列化的数据：
- en: '[PRE35]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The data is already split into train-test sets, and you only need assign these
    to their respective variables:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据已分割为训练集和测试集，你只需将它们分别分配给各自的变量：
- en: '[PRE36]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Instantiate a decision tree classifier with default parameters:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用默认参数实例化决策树分类器：
- en: '[PRE37]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Fit the classifier to the training data:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将分类器拟合到训练数据：
- en: '[PRE38]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Test it on the test set:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在测试集上进行测试：
- en: '[PRE39]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The following is the output:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是输出：
- en: '[PRE40]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: How it works…
  id: totrans-195
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: We begin *Step 1* by loading the data by unpickling it. The dataset has been
    pre-engineered to be balanced, so we do not need to worry about imbalanced data
    challenges. In practice, the detection of botnets may require satisfying a constraint
    on false positives. Moving on, we utilize the already predefined train-test split
    to split our data (*Step 2*). We can now instantiate a classifier, fit it to the
    data, and then test it (*Steps 3* and *5*). Looking at the accuracy, we see that
    it is quite high. Since the dataset is already balanced, we need not worry that
    our metric is misleading. In general, detecting botnets can be challenging. The
    difficulty in detecting botnets is illustrated by the GameOver Zeus botnet malware
    package. Originally discovered in 2007, it operated for over three years, eventually
    resulting in an estimated $70 million in stolen funds that led to the arrest of
    over a hundred individuals by the FBI in 2010\. It wasn't until March 2012 that
    Microsoft announced that it was able to shut down the majority of the botnet's
    command and control (C&C) servers.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从*步骤1*开始，通过反序列化数据来加载它。数据集已经经过预处理以确保平衡，因此我们无需担心数据不平衡的问题。实际上，检测僵尸网络可能需要满足对假阳性率的限制。接下来，我们利用已经预定义的训练集-测试集划分来分割数据（*步骤2*）。现在我们可以实例化分类器，将其拟合到数据上，然后进行测试（*步骤3*和*步骤5*）。从准确率来看，我们看到它相当高。由于数据集已经平衡，我们无需担心我们的指标会产生误导。一般来说，检测僵尸网络是一个具有挑战性的任务。僵尸网络的检测难度可以通过GameOver
    Zeus僵尸网络恶意软件包来说明。该僵尸网络最初在2007年被发现，运营了超过三年，最终导致约7000万美元的资金被盗，并导致FBI在2010年逮捕了100多名嫌疑人。直到2012年3月，微软才宣布它已经能够关闭该僵尸网络的大部分指挥与控制（C&C）服务器。
- en: Insider threat detection
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 内部威胁检测
- en: Insider threat is a complex and growing challenge for employers. It is generally
    defined as any actions taken by an employee that are potentially harmful to the
    organization. These can include actions such as unsanctioned data transfer or
    the sabotaging of resources. Insider threats may manifest in various and novel
    forms motivated by differing goals, ranging from a disgruntled employee subverting
    the prestige of an employer, to **advanced persistent threats** (**APT**).
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 内部威胁是雇主面临的一个复杂且日益严峻的挑战。通常定义为员工采取的任何可能对组织造成危害的行为。这些行为可能包括未经授权的数据传输或资源破坏等。内部威胁可能以各种新颖形式表现出来，动机各异，从不满的员工破坏雇主声誉，到**高级持续性威胁**（**APT**）等。
- en: The insider risk database of the CERT Program of the Carnegie Mellon University
    Software Engineering Institute contains the largest public archive of red team
    scenarios. The simulation is built by combining real-world insider risk case studies
    with actual neutral clients secretly obtained from a defense corporation. The
    dataset represents months of traffic in a single engineering company from internet,
    phone, logon, folder, and system access (dtaa.com). The mock company employs several
    thousand people who each perform an average of 1,000 logged activities per day.
    There are several threat scenarios depicted, such as a leaker, thief, and saboteur.
    A notable feature of the issue is its very low signal-to-noise, whether this is
    expressed in total malicious users, frequent tallies, or overall usage.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 卡内基梅隆大学软件工程研究所（CERT项目）的内部风险数据库包含了最大的公开红队情景档案。该模拟通过将真实世界的内部风险案例与从防御公司秘密获得的实际中立客户结合而构建。该数据集代表了一家单一工程公司数月的流量，涵盖了互联网、电话、登录、文件夹和系统访问（dtaa.com）。模拟公司雇佣了数千名员工，每人每天平均执行1,000次登录活动。数据中描绘了几种威胁情景，例如泄密者、小偷和破坏者。该问题的一个显著特点是其非常低的信噪比，无论是表现为恶意用户的总数、频繁的计数，还是总体使用情况。
- en: The analysis we perform is on the CERT insider threat scenario (v.4.2), specifically
    because it represents a dense needle dataset, meaning that it has a high incidence
    of attacks.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进行的分析基于CERT内部威胁情景（v.4.2），特别是因为它代表了一个密集的针形数据集，这意味着它具有高频次的攻击发生。
- en: 'The basic plan of attack is, first, to hand-engineer new features, such as
    whether an email has been sent to an outsider or a login has occurred outside
    of business hours. Next, the idea is to extract a multivariate time series per
    user. This time series will consist of a sequence of vectors—each vector constitutes
    a count of the number of times our hand-engineered features took place in a day.
    Hence, the shape of our input dataset will be as follows:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 攻击的基本计划是，首先手工创建新特征，例如是否向外部人员发送了邮件或登录是否发生在非工作时间。接下来的想法是为每个用户提取一个多变量时间序列。这个时间序列将由一系列向量组成，每个向量构成一天中我们手工创建的特征发生的次数计数。因此，我们输入数据集的形状将如下所示：
- en: '(# of users, total # of features examined per day, # of days in the time series).'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: （每天检查的用户数，每天检查的总特征数，时间序列中的天数）。
- en: We will then flatten the time series of each user, and utilize isolation forest
    to detect anomalies.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将展平每个用户的时间序列，并利用隔离森林来检测异常。
- en: Feature engineering for insider threat detection
  id: totrans-204
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 内部威胁检测的特征工程
- en: Generally, whenever a machine learning solution does not rely on end-to-end
    deep learning, performance can be improved by creating insightful and informative
    features. In this recipe, we will construct several promising new features for
    insider threat detection.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，当一个机器学习解决方案不依赖端到端的深度学习时，通过创建富有洞见和信息性的特征可以提高性能。在这个示例中，我们将为内部威胁检测构建几个有前途的新特征。
- en: Getting ready
  id: totrans-206
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Preparation for this recipe involves installing `pandas` in `pip`. The command
    is as follows:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 准备工作包括在`pip`中安装`pandas`。命令如下：
- en: '[PRE41]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'In addition, download the CERT insider threat dataset from the following link:
    [ftp://ftp.sei.cmu.edu/pub/cert-data/r4.2.tar.bz2](ftp://ftp.sei.cmu.edu/pub/cert-data/r4.2.tar.bz2).
    More information about the dataset, as well as answers, can be found at [https://resources.sei.cmu.edu/library/asset-view.cfm?assetid=508099](https://resources.sei.cmu.edu/library/asset-view.cfm?assetid=508099).'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，从以下链接下载CERT内部威胁数据集：[ftp://ftp.sei.cmu.edu/pub/cert-data/r4.2.tar.bz2](ftp://ftp.sei.cmu.edu/pub/cert-data/r4.2.tar.bz2)。有关数据集的更多信息以及答案，请访问[https://resources.sei.cmu.edu/library/asset-view.cfm?assetid=508099](https://resources.sei.cmu.edu/library/asset-view.cfm?assetid=508099)。
- en: How to do it…
  id: totrans-210
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做…
- en: 'In the following steps, you will construct new features for the CERT insider
    threat dataset:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的步骤中，您将为CERT内部威胁数据集构建新特征：
- en: 'Import `numpy` and `pandas`, and point to where the downloaded data is located:'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`numpy`和`pandas`，并指向下载数据的位置：
- en: '[PRE42]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Specify the `.csv` files and which of their columns to read:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指定`.csv`文件及其要读取的列：
- en: '[PRE43]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: We will hand-engineer a number of features and encode them, thereby creating
    a dictionary to track these.
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将手工创建一些特征并对其进行编码，从而创建一个字典来跟踪这些特征。
- en: '[PRE44]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Add the features we will be using to our dictionary:'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将要使用的特征添加到我们的字典中：
- en: '[PRE45]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Define a function to note the file type that was copied to removable media:'
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数来记录被复制到可移动介质的文件类型：
- en: '[PRE46]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Define a function to identify whether an employee has sent an email to a non-company
    email:'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数来识别员工是否向非公司邮箱发送了邮件：
- en: '[PRE47]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Define a function to note whether the employee used removable media outside
    of business hours:'
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数来记录员工是否在非工作时间使用可移动介质：
- en: '[PRE48]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Define a function to note whether an employee has logged onto a machine outside
    of business hours:'
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数来记录员工是否在非工作时间登录到计算机：
- en: '[PRE49]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'We will not take advantage of the information contained in URLs visited by
    an employee:'
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们不会利用员工访问的URL中包含的信息：
- en: '[PRE50]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'We preserve only the day when an event has occurred, rather than the full timestamp:'
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们仅保留事件发生的日期，而不是完整的时间戳：
- en: '[PRE51]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'We loop over the `.csv` files containing the logs and read them into pandas
    data frames:'
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们循环遍历包含日志的`.csv`文件，并将它们读入pandas数据框中：
- en: '[PRE52]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Convert the `date` data to a `pandas` timestamp:'
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`date`数据转换为`pandas`时间戳：
- en: '[PRE53]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Create the new features defined above and then drop all features except the
    date, user, and our new feature:'
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建上述定义的新特征，然后丢弃除日期、用户和我们的新特征之外的所有特征：
- en: '[PRE54]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Convert the date to just a day:'
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将日期转换为只有一天：
- en: '[PRE55]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Concatenate all the data frames into one and sort by `date`:'
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将所有数据框连接成一个，并按`date`排序：
- en: '[PRE56]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: How it works...
  id: totrans-242
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: Start by importing `pandas` and `numpy` and creating a variable pointing to
    the dataset (*Step 1*). There are several datasets available from CERT. Version
    4.2 is distinguished in being a dense needle dataset, meaning that it has a higher
    incidence of insider threats than the other datasets. Since the dataset is so
    massive, it is convenient to filter and downsample it, at the very least during
    the experimentation phases, so we do so in *Step 2*. In the following steps, we
    will hand-engineer features that we believe will help our classifier catch insider
    threats. In *Step 3*, we create a convenient function to encode features, so that
    a dictionary can track these. We provide the names of the features we will be
    adding in *Step 4*. In *Step 5*, we create a feature that will track the file
    type of a file copied to removable media. Presumably, this is indicative of criminal
    data leaking. In *Step 6*, we create a feature that tracks whether the employee
    has emailed an external entity. We create another feature to track whether an
    employee has used a removable media device outside of business hours (*Step 7*).
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 首先导入`pandas`和`numpy`并创建一个指向数据集的变量（*步骤 1*）。CERT提供了多个数据集。4.2版本之所以与众不同，是因为它是一个密集的“针”数据集，意味着它比其他数据集有更高的内部威胁发生率。由于数据集非常庞大，因此在实验阶段，至少要对其进行过滤和下采样，以便更方便地处理数据，因此我们在*步骤
    2*中这样做。在接下来的步骤中，我们将手动设计一些特征，认为这些特征有助于我们的分类器识别内部威胁。在*步骤 3*中，我们创建一个便捷的函数来编码特征，以便一个字典可以跟踪这些特征。我们在*步骤
    4*中提供将要添加的特征名称。在*步骤 5*中，我们创建一个特征，用于跟踪复制到可移动介质中的文件类型。推测这可能表明数据泄露犯罪行为。在*步骤 6*中，我们创建一个特征，跟踪员工是否曾给外部实体发送过电子邮件。我们又创建了一个特征，用于跟踪员工是否在非工作时间使用过可移动存储设备（*步骤
    7*）。
- en: An additional feature tracks whether an employee has logged into a device outside
    of business hours (*Step 8*). For simplicity, we do not utilize the URLs visited
    by employees (*Step 9*), though these may be indicative of malicious behavior.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 一个附加特征用于跟踪员工是否在非工作时间登录过设备（*步骤 8*）。为了简化处理，我们没有利用员工访问的URL（*步骤 9*），尽管这些可能暗示恶意行为。
- en: Next, we simplify our data by using only the date (*Step 10*), rather than the
    full timestamp in our featurized data. In *Step 11*, we read our data into a pandas
    data frame. We then edit the current date format to fit pandas (*Step 12*), and
    then gather up all of the new features, while dropping the old ones (*Step 13*).
    In *Step 14*, we transform the data into a time series whose delta are single
    days. Finally, in *Step 15*, we aggregate all of the data into one large sorted
    data frame. We have now completed the first iteration of the feature-engineering
    phase. There are many directions you can pursue in order to improve performance
    and add features. These include observing email text for negative sentiment and
    analyzing personality using psychometrics.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们通过仅使用日期（*步骤 10*），而不是在特征化数据中使用完整的时间戳，来简化数据。在*步骤 11*中，我们将数据读取到一个pandas数据框中。然后，在*步骤
    12*中，我们编辑当前的日期格式，以适应pandas，并收集所有新的特征，同时丢弃旧的特征（*步骤 13*）。在*步骤 14*中，我们将数据转换为一个时间序列，其增量为单天。最后，在*步骤
    15*中，我们将所有数据汇总到一个大型的已排序数据框中。我们现在已经完成了特征工程阶段的第一次迭代。为了提升性能并添加特征，你可以朝着多个方向努力。这些方向包括观察电子邮件文本中的负面情绪，并使用心理测量学分析个性。
- en: Employing anomaly detection for insider threats
  id: totrans-246
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用异常检测来识别内部威胁
- en: Having engineered promising new features, our next steps are to train-test split,
    process the data into a convenient time series form, and then classify. Our training
    and testing sets will be two temporal halves of the dataset. This way, we can
    easily ensure that the shape of the input for training is the same as the shape
    of the input for testing, without cheating in our evaluation.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 在设计出有前景的新特征后，我们的下一步是进行训练集和测试集划分，将数据处理成方便的时间序列形式，然后进行分类。我们的训练集和测试集将是数据集的两个时间半部分。通过这种方式，我们可以轻松确保训练输入的形状与测试输入的形状相同，从而避免在评估中作弊。
- en: Getting ready
  id: totrans-248
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Preparation for this recipe involves installing `scikit-learn`, `pandas`, and
    `matplotlib` in `pip`. The command is as follows:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 这个配方的准备工作包括在`pip`中安装`scikit-learn`、`pandas`和`matplotlib`。命令如下：
- en: '[PRE57]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: In preparation for this recipe, you will want to load in the data frame from
    the previous recipe (or just continue from where the previous recipe ended).
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 在准备这个配方时，你需要加载前一个配方中的数据框（或者直接从前一个配方的结束部分继续）。
- en: How to do it...
  id: totrans-252
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'In the following steps, you will convert the featurized data into a collection
    of time series and detect crime using isolation forest:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的步骤中，你将把特征化数据转换为时间序列集合，并使用孤立森林检测犯罪：
- en: 'List all threat actors in preparation for creating labels:'
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 列出所有威胁行为者，为创建标签做准备：
- en: '[PRE58]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'We then index the dates:'
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们对日期进行索引：
- en: '[PRE59]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Define a function to extract the time series information of a given user:'
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数来提取给定用户的时间序列信息：
- en: '[PRE60]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Define a function to vectorize the time series information of a user:'
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数来向量化用户的时间序列信息：
- en: '[PRE61]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Define a function to vectorize a time series of all users'' features:'
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数来向量化所有用户特征的时间序列：
- en: '[PRE62]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Vectorize the dataset:'
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向量化数据集：
- en: '[PRE63]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Train-test split the vectorized data:'
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对向量化数据进行训练-测试集划分：
- en: '[PRE64]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Reshape the vectorized data:'
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新调整向量化数据的形状：
- en: '[PRE65]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Split the training and testing datasets into threat and non-threat subsets:'
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将训练集和测试集数据拆分为威胁和非威胁子集：
- en: '[PRE66]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Define and instantiate an isolation forest classifier:'
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义并实例化孤立森林分类器：
- en: '[PRE67]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Fit the isolation forest classifier to the training data:'
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将孤立森林分类器拟合到训练数据：
- en: '[PRE68]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'Plot the decision scores of the normal subset of the training data:'
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制训练数据中正常子集的决策分数：
- en: '[PRE69]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Take a look at the following screenshot:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 请查看以下截图：
- en: '![](assets/c2b73e67-f7c5-49a7-a4ff-de067fc826eb.png)'
  id: totrans-279
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/c2b73e67-f7c5-49a7-a4ff-de067fc826eb.png)'
- en: 'Do the same for the threat actors in the training data:'
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对训练数据中的威胁行为者执行相同操作：
- en: '[PRE70]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'Take a look at the following screenshot:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 请查看以下截图：
- en: '![](assets/cda00f69-d7e1-49da-adf6-e2eeddd31596.png)'
  id: totrans-283
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/cda00f69-d7e1-49da-adf6-e2eeddd31596.png)'
- en: 'Select a cut-off score:'
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择一个截断分数：
- en: '[PRE71]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Observe the results of the cut-off on the training data:'
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 观察截断在训练数据上的结果：
- en: '[PRE72]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'The following is the output:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是输出结果：
- en: '[PRE73]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'Measure the results of the cut-off choice on the testing set:'
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测量截断选择在测试集上的结果：
- en: '[PRE74]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'The following is the output:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是输出结果：
- en: '[PRE75]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: How it works…
  id: totrans-294
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: Having completed the feature-engineering phase in the previous recipe, we went
    ahead and created a model. In *Step 1*, we listed all threat actors in preparation
    for the next steps. In *Step 2*, we created an indexing for the dates, so that
    `0` corresponded to the starting date, `1` to the next day, and so on. In the
    subsequent *Steps 3* and *5*, we defined functions to read in the whole dataset
    time series, filter it down to individual users, and then vectorize the time series
    for each user. We went ahead and vectorized the dataset (*Step 6*) and then train-test
    split it (*Step 7*). We reshaped the data in *Step 8* in order to be able to feed
    it into the isolation forest classifier. We split the data further into benign
    and threat subsets (*Step 9*) to allow us to tune our parameters. We instantiated
    an isolation forest classifier in *Step 10* and then fit it on the data in *Step
    11*. For our contamination parameter, we used a value corresponding to the proportion
    of threats-to-benign actors.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的食谱中完成特征工程阶段后，我们继续创建了一个模型。在*第1步*中，我们列出了所有的威胁行为者，为接下来的步骤做准备。在*第2步*中，我们为日期创建了索引，使得`0`对应起始日期，`1`对应第二天，依此类推。在随后的*第3步*和*第5步*中，我们定义了函数来读取整个数据集的时间序列，将其过滤到每个用户，然后为每个用户向量化时间序列。接着我们向量化了数据集（*第6步*），并进行了训练-测试集划分（*第7步*）。我们在*第8步*中重新调整了数据形状，以便能够将其输入到孤立森林分类器中。我们进一步将数据拆分为良性和威胁子集（*第9步*），以便调整我们的参数。在*第10步*中，我们实例化了孤立森林分类器，然后在*第11步*中将其拟合到数据上。对于我们的污染参数，我们使用了一个值，对应威胁与良性行为者的比例。
- en: In the next three steps (*Steps 12*-*14*), we examined the decision scores of
    isolation forest on benign and threat actors, and concluded, via inspection, that
    the cut-off value of 0.12 detects a large proportion of the threat actors without
    flagging too many of the benign actors. Finally, assessing our performance in
    *Steps* 15 and *16*, we saw that there were some false positives, but also a significant
    number of insider threats detected. Since the ratio was not too high, the classifier
    can be of great help in informing analysts about plausible threats.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的三步（*第12步* - *第14步*）中，我们检查了孤立森林在良性和威胁行为者上的决策分数，并通过检查得出结论，截断值0.12能够检测到大比例的威胁行为者，而不会标记太多良性行为者。最后，在*第15步*和*第16步*中评估我们的性能时，我们发现有一些假阳性，但也检测到了相当数量的内部威胁。由于比例不是很高，因此分类器对于告知分析员潜在威胁非常有帮助。
- en: Detecting DDoS
  id: totrans-297
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检测DDoS
- en: '**DDoS**, or **Distributed Denial of Service**, is an attack in which traffic
    from different sources floods a victim, resulting in service interruption. There
    are many types of DDoS attacks, falling under three general categories: application-level,
    protocol, and volumetric attacks. Much of the DDoS defense today is manual. Certain
    IP addresses or domains are identified and then blocked. As DDoS bots become more
    sophisticated, such approaches are becoming outdated. Machine learning offers
    a promising automated solution.'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: '**DDoS**，即**分布式拒绝服务攻击**，是一种攻击方式，其中来自不同来源的流量洪水般涌向目标，导致服务中断。DDoS攻击有许多类型，通常分为三大类：应用层攻击、协议攻击和流量攻击。目前，很多DDoS防御仍是手动进行的。通过识别并阻止特定的IP地址或域名来进行防御。随着DDoS攻击的机器人变得越来越复杂，这种方法正在逐渐过时。机器学习为此提供了一个有前景的自动化解决方案。'
- en: The dataset we will be working with is a subsampling of the CSE-CIC-IDS2018,
    CICIDS2017, and CIC DoS datasets (2017). It consists of 80% benign and 20% DDoS
    traffic, in order to represent a more realistic ratio of normal-to-DDoS traffic.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用的数据集是对CSE-CIC-IDS2018、CICIDS2017和CIC DoS数据集（2017年）的子采样。它由80%的正常流量和20%的DDoS流量组成，以代表更为现实的正常流量与DDoS流量的比例。
- en: Getting ready
  id: totrans-300
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Preparation for this recipe involves installing a couple of packages in `pip`,
    namely, `scikit-learn` and `pandas`. The command is as follows:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 本配方的准备工作包括在`pip`中安装几个包，分别是`scikit-learn`和`pandas`。命令如下：
- en: '[PRE76]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: In preparation for this recipe, extract the archive, `ddos_dataset.7z`.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 为了准备这个配方，提取归档文件`ddos_dataset.7z`。
- en: How to do it…
  id: totrans-304
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何实现…
- en: 'In the following steps, we will train a random forest classifier to detect
    DDoS traffic:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的步骤中，我们将训练一个随机森林分类器来检测DDoS流量：
- en: 'Import `pandas` and specify the data types for the columns you will be reading
    in the code:'
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`pandas`并指定您将在代码中读取的列的数据类型：
- en: '[PRE77]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'Read in the `.csv` file containing the dataset:'
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取包含数据集的`.csv`文件：
- en: '[PRE78]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'Sort the data by date:'
  id: totrans-310
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按日期对数据进行排序：
- en: '[PRE79]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'Drop the date column, as it is no longer needed:'
  id: totrans-312
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 删除日期列，因为它不再需要：
- en: '[PRE80]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'Split the data into training and testing subsets, consisting of the first 80%
    and last 20% of the data:'
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据分割为训练集和测试集，分别由数据的前80%和后20%组成：
- en: '[PRE81]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'Prepare the labels:'
  id: totrans-316
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准备标签：
- en: '[PRE82]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'Prepare the feature vectors:'
  id: totrans-318
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准备特征向量：
- en: '[PRE83]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'Import and instantiate a random forest classifier:'
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入并实例化一个随机森林分类器：
- en: '[PRE84]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'Fit random forest to the training data and score it on the testing data:'
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将随机森林模型拟合到训练数据，并在测试数据上进行评分：
- en: '[PRE85]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'The following is the output:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是输出结果：
- en: '[PRE86]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: How it works…
  id: totrans-326
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: Since the dataset is large, even importing all of it is computationally intensive.
    For this reason, we begin *Step 1* by specifying a subset of features from our
    dataset, the ones we consider most promising, as well as recording their data
    type so that we don't have to convert them later. We then proceed to read the
    data into a data frame in *Step 2*. In *Steps 3* and *4*, we sort the data by
    date, since the problem requires being able to predict events in the future, and
    then drop the date column since we will not be employing it further. In the next
    two steps, we perform a train-test split, keeping in mind temporal progression.
    We then instantiate, fit, and test a random forest classifier in *Steps 8* and
    *9*. Depending on the application, the accuracy achieved is a good starting point.
    A promising direction to improve performance is to account for the source and
    destination IPs. The reasoning is that, intuitively, where a connection is coming
    from should have a significant bearing on whether it is part of a DDoS.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据集较大，即便是导入它也会消耗大量计算资源。因此，我们在*步骤1*中通过指定我们认为最有前景的特征子集以及记录它们的数据类型来开始操作，这样我们就不需要后续再转换它们。然后，在*步骤2*中，我们将数据读取到数据框中。在*步骤3*和*4*中，我们按日期对数据进行排序，因为问题要求能够预测未来的事件，并且随后删除日期列，因为我们不再需要它。在接下来的两步中，我们进行训练-测试数据集划分，同时考虑到时间进展。然后，我们在*步骤8*和*9*中实例化、拟合并测试一个随机森林分类器。根据应用场景，得到的准确性是一个不错的起点。为了提升性能，一个有前景的方向是考虑源IP和目的IP。直观来说，连接的来源应该对它是否属于DDoS攻击有重要影响。
- en: Credit card fraud detection
  id: totrans-328
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 信用卡欺诈检测
- en: Credit card companies must monitor for fraudulent transactions in order to keep
    their customers from being charged for items they have not purchased. Such data
    is unique in being extremely imbalanced, with the particular dataset we will be
    working on in this chapter having fraud constituting 0.172% of the total transactions.
    It contains only numeric input variables, which are the result of a PCA transformation,
    and the features *Time* and *Amount*. The *Time* feature contains the seconds
    elapsed between each transaction and the first transaction in the dataset. The
    *Amount* feature is the amount transaction, a feature that we will use, for instance,
    in cost-sensitive learning. The *Class* feature is the response parameter and,
    in case of fraud, it takes the value `1`, and `0` otherwise.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 信用卡公司必须监控欺诈交易，以避免客户被错误收费。这样的数据非常不平衡，我们在本章中将使用的数据集，其中欺诈交易仅占总交易的0.172%。它只包含数字输入变量，这些变量是通过PCA变换得到的，还有*Time*和*Amount*特征。*Time*特征包含每笔交易与数据集中第一笔交易之间经过的秒数。*Amount*特征是交易金额，这是我们将在成本敏感学习中使用的一个特征。*Class*特征是响应参数，在欺诈情况下，其值为`1`，否则为`0`。
- en: 'So what is example-dependent, cost-senstive learning? Consider the costs associated
    with each type of classification. If the program does not identify a fraudulent
    transaction, the money will be wasted and the card holder must be reimbursed for
    the entire amount of the transaction. If a payment is considered fraudulent by
    the program, the transaction will be stopped. In that situation, administrative
    costs arise due to the need to contact the card holder and the card needs to be
    replaced (if the transaction was correctly labeled fraudulent) or reactivated
    (if the transaction was actually legitimate). Let''s assume, for simplicity''s
    sake, that administrative costs are always the same. If the system finds the transaction
    valid, then the transaction will automatically be accepted and there will be no
    charge. This results in the following costs associated with each prediction scenario:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 那么什么是示例相关的、成本敏感的学习呢？考虑每种分类类型相关的成本。如果程序没有识别出欺诈交易，钱就会被浪费，并且持卡人必须获得全额退款。如果程序认为支付是欺诈性的，交易将被停止。在这种情况下，由于需要联系持卡人，且卡需要被替换（如果交易被正确标记为欺诈），或者重新激活（如果交易实际上是合法的），就会产生行政成本。为了简化起见，假设行政成本总是相同的。如果系统认为交易是有效的，那么交易将自动接受，并且不会收取费用。这就导致了每种预测场景相关的以下成本：
- en: '|  | Fraudy = 1 | Benigny = 0 |'
  id: totrans-331
  prefs: []
  type: TYPE_TB
  zh: '|  | 欺诈y = 1 | 良性y = 0 |'
- en: '| Predicted fraudy_pred = 1 | TPcost = administrative | FPcost = administrative
    |'
  id: totrans-332
  prefs: []
  type: TYPE_TB
  zh: '| 预测的欺诈y_pred = 1 | 真阳性成本 = 行政成本 | 假阳性成本 = 行政成本 |'
- en: '| Predicted benigny_pred = 0 | FNcost = transaction amount | TNcost = $0 |'
  id: totrans-333
  prefs: []
  type: TYPE_TB
  zh: '| 预测的良性y_pred = 0 | 假阴性成本 = 交易金额 | 真阴性成本 = $0 |'
- en: Unlike most scenarios, our interest is to minimize the total cost, derived from
    the above considerations, rather than accuracy, precision, or recall.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 与大多数场景不同，我们的兴趣在于最小化总成本，基于上述考虑，而不是准确性、精确度或召回率。
- en: Getting ready
  id: totrans-335
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Preparation for this recipe involves installing `scikit-learn`, `pandas`, and
    `matplotlib` in `pip`, as well as a new package called `costcla`. The command
    is as follows:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 为了准备这个配方，需要在`pip`中安装`scikit-learn`、`pandas`和`matplotlib`，以及一个名为`costcla`的新包。命令如下：
- en: '[PRE87]'
  id: totrans-337
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: In preparation for this recipe, download the credit card transactions dataset
    from [https://www.kaggle.com/mlg-ulb/creditcardfraud/downloads/creditcardfraud.zip/3](https://www.kaggle.com/mlg-ulb/creditcardfraud/downloads/creditcardfraud.zip/3)
    (open database license).
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 为了准备这个配方，从[https://www.kaggle.com/mlg-ulb/creditcardfraud/downloads/creditcardfraud.zip/3](https://www.kaggle.com/mlg-ulb/creditcardfraud/downloads/creditcardfraud.zip/3)下载信用卡交易数据集（开放数据库许可证）。
- en: How to do it…
  id: totrans-339
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作……
- en: 'In the following steps, we will build an example-dependent, cost-sensitive
    classifier using the `costcla` library on credit card transaction data:'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的步骤中，我们将使用`costcla`库在信用卡交易数据上构建一个示例相关的、成本敏感的分类器：
- en: 'Import `pandas` and read the data pertaining to transactions into a data frame:'
  id: totrans-341
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`pandas`并将与交易相关的数据读取到数据框中：
- en: '[PRE88]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: 'Set a cost to `false` positives and `false` negatives:'
  id: totrans-343
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为`假`正例和`假`负例设置成本：
- en: '[PRE89]'
  id: totrans-344
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: 'Define a cost matrix corresponding to the figure:'
  id: totrans-345
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个对应于图表的成本矩阵：
- en: '[PRE90]'
  id: totrans-346
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: 'Create labels and feature matrices:'
  id: totrans-347
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建标签和特征矩阵：
- en: '[PRE91]'
  id: totrans-348
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: 'Create a train-test split:'
  id: totrans-349
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建训练集和测试集的划分：
- en: '[PRE92]'
  id: totrans-350
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: 'Import the decision tree, fit it to the training data, and then predict on
    the testing set:'
  id: totrans-351
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入决策树，将其拟合到训练数据上，然后在测试集上进行预测：
- en: '[PRE93]'
  id: totrans-352
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: 'Import the cost-sensitive decision tree, fit it to the training data, and then
    predict on the testing set:'
  id: totrans-353
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入成本敏感决策树，将其拟合到训练数据上，然后在测试集上进行预测：
- en: '[PRE94]'
  id: totrans-354
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: 'Calculate the savings score of the two models:'
  id: totrans-355
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算两个模型的节省得分：
- en: '[PRE95]'
  id: totrans-356
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: 'The following is the output:'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是输出结果：
- en: '[PRE96]'
  id: totrans-358
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: How it works…
  id: totrans-359
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: The first step is simply to load the data. In *Step 2*, we set an administrative
    cost based on the expected cost of replacing a credit card. In addition, we estimate
    the business cost of freezing a customer's banking operations until all transactions
    are verified. In practice, you should obtain an accurate figure that is appropriate
    to the credit card company or business use case in question. Using the parameters
    we have defined, we define a cost matrix in *Step 3* that takes into account the
    administrative cost of replacing a credit card, business interruption from freezing
    a customer, and so on. In *Steps 4* and *5*, we train-test split our data. Next,
    we would like to see how the example-dependent, cost-sensitive classifier performs
    as compared with a vanilla classifier. To that end, we instantiate a simple classifier,
    train it, and then use it to predict on the testing set in *Step 6*, and then
    utilize the cost-sensitive random forest model from the `costcla` library in *Step
    7* to do the same. Finally, in *Step 8*, we utilize the `savings_score` function
    from `costcla` to calculate the savings cost of using `y_pred` on `y_true` with
    a cost matrix. The higher the number, the larger the cost savings. Consequently,
    we see that the cost-sensitive random forest model outperformed the vanilla model.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是简单地加载数据。在*第2步*中，我们根据更换信用卡的预期成本设置了行政成本。此外，我们还估算了冻结客户银行操作直到所有交易被验证的商业成本。在实践中，你应该获取一个准确的数字，适合具体的信用卡公司或业务用例。使用我们定义的参数，在*第3步*中，我们定义了一个成本矩阵，考虑了更换信用卡的行政成本、冻结客户带来的业务中断等因素。在*第4步*和*第5步*中，我们进行数据的训练-测试拆分。接下来，我们想看看这个依赖于示例的、成本敏感的分类器与普通分类器相比表现如何。为此，我们实例化一个简单的分类器，进行训练，并在*第6步*中使用它对测试集进行预测，然后在*第7步*中使用`costcla`库中的成本敏感随机森林模型进行相同的操作。最后，在*第8步*中，我们利用`costcla`中的`savings_score`函数，基于成本矩阵计算使用`y_pred`对`y_true`的节省成本。数字越高，节省的成本越大。因此，我们可以看到，成本敏感的随机森林模型优于普通模型。
- en: Counterfeit bank note detection
  id: totrans-361
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 伪造钞票检测
- en: Counterfeit money is a currency created without the state or government's legal
    sanction, usually in a deliberate attempt to imitate the currency and to deceive
    its user. In this recipe, you will train a machine learning classifier to distinguish
    between genuine and fake bank notes.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 伪造货币是未经国家或政府合法批准的货币，通常是为了模仿合法货币并欺骗其使用者。在这个教程中，你将训练一个机器学习分类器来区分真实和伪造的钞票。
- en: Getting ready
  id: totrans-363
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备中
- en: 'Preparation for this recipe involves installing `scikit-learn` and `pandas`
    in `pip`. The command is as follows:'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程的准备工作包括在`pip`中安装`scikit-learn`和`pandas`。命令如下：
- en: '[PRE97]'
  id: totrans-365
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: 'In preparation for this recipe, download the banknote authentication dataset
    from UCI''s machine learning repository: [https://archive.ics.uci.edu/ml/datasets/banknote+authentication](https://archive.ics.uci.edu/ml/datasets/banknote+authentication).'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 在准备本教程时，从UCI机器学习库下载钞票鉴定数据集：[https://archive.ics.uci.edu/ml/datasets/banknote+authentication](https://archive.ics.uci.edu/ml/datasets/banknote+authentication)。
- en: How to do it...
  id: totrans-367
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'In the following steps, you will download a labeled dataset of counterfeit
    and legitimate bank notes and construct a classifier to detect counterfeit currency:'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的步骤中，你将下载一个标注过的伪造和合法钞票数据集，并构建一个分类器来检测伪造货币：
- en: Obtain a labeled dataset of authentic and counterfeit bank notes.
  id: totrans-369
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取真实和伪造的钞票标注数据集。
- en: 'Read in the bank note dataset using `pandas`:'
  id: totrans-370
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`pandas`读取钞票数据集：
- en: '[PRE98]'
  id: totrans-371
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: 'The following is the output:'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是输出结果：
- en: '[PRE99]'
  id: totrans-373
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: 'Create a train-test split:'
  id: totrans-374
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建训练-测试拆分：
- en: '[PRE100]'
  id: totrans-375
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: 'Collect the features and labels into arrays:'
  id: totrans-376
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将特征和标签收集到数组中：
- en: '[PRE101]'
  id: totrans-377
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: 'Instantiate a random forest classifier:'
  id: totrans-378
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化一个随机森林分类器：
- en: '[PRE102]'
  id: totrans-379
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: 'Train and test the classifier:'
  id: totrans-380
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练并测试分类器：
- en: '[PRE103]'
  id: totrans-381
  prefs: []
  type: TYPE_PRE
  zh: '[PRE103]'
- en: 'The following is the output:'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是输出结果：
- en: '[PRE104]'
  id: totrans-383
  prefs: []
  type: TYPE_PRE
  zh: '[PRE104]'
- en: How it works...
  id: totrans-384
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The greatest potential for a counterfeiting solution lies in obtaining a large
    dataset of images and using deep learning technology. In a regime where the dataset
    is relatively small, as is the case here, however, feature-engineering is mandatory.
    We begin attacking our problem by loading and then reading in a dataset into pandas
    (*Steps 1* and *2*). In the case of this dataset, a wavelet transform tool was
    used to extract features from the images. Next, in *Steps 3* and *4*, we train-test
    split the data and gather it into arrays. Finally, we fit and test a basic classifier
    on the dataset in *Steps 5* and *6*. The high score (98%) suggests that the features
    extracted for this dataset are indeed able to distinguish between authentic and
    counterfeit notes.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 解决伪造问题的最大潜力在于获取大量的图像数据集并使用深度学习技术。然而，在数据集相对较小的情况下（如本案例所示），特征工程是必不可少的。我们通过加载并读取数据集到
    pandas 中来开始解决问题（*步骤 1* 和 *步骤 2*）。在这个数据集的情况下，使用了小波变换工具从图像中提取特征。接下来，在*步骤 3* 和 *步骤
    4* 中，我们将数据进行训练-测试分割并汇总成数组。最后，在*步骤 5* 和 *步骤 6* 中，我们对数据集进行了基础分类器的训练和测试。高达 98% 的得分表明，从该数据集中提取的特征确实能够区分真实与伪造的钞票。
- en: Ad blocking using machine learning
  id: totrans-386
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用机器学习进行广告屏蔽
- en: Ad blocking is the operation of removing or altering online advertising in a
    web browser or an application. In this recipe, you will utilize machine learning
    to detect ads so that they can be blocked and you can browse hassle-free!
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 广告屏蔽是指在网页浏览器或应用程序中移除或更改在线广告。在这个食谱中，你将利用机器学习检测广告，以便能够屏蔽广告，畅快无忧地浏览！
- en: Getting ready
  id: totrans-388
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Preparation for this recipe involves installing `scikit-learn` and `pandas`
    in `pip`. The command is as follows:'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 准备这个食谱时，需要在 `pip` 中安装 `scikit-learn` 和 `pandas`。命令如下：
- en: '[PRE105]'
  id: totrans-390
  prefs: []
  type: TYPE_PRE
  zh: '[PRE105]'
- en: 'In preparation for this recipe, download the internet advertisements dataset
    from UCI''s machine learning repository: [https://archive.ics.uci.edu/ml/datasets/internet+advertisements](https://archive.ics.uci.edu/ml/datasets/internet+advertisements).'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 为了准备这个食谱，从 UCI 机器学习库下载互联网广告数据集：[https://archive.ics.uci.edu/ml/datasets/internet+advertisements](https://archive.ics.uci.edu/ml/datasets/internet+advertisements)。
- en: How to do it...
  id: totrans-392
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何实现……
- en: 'The following steps show how ad blocking is implemented using machine learning:'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤展示了如何使用机器学习实现广告屏蔽：
- en: Collect a dataset of internet advertisements.
  id: totrans-394
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 收集互联网广告的数据集。
- en: 'Import the data into a data frame using `pandas`:'
  id: totrans-395
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `pandas` 导入数据到数据框中：
- en: '[PRE106]'
  id: totrans-396
  prefs: []
  type: TYPE_PRE
  zh: '[PRE106]'
- en: 'The data is dirty in the sense of having missing values. Let''s find all the
    rows that have a missing value:'
  id: totrans-397
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据存在脏数据问题，即有缺失值。让我们找出所有缺失值的行：
- en: '[PRE107]'
  id: totrans-398
  prefs: []
  type: TYPE_PRE
  zh: '[PRE107]'
- en: 'In the case at hand, it makes sense to drop the rows with missing values, as
    seen in the following code:'
  id: totrans-399
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在当前的情况下，删除缺失值的行是合理的，如下代码所示：
- en: '[PRE108]'
  id: totrans-400
  prefs: []
  type: TYPE_PRE
  zh: '[PRE108]'
- en: 'Convert the label into numerical form:'
  id: totrans-401
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将标签转换为数值形式：
- en: '[PRE109]'
  id: totrans-402
  prefs: []
  type: TYPE_PRE
  zh: '[PRE109]'
- en: 'Split the data into training and testing data:'
  id: totrans-403
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据分为训练数据和测试数据：
- en: '[PRE110]'
  id: totrans-404
  prefs: []
  type: TYPE_PRE
  zh: '[PRE110]'
- en: 'Distribute the data into feature arrays and label arrays:'
  id: totrans-405
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据分配到特征数组和标签数组中：
- en: '[PRE111]'
  id: totrans-406
  prefs: []
  type: TYPE_PRE
  zh: '[PRE111]'
- en: 'Instantiate a random forest classifier and train it:'
  id: totrans-407
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化一个随机森林分类器并进行训练：
- en: '[PRE112]'
  id: totrans-408
  prefs: []
  type: TYPE_PRE
  zh: '[PRE112]'
- en: 'Score the classifier on the testing data:'
  id: totrans-409
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在测试数据上对分类器进行评分：
- en: '[PRE113]'
  id: totrans-410
  prefs: []
  type: TYPE_PRE
  zh: '[PRE113]'
- en: 'The following is the output:'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是输出结果：
- en: '[PRE114]'
  id: totrans-412
  prefs: []
  type: TYPE_PRE
  zh: '[PRE114]'
- en: How it works...
  id: totrans-413
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: 'We begin our recipe for blocking unwanted ads by importing the dataset. The
    data we have used in this recipe has been feature-engineered for us. In *Step
    2*, we import the data into a data frame. Looking at the data, we see that it
    consists of 1,558 numerical features and an ad or non-ad label:'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过导入数据集来开始阻止不必要广告的步骤。我们在这个食谱中使用的数据已经经过了特征工程处理。在*步骤 2* 中，我们将数据导入数据框。查看数据，我们发现它由
    1,558 个数值特征和一个广告或非广告标签组成：
- en: '![](assets/53966614-0e11-4d70-ac4b-cf54579b9517.png)'
  id: totrans-415
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/53966614-0e11-4d70-ac4b-cf54579b9517.png)'
- en: The features encode the geometry of the image, sentences in the URL, the URL
    of the image, alt text, anchor text, and words near the anchor text. Our goal
    is to predict whether an image is an advertisement (ad) or not (non-ad). We proceed
    to clean our data by dropping rows with missing values in *Steps*3 and *4*. Generally,
    it may make sense to use other techniques to impute missing values, such as using
    an average or most common value. Proceeding to *Step 5*, we convert our target
    to numerical form. Then, we train-test split our data in preparation for learning
    in *Steps 6* and *7*. Finally, in *Steps 8* and *9*, we fit and test a basic classifier
    on the data. The results suggest that the features do provide high discrimination
    power.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 特征编码了图像的几何形状、URL中的句子、图像的URL、alt文本、锚文本和靠近锚文本的单词。我们的目标是预测图像是否为广告（ad）或不是（non-ad）。我们通过在*步骤*3和*4*中删除缺失值的行来清理数据。通常，使用其他技术来填补缺失值是有意义的，比如使用平均值或最常见的值。继续到*步骤*5，我们将目标转换为数字形式。然后，在*步骤*6和*7*中，我们将数据进行训练集和测试集的拆分，为学习做好准备。最后，在*步骤*8和*9*中，我们在数据上训练并测试一个基本分类器。结果表明，这些特征确实提供了很高的区分能力。
- en: Recent approaches have utilized deep learning on screen images to tackle ads.
    The approach is very promising, but so far has been unsuccessful due to deep learning's
    adversarial sensitivity. With robustness to adversarial attacks improving in the
    field, deep learning-based ad blockers may become commonplace.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的方法利用深度学习处理屏幕图像来应对广告。这个方法非常有前景，但由于深度学习对对抗性攻击的敏感性，到目前为止并未成功。随着对抗攻击的鲁棒性在该领域的提升，基于深度学习的广告拦截器可能会变得普及。
- en: Wireless indoor localization
  id: totrans-418
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 无线室内定位
- en: Tales of a hacker parked outside a home, and hacking into their network for
    malice, are legendary. Though these tales may exaggerate the ease and motivation
    of this scenario, there are many situations where it is best to only permit users
    inside the home, or, in the case of an enterprise environment, in a designated
    area, to have specified network privileges. In this recipe, you will utilize machine
    learning to localize an entity based on the Wi-Fi signal. The dataset we will
    be working with was collected in an indoor space by observing signal strengths
    of seven Wi-Fi signals visible on a smartphone. One of the four rooms is the decision
    factor.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 黑客停在某个住宅外，恶意入侵他们的网络的故事堪称传奇。虽然这些故事可能夸大了此情景的易得性和动机，但在许多情况下，最佳做法是仅允许家中的用户，或者在企业环境中，仅允许特定区域的用户拥有指定的网络权限。在这个案例中，您将利用机器学习基于
    Wi-Fi 信号来定位一个实体。我们将使用的数据集是在室内空间收集的，数据通过观察智能手机上可见的七个 Wi-Fi 信号的信号强度获得。四个房间中的一个是决策因素。
- en: Getting ready
  id: totrans-420
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Preparation for this recipe involves installing `scikit-learn` and `pandas`.
    In your Python environment, run the following command:'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 本案例的准备工作包括安装 `scikit-learn` 和 `pandas`。在您的 Python 环境中，运行以下命令：
- en: '[PRE115]'
  id: totrans-422
  prefs: []
  type: TYPE_PRE
  zh: '[PRE115]'
- en: 'In preparation for this recipe, download the wireless indoor localization dataset
    from UCI''s machine learning repository: [https://archive.ics.uci.edu/ml/datasets/Wireless+Indoor+Localization.](https://archive.ics.uci.edu/ml/datasets/Wireless+Indoor+Localization)'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 为了准备本案例，下载 UCI 机器学习库中的无线室内定位数据集：[https://archive.ics.uci.edu/ml/datasets/Wireless+Indoor+Localization.](https://archive.ics.uci.edu/ml/datasets/Wireless+Indoor+Localization)
- en: How to do it…
  id: totrans-424
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'To localize an entity based on the Wi-Fi signal using machine learning, observe
    the following steps:'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 要利用机器学习基于 Wi-Fi 信号定位一个实体，请按照以下步骤操作：
- en: Collect a dataset of Wi-Fi signal strengths from different locations in the
    area of interest.
  id: totrans-426
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从感兴趣区域的不同位置收集 Wi-Fi 信号强度的数据集。
- en: 'Load the data into a data frame using `pandas`:'
  id: totrans-427
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `pandas` 将数据加载到数据框中：
- en: '[PRE116]'
  id: totrans-428
  prefs: []
  type: TYPE_PRE
  zh: '[PRE116]'
- en: 'Train-test split the data frame:'
  id: totrans-429
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据框分割为训练集和测试集：
- en: '[PRE117]'
  id: totrans-430
  prefs: []
  type: TYPE_PRE
  zh: '[PRE117]'
- en: 'Distribute the features and labels into an array:'
  id: totrans-431
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将特征和标签分配到数组中：
- en: '[PRE118]'
  id: totrans-432
  prefs: []
  type: TYPE_PRE
  zh: '[PRE118]'
- en: 'Instantiate a random forest classifier:'
  id: totrans-433
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化一个随机森林分类器：
- en: '[PRE119]'
  id: totrans-434
  prefs: []
  type: TYPE_PRE
  zh: '[PRE119]'
- en: 'Fit the classifier to the training data:'
  id: totrans-435
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将分类器拟合到训练数据上：
- en: '[PRE120]'
  id: totrans-436
  prefs: []
  type: TYPE_PRE
  zh: '[PRE120]'
- en: 'Predict on the testing dataset and print out the confusion matrix:'
  id: totrans-437
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在测试数据集上进行预测并打印出混淆矩阵：
- en: '[PRE121]'
  id: totrans-438
  prefs: []
  type: TYPE_PRE
  zh: '[PRE121]'
- en: 'The following output shows us the confusion matrix:'
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 以下输出显示了我们的混淆矩阵：
- en: '[PRE122]'
  id: totrans-440
  prefs: []
  type: TYPE_PRE
  zh: '[PRE122]'
- en: How it works…
  id: totrans-441
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理…
- en: '*Step 1* consists of assembling a dataset of Wi-Fi signal strengths from different
    locations in the area of interest. This is something that can be done relatively
    easily, simply by walking through a room with a GPS-enabled phone, and running
    a script to record the strength of the Wi-Fi. In *Step 2*, we read the data into
    a data frame, and then rename the target column to `room` so we know what it refers
    to. Moving on, in *Step*3, we train-test split our data in preparation for learning.
    We divide up the features and labels into arrays (*Step*4). Finally, in *Steps*5
    and 6, we train and test a basic classifier. Observe that the performance of the
    model is very high. This suggests that it is not a difficult task to localize
    a device based on the strength of the Wi-Fi signals that it is able to pick up,
    provided the region has been learned previously.'
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: '*第一步* 是从感兴趣区域的不同位置收集 Wi-Fi 信号强度的数据集。这是一个相对容易完成的任务，只需要带着启用 GPS 功能的手机走遍一个房间，并运行一个脚本记录
    Wi-Fi 的信号强度。在 *第二步* 中，我们将数据读取到数据框中，然后将目标列重命名为 `room`，这样我们就知道它指的是什么。接下来，在 *第三步*
    中，我们将数据进行训练测试集拆分，为学习做准备。我们将特征和标签拆分成数组（*第四步*）。最后，在 *第五步* 和第六步 中，我们训练并测试一个基本的分类器。观察到模型的表现非常优秀。这表明，基于设备能够接收到的
    Wi-Fi 信号强度进行定位并不是一项困难的任务，只要该区域已经被预先学习过。'
