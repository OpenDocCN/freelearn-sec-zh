- en: '9'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '9'
- en: Analyzing Network Evidence
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分析网络证据
- en: '[*Chapter 5*](B18571_05.xhtml#_idTextAnchor084) explored how incident responders
    and security analysts can acquire network-based evidence for later evaluation.
    That chapter focused on two primary sources of that evidence: network log files
    and network packet captures. This chapter will show you which tools and techniques
    are available to examine the evidence acquired. Incorporating these techniques
    into an incident response investigation can provide incident response analysts
    with insight into the network activity of possible threats.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第5章*](B18571_05.xhtml#_idTextAnchor084)探讨了事件响应人员和安全分析师如何获取基于网络的证据以供后续评估。该章节主要关注了两种证据来源：网络日志文件和网络数据包捕获。本章将展示可用于检查已获取证据的工具和技术。将这些技术融入事件响应调查，可以为事件响应分析师提供对潜在威胁的网络活动的洞察。'
- en: 'In this chapter, the following main topics will be addressed:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将重点讨论以下主要内容：
- en: Network evidence overview
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络证据概述
- en: Analyzing firewall and proxy logs
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析防火墙和代理日志
- en: Analyzing NetFlow
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析NetFlow
- en: Analyzing packet captures
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析数据包捕获
- en: Network evidence overview
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 网络证据概述
- en: Adversaries are bound to the same network protocols that govern normal network
    traffic. Here, adversarial techniques that can be identified by analyzing network
    data properly are addressed.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 攻击者被同样的网络协议约束，这些协议控制着正常的网络流量。本文将探讨通过正确分析网络数据来识别的对抗技术。
- en: In [*Chapter 5*](B18571_05.xhtml#_idTextAnchor084) we focused on the various
    sources of evidence that network devices produce. Most of this evidence is contained
    within the variety of log files produced by switches, routers, and firewalls.
    Depending on the type of environment that responders find themselves in, this
    evidence source can be augmented with NetFlow data and full packet captures.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第5章*](B18571_05.xhtml#_idTextAnchor084)中，我们重点关注了网络设备产生的各种证据。大多数这些证据包含在交换机、路由器和防火墙生成的各种日志文件中。根据响应人员所处的环境类型，这些证据来源可以通过NetFlow数据和完整的数据包捕获进行补充。
- en: 'Once the various sources have been understood, it is important to focus on
    what logs, NetFlow, and packet captures can tell us about an incident. The following
    are several areas of focus where proper logging and evidence collection may provide
    additional context surrounding an incident, as well as potential data points when
    deriving root cause:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦了解了各种来源，重要的是要关注日志、NetFlow和数据包捕获能告诉我们关于事件的哪些信息。以下是几个关注点，在这些领域中，适当的日志记录和证据收集可以为事件提供额外的背景信息，以及在分析根本原因时可能的数据点：
- en: '**Reconnaissance and scanning behavior**: There are a plethora of tools available
    to adversaries to automate the process of scanning perimeter devices such as firewalls
    and routers. These scanners attempt to ascertain open ports, vulnerabilities,
    or authentication protocols such as **Secure Shell** (**SSH**) that can be exploited.
    These scans do leave a trace as they will often require connections to the devices.
    Depending on the level of logging and the retention period, responders may be
    able to identify the external infrastructure that is attempting to compromise
    the perimeter systems.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**侦察与扫描行为**：攻击者可以利用众多工具来自动化扫描外围设备（如防火墙和路由器）的过程。这些扫描工具试图确定开放端口、漏洞或可以被利用的认证协议，如**安全外壳**（**SSH**）。这些扫描会留下痕迹，因为它们通常需要与设备建立连接。根据日志记录的级别和保留期限，响应人员可能能够识别出尝试破坏外围系统的外部基础设施。'
- en: '**Initial infection**: Adversaries have become very sophisticated in compromising
    systems. They will often make use of multi-stage exploits and malware. The first
    stage will call out to an external infrastructure through a URL and download additional
    exploits. Web proxies and firewalls may have connection data contained within
    the log files that record this activity.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**初始感染**：攻击者在入侵系统方面变得非常复杂。他们通常会利用多阶段的漏洞利用和恶意软件。第一阶段将通过URL调用外部基础设施并下载其他漏洞。Web代理和防火墙的日志文件中可能包含记录此活动的连接数据。'
- en: '**Lateral movement**: Once inside a network, adversaries will often attempt
    to conduct reconnaissance, exploit other systems, and move data around. NetFlow
    logs provide insight into this type of behavior.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**横向移动**：一旦进入网络，攻击者通常会尝试进行侦察、利用其他系统并移动数据。NetFlow日志可以提供对这种行为的洞察。'
- en: '**Command and control**: Once a foothold has been established in the network,
    adversaries require the ability to maintain control over compromised systems.
    Logs, packet captures, and NetFlow data may be leveraged to identify this type
    of behavior.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**指挥和控制**：一旦在网络中站稳脚跟，攻击者就需要能够维持对受损系统的控制。日志、数据包捕获和NetFlow数据可以用来识别这种行为。'
- en: '**Data exfiltration**: One of the goals of an adversary may be to compromise
    and exfiltrate data. Proxy logs may identify the destination of such data. NetFlow
    may show the flow of data from the internal systems to any external systems. Finally,
    packet captures may be leveraged to identify the exfiltrated files, the source
    of the data, and the destination.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据泄漏**：攻击者的目标之一可能是破坏并窃取数据。代理日志可能会识别这些数据的目的地。NetFlow可能会显示从内部系统到外部系统的数据流动。最后，数据包捕获可以用来识别泄露的文件、数据源以及目的地。'
- en: In [*Chapter 5*](B18571_05.xhtml#_idTextAnchor084) we discussed the three main
    types of network evidence that can be leveraged in an incident. It is often hard
    for responders that do not know about network traffic to understand its various
    aspects. Think about network traffic as a letter that is sent from one individual
    to another. Log data records the sender’s and receiver’s addresses and mailbox
    numbers at a central location, such as the local post office. This is akin to
    the source and destination IP addresses and ports.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第五章*](B18571_05.xhtml#_idTextAnchor084)中，我们讨论了在事件中可以利用的三种主要类型的网络证据。对于不了解网络流量的响应者来说，理解网络流量的各个方面往往是困难的。可以将网络流量看作是从一个人发送到另一个人的信件。日志数据记录了发送者和接收者的地址以及在一个中央位置（如本地邮局）的邮箱号码。这类似于源IP地址和目标IP地址以及端口。
- en: NetFlow records much of the same information about the letter but can also tell
    the individual the weight or relative size of the letter, along with the sender’s
    and receiver’s addresses and mailbox numbers. Finally, a packet capture tells
    us all the same information that’s obtained through logs and NetFlow but will
    also tell the individual the contents of the letter, including (so long as it
    is not encrypted) the actual data contained within.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: NetFlow记录了关于信件的许多相同信息，但还可以告诉个人信件的重量或相对大小，以及发送者和接收者的地址和邮箱号码。最后，数据包捕获提供了通过日志和NetFlow获得的所有信息，还会告诉个人信件的内容，包括（只要它没有加密）实际的数据。
- en: Identifying a root cause with network evidence is largely dependent on the evidence
    itself. One major drawback to evidence such as packet captures and log files is
    the sheer volume of data that normal network operations create. Often, an incident
    is identified days or even weeks after it has occurred. During this intervening
    period, these log files and packet captures become unavailable. Therefore, it
    is incumbent on responders to fully understand what their organization’s capabilities
    are regarding network evidence.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 通过网络证据识别根本原因在很大程度上取决于证据本身。像数据包捕获和日志文件这样的证据的一个主要缺点是，正常网络操作所产生的数据量巨大。通常，事件发生后几天甚至几周才会被识别。在此期间，这些日志文件和数据包捕获可能变得无法获取。因此，响应者必须充分理解他们组织在网络证据方面的能力。
- en: Analyzing firewall and proxy logs
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分析防火墙和代理日志
- en: Adversaries need to make initial and continued connections to their infrastructure.
    Network devices such as firewalls and proxies may provide a source of evidence
    from log files.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 攻击者需要与其基础设施建立初始连接并保持持续连接。网络设备如防火墙和代理可能提供日志文件作为证据来源。
- en: '[*Chapter 5*](B18571_05.xhtml#_idTextAnchor084) contained a good deal of information
    concerning the acquisition of network-based evidence and the types of log files
    that are of importance to an incident responder or security analyst. Aside from
    the previously covered packet capture, we focused on the acquisition of log files
    from a variety of sources. These log files can provide some insight into the potential
    indicators of compromise that can aid in an incident investigation. The main challenge
    for analysts, though, is sifting through all of the irrelevant logs to find those
    that have some evidential value.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第五章*](B18571_05.xhtml#_idTextAnchor084)包含了有关获取基于网络的证据以及对事件响应者或安全分析师重要的日志文件类型的大量信息。除了之前讨论的数据包捕获外，我们还重点关注了从多种来源获取日志文件。这些日志文件可以为可能的入侵指示提供一些线索，帮助事件调查。然而，分析师面临的主要挑战是从大量无关的日志中筛选出那些具有证据价值的日志。'
- en: 'Log file analysis can be performed in a variety of ways. The specific method
    that is used may often depend on the type of incident, the tools available, and
    the amount of log data that has to be analyzed. The following are some of the
    methods that can be utilized:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 日志文件分析可以通过多种方式进行。使用的具体方法通常取决于事件的类型、可用的工具和需要分析的日志数据量。以下是一些可以使用的方法：
- en: '**Manual log review**: In a manual log review, raw log files are dumped into
    a tool such as a text editor. From there, the analyst will review the logs line
    by line. This is a low-cost solution, but it is only useful with a limited amount
    of data. For example, an analyst would not be able to perform this type of analysis
    on a large enterprise firewall connection log. Rather, it may be useful to determine
    which users logged into a seldom-used web application on a particular day.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**手动日志审查**：在手动日志审查中，原始日志文件会被导入到像文本编辑器这样的工具中。之后，分析人员将逐行审查日志。这是一种低成本的解决方案，但仅在数据量有限时有用。例如，分析人员无法在大型企业防火墙连接日志上执行此类分析。然而，它可能对确定某个特定日期有哪些用户登录到不常用的Web应用程序有帮助。'
- en: '**Filtered log review**: Log review tools allow analysts to filter out log
    files in terms of specific parameters. This can include showing a list of any
    known malicious activity. The one drawback is that logs may not immediately indicate
    known malicious activity, but rather are innocuous at the onset.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**过滤日志审查**：日志审查工具允许分析人员根据特定参数过滤日志文件。这可以包括显示已知恶意活动的列表。一个缺点是，日志可能不会立即指示已知的恶意活动，而是在最初阶段看起来无害。'
- en: '**Log file searching**: Another key feature in most log analysis tools is the
    ability to search log files for specific expressions. Tools for searching can
    utilize both regex and Boolean expressions and allow the analyst to limit logs
    to a specific period, source IP address, or other specific condition. This allows
    analysts to quickly isolate specific log files. Depending on the search terms,
    this may return a good deal of information that has to then be reviewed manually.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**日志文件搜索**：大多数日志分析工具的另一个关键功能是能够搜索日志文件中的特定表达式。搜索工具可以利用正则表达式和布尔表达式，并允许分析人员将日志限制在特定的时间段、源IP地址或其他特定条件下。这使得分析人员可以迅速定位特定的日志文件。根据搜索词的不同，这可能返回大量的信息，需要手动进一步审查。'
- en: '**Log file correlation**: Separate log activity can be correlated with other
    logs based on either preconfigured rules or algorithms. Log correlation is often
    made part of log management tools or **Security Information and Event Management**
    (**SIEM**) platforms with rulesets that have been created. This method is very
    powerful as it automates the process, but it does require a good deal of upfront
    labor to configure and tune the specific environment.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**日志文件关联**：可以根据预配置的规则或算法将不同的日志活动与其他日志进行关联。日志关联通常是日志管理工具或**安全信息和事件管理**（**SIEM**）平台的一部分，这些工具带有已创建的规则集。这种方法非常强大，因为它自动化了过程，但也需要大量的前期劳动来配置和调整特定环境。'
- en: '**Log file data mining**: The next step up from correlation is the ability
    to mine log files and extract meaning from them. This gives greater context and
    insight into the specific activity. At the time of writing, there are several
    tools, such as Elasticsearch and Logstash, that can be integrated into a platform
    for more useful information.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**日志文件数据挖掘**：比关联更进一步的是能够从日志文件中提取有意义的信息。这为特定活动提供了更多的上下文和洞察力。在撰写本文时，已有多个工具（如Elasticsearch和Logstash）可以集成到平台中，以提供更有用的信息。'
- en: The number of logs that are produced in a network over a month or so can be
    staggering. This quantity only increases with the addition of new sources. Sorting
    through these manually is nearly impossible. In terms of log review, it is better
    to have a solution that provides some measure of automation, even in small networks.
    These tools give analysts the ability to sort through the proverbial haystack
    for that critical needle.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 网络中每月产生的日志数量可能是惊人的。随着新来源的增加，这一数量只会进一步增加。手动筛选这些日志几乎是不可能的。在日志审查方面，最好有一个能够提供一定自动化程度的解决方案，即使是在小型网络中。这些工具使分析人员能够在成千上万的日志中找到那根关键的针。
- en: SIEM tools
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SIEM工具
- en: SIEM tools are critical to gaining situational awareness of activity across
    the network. These platforms not only serve as an aggregation point for log files
    from network devices, but they also allow analysts to perform queries on the logs
    that have been aggregated. For example, let’s say that IP addresses associated
    with potential malicious activity were discovered during the analysis of the packet
    capture file. This file was limited to a single host on the internal network.
    One question that analysts would like to answer is, how many other hosts could
    be infected? If the SIEM aggregates connection log files from devices such as
    the exterior facing firewall and web proxy, the analyst would be able to determine
    whether any other internal hosts are connected to those suspect IP addresses.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: SIEM工具对于获得网络活动的态势感知至关重要。这些平台不仅充当来自网络设备的日志文件的聚合点，还允许分析员对已聚合的日志进行查询。例如，假设在分析数据包捕获文件时，发现了与潜在恶意活动相关的IP地址。这个文件仅限于内部网络上的一台主机。分析员希望回答的一个问题是，其他多少台主机可能已经被感染？如果SIEM聚合了来自外部防火墙和Web代理等设备的连接日志文件，分析员就能够确定是否有其他内部主机连接到这些可疑的IP地址。
- en: A wide variety of SIEM platforms are available, from freeware solutions to enterprise
    security management platforms. Most of these platforms allow analysts to conduct
    filtered searching and correlation log reviews. Many of the more robust commercial
    platforms provide rulesets for detecting specific types of attacks and updates
    to these rulesets as new attacks become known. Analysts could also query the SIEM
    tool for connection logs for the host IP address to any other systems. This would
    normally be the behavior seen in an incident where malware has infected a machine
    and an attacker is attempting to compromise other machines.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 有多种SIEM平台可供选择，从免费的解决方案到企业级安全管理平台。这些平台大多数允许分析员进行过滤搜索和关联日志审查。许多更强大的商业平台提供了检测特定类型攻击的规则集，并随着新攻击的出现更新这些规则集。分析员还可以查询SIEM工具，以获取主机IP地址与其他系统的连接日志。这通常是恶意软件感染机器后，攻击者试图攻破其他机器时的行为表现。
- en: In organizations where incident response personnel are separate from those who
    are responsible for maintaining the SIEM tool, it is a good idea to review the
    communications structure so that incident response analysts have access to these
    platforms. The wealth of information and data that is available can be leveraged
    to determine what activity on the internal network is connected to a possible
    incident, as well as evidence that can be utilized to determine the root cause.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在事件响应人员与负责维护SIEM工具的人员分开的组织中，最好审查一下通信结构，以确保事件响应分析员可以访问这些平台。可用的大量信息和数据可以帮助确定内部网络上哪些活动与可能的事件相关，以及可以用来确定根本原因的证据。
- en: The Elastic Stack
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Elastic Stack
- en: Alongside the SIEM technology, incident response analysts can also leverage
    a bundle of applications for log analysis. This bundle, referred to as the Elastic
    Stack, combines three tools that allow large sets of data to be analyzed. The
    first of these is Elasticsearch. Elasticsearch is a log-searching tool that allows
    near real-time searching of log data. This is accomplished through full-text searching,
    powered by Lucene. This allows analysts to perform queries against log files for
    elements such as user IDs, IP addresses, or log entry numbers. Another key feature
    of Elasticsearch is the ability of the platform to expand the solution as the
    enterprise grows larger and gains more data sources. This is useful for organizations
    that may want to test this capability and then add data sources and log files
    incrementally.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 除了SIEM技术外，事件响应分析员还可以利用一系列应用程序进行日志分析。这一系列工具被称为Elastic Stack，它结合了三种工具，能够分析大量数据。第一个工具是Elasticsearch。Elasticsearch是一个日志搜索工具，允许对日志数据进行近实时搜索。这是通过Lucene驱动的全文搜索实现的。这使得分析员能够针对日志文件中的元素（如用户ID、IP地址或日志条目编号）执行查询。Elasticsearch的另一个关键特性是平台能够随着企业的增长和数据源的增加，扩展解决方案。这对于那些可能希望先测试此功能，然后逐步添加数据源和日志文件的组织来说非常有用。
- en: The next component in the Elastic Stack is Logstash. Logstash is the mechanism
    that handles the intake of log files from the sources across the network, processes
    log entries, and, finally, allows them to be output through a visualization platform.
    Logstash can be configured and deployed easily. The integration of Logstash with
    Elasticsearch allows the incident response analyst to conduct fast queries against
    a large amount of log data.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: Elastic Stack 中的下一个组件是 Logstash。Logstash 是处理来自网络各个来源的日志文件输入、处理日志条目，并最终通过可视化平台输出它们的机制。Logstash
    可以轻松配置和部署。Logstash 与 Elasticsearch 的集成使得事件响应分析师能够对大量日志数据进行快速查询。
- en: The final component of the Elastic Stack is Kibana. Kibana serves as the visual
    interface or dashboard of the Elastic Stack. This platform allows analysts to
    gain insight into the data through the use of dashboards. Kibana also allows analysts
    to drill down into specific key data points for detailed analysis. Incident response
    analysts can customize these dashboards so that the most critical information,
    such as intrusion detection logs or connection logs, is immediately available
    for review.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: Elastic Stack 的最终组件是 Kibana。Kibana 作为 Elastic Stack 的可视化界面或仪表板，允许分析师通过仪表板洞察数据。Kibana
    还允许分析师深入到特定的关键数据点进行详细分析。事件响应分析师可以自定义这些仪表板，以便最重要的信息，如入侵检测日志或连接日志，能够立即供审阅。
- en: For example, the Kibana dashboard utilizes several pie charts to display log
    activity. Utilizing these provides an overview of what information is available
    to an analyst.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，Kibana 仪表板利用多个饼图来展示日志活动。利用这些图表可以概览分析师可用的信息。
- en: A good tool to augment logs is NetFlow analysis, which we will cover next.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 增强日志的一个好工具是 NetFlow 分析，我们将在接下来介绍。
- en: Analyzing NetFlow
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分析 NetFlow
- en: NetFlow describes the data about connections between devices in the network.
    Used primarily to troubleshoot connectivity and bandwidth issues, NetFlow can
    be used by responders to gain insight into the movement of data precipitating
    an incident.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: NetFlow 描述了网络中设备之间连接的数据。NetFlow 主要用于故障排除连接性和带宽问题，事件响应人员可以使用 NetFlow 获得数据流动的洞察，从而引发事件。
- en: NetFlow is a feature that was first introduced by Cisco Systems in the 1990s.
    NetFlow collects specific data about packets as they enter or exit an interface
    of a router or switch. This data is then sent to a NetFlow Collector via a NetFlow
    Exporter, which is often made part of switches or routers. The NetFlow Collector
    then aggregates and stores the flow data for analysis. This data is often leveraged
    by network and systems administrators to troubleshoot bandwidth issues, identify
    network congestion, and observe the flow of data.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: NetFlow 是由 Cisco Systems 在 1990 年代首次推出的一个功能。NetFlow 收集关于数据包的特定数据，当它们进入或退出路由器或交换机的接口时。这些数据随后通过
    NetFlow 导出器发送到 NetFlow 收集器，NetFlow 导出器通常作为交换机或路由器的一部分。NetFlow 收集器随后汇总并存储流数据以供分析。网络和系统管理员通常利用这些数据来排查带宽问题、识别网络拥堵以及观察数据流动情况。
- en: 'A sample NetFlow output can be seen in the following screenshot. What is included
    with flow data can vary between network device manufacturers as there are several
    versions in the commercial market. The following screenshot shows some of the
    basic information that is captured as part of a NetFlow dataset:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图中可以看到一个 NetFlow 输出的示例。流数据包含的内容在网络设备制造商之间可能有所不同，因为商业市场上有多个版本。以下截图显示了作为 NetFlow
    数据集一部分所捕获的一些基本信息：
- en: '![](img/Image_B18571_09_01.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Image_B18571_09_01.jpg)'
- en: Figure 9.1 – Sample NetFlow data
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.1 – 示例 NetFlow 数据
- en: 'The following components of a NetFlow record can be seen in the preceding screenshot:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是前面截图中可以看到的 NetFlow 记录的组成部分：
- en: '**Src Addr**: This is the source address that has initiated the connection
    or is sending traffic.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Src Addr**：这是启动连接或发送流量的源地址。'
- en: '**Dst Addr**: The destination addresses for the connection.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Dst Addr**：连接的目标地址。'
- en: '**Sport**: This is the source port for the source address.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Sport**：这是源地址的源端口。'
- en: '**Dport**: This is the destination port. In terms of analyzing NetFlow as part
    of an incident investigation, this is one of the key data points to focus on as
    this often tells responders the service that the source address is connecting
    to.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Dport**：这是目标端口。在将 NetFlow 作为事件调查的一部分进行分析时，这是需要关注的关键数据点之一，因为它通常能告诉响应人员源地址正在连接的服务。'
- en: '**Proto**: This is the protocol in use.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Proto**：这是使用的协议。'
- en: '**Packets**: The number of packets that are made as part of the flow.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据包**：作为流的一部分所生成的数据包数量。'
- en: '**Bytes**: The total number of bytes.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**字节**：字节的总数。'
- en: '**Flows**: This indicates how many flows have been recorded. Flows can be thought
    of as separate TCP connections. For example, a packet capture analyzed with a
    tool such as Wireshark will show individual packets. Flows indicate the TCP session
    that was established. In this circumstance, if an SSH session is interrupted and
    established, two flows would be recorded.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**流**：这表示已记录的流的数量。流可以视为独立的TCP连接。例如，使用像Wireshark这样的工具分析数据包捕获时，会显示单独的数据包。流指示已建立的TCP会话。在这种情况下，如果SSH会话中断并重新建立，则会记录两个流。'
- en: When examining the NetFlow data shown in the preceding example, two significant
    data points may be important. The first is the number of SSH connections between
    devices. Secure Shell is a common way for systems to communicate with each other,
    but if this is outside the bounds of normal network behavior, it warrants a follow-up.
    In addition, connections via SMB (port `445`) are commonly abused by adversaries
    to access other systems, deliver ransomware, or access file shares. Even in this
    short example, it becomes very clear that responders gain a great deal of insight
    by just having visibility of the connections that occur on the internal network.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在检查前面的NetFlow数据时，两个重要的数据点可能值得关注。第一个是设备之间的SSH连接数量。安全外壳（SSH）是系统之间常用的通信方式，但如果它超出了正常网络行为的范围，则需要进一步调查。此外，通过SMB（端口`445`）的连接常常被攻击者滥用，用于访问其他系统、传播勒索软件或访问文件共享。即使在这个简短的示例中，也可以清楚地看到，响应人员通过仅查看内部网络上发生的连接，就能获得大量的洞察信息。
- en: Analyzing packet captures
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分析数据包捕获
- en: One of the best sources of evidence during an incident is packet captures. Dissecting
    them can uncover data exfiltration, exploits, and command and control.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 事件发生时，最好的证据来源之一是数据包捕获。分析这些数据包可以揭示数据外泄、漏洞利用以及命令和控制。
- en: A great deal of [*Chapter 5*](B18571_05.xhtml#_idTextAnchor084) covered the
    various methods to obtain packet captures from a range of sources and a variety
    of locations. Packet captures contain a great deal of information that is potentially
    valuable to incident response analysts. Some of this information includes source
    and destination IP addresses, domains and ports, and the content of communications
    between hosts. In some instances, incident response analysts can reconstruct actual
    files, such as text documents and images. The main drawback is the sheer amount
    of data that is involved.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第5章*](B18571_05.xhtml#_idTextAnchor084)详细介绍了从各种来源和不同位置获取数据包捕获的多种方法。数据包捕获包含大量潜在对事件响应分析员有价值的信息。其中一些信息包括源和目的地IP地址、域名和端口，以及主机之间通信的内容。在某些情况下，事件响应分析员可以重建实际文件，例如文本文件和图像。主要的缺点是涉及的数据量非常庞大。'
- en: Sample packet captures
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 示例数据包捕获
- en: This chapter refers to several preconfigured packet captures. These packet captures
    have been taken directly from [http://malware-traffic-analysis.net/](http://malware-traffic-analysis.net/)
    by permission of the author. This site contains several packet capture exercises,
    where incident response analysts can practice locating indicators of compromise.
    It should be noted, though, that these captures may contain malware. You should
    only examine the live packet captures in a properly configured sandbox (see [*Chapter
    16*](B18571_16.xhtml#_idTextAnchor284)) or another system not connected to a production
    environment.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 本章提到了一些预先配置好的数据包捕获。这些数据包捕获直接来源于[http://malware-traffic-analysis.net/](http://malware-traffic-analysis.net/)，并得到了作者的许可。该网站包含多个数据包捕获练习，事件响应分析员可以在这些练习中练习定位妥协迹象。不过需要注意的是，这些捕获可能包含恶意软件。你应该仅在正确配置的沙盒环境中（见[*第16章*](B18571_16.xhtml#_idTextAnchor284)）或其他不与生产环境连接的系统中检查实时数据包捕获。
- en: Command-line tools
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 命令行工具
- en: 'Several command-line tools can be utilized when analyzing network packet captures.
    During more in-depth or lengthy incident response engagements, analysts may gather
    several packet capture files. It may be beneficial to combine these multiple packet
    captures into a single file to make analysis easier. The Mergecap application
    does just that by combining several packet capture files. Mergecap is offered
    as part of the SANS SIFT workstation and can be executed using the following command:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 分析网络数据包捕获时可以使用多个命令行工具。在更深入或较长时间的事件响应工作中，分析员可能会收集多个数据包捕获文件。将这些多个数据包捕获文件合并成一个文件可以使分析变得更加简便。Mergecap
    应用程序正是通过将多个数据包捕获文件合并来实现这一点。Mergecap 是 SANS SIFT 工作站的一部分，可以通过以下命令执行：
- en: '[PRE0]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Another command-line tool that is useful in analyzing packet captures is Editcap.
    Editcap allows analysts to manipulate the packet capture files into smaller segments
    for easier review. For example, an analyst may only want to look at captures that
    are broken up into 50,000 packet segments. This would be helpful if an analyst
    has a large packet capture and dividing would make searching easier. To do this,
    the analyst would type the following into the command line:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个在分析数据包捕获时非常有用的命令行工具是 Editcap。Editcap 允许分析员将数据包捕获文件分割成更小的段，便于审查。例如，分析员可能只希望查看被拆分成
    50,000 个数据包段的捕获文件。如果分析员有一个很大的数据包捕获文件，分割文件会使得搜索更加高效。为此，分析员可以在命令行中输入以下命令：
- en: '[PRE1]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'In the preceding command, `editcap` took the `evidence.pcap` evidence file
    and divided it into 50,000 packet segments. Another technique that Editcap can
    be leveraged for is to divide a larger packet capture into time segments. For
    example, if analysts want to divide a packet capture into 10-minute segments,
    they can type the following:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的命令中，`editcap` 将 `evidence.pcap` 证据文件分割成了 50,000 个数据包段。Editcap 还可以用来将较大的数据包捕获文件按时间段进行分割。例如，如果分析员希望将数据包捕获文件按
    10 分钟为一个段来分割，他们可以输入以下命令：
- en: '[PRE2]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Analysts may also find that, in some circumstances, they may want to isolate
    domain name registration traffic. This is due in large part to a variety of adversarial
    actions such as C2 traffic, data exfiltration, and the possible redirection to
    compromised websites, often leveraging vulnerabilities in the DNS system. The
    `dnstop` application parses packet capture files and ascertains the sources and
    count of DNS queries from internal hosts. To install it on a Linux system, you
    can use the following command:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 分析员还可能会发现，在某些情况下，他们可能希望隔离域名注册流量。这在很大程度上是由于各种对抗性行为，如 C2 流量、数据外泄，以及可能通过利用 DNS
    系统中的漏洞重定向到受损网站。`dnstop` 应用程序解析数据包捕获文件并确定来自内部主机的 DNS 查询的来源和数量。要在 Linux 系统上安装它，可以使用以下命令：
- en: '[PRE3]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This command will download and install `dnstop`. In the following example,
    the packet capture was taken from the Malware Traffic Analysis site located at
    [https://www.malware-traffic-analysis.net/2022/03/21/index2.html](https://www.malware-traffic-analysis.net/2022/03/21/index2.html).
    If an incident response analyst wants to determine whether any IP addresses were
    sending outbound DNS queries for packet capture, they can simply execute the following
    command:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令将下载并安装 `dnstop`。在以下示例中，数据包捕获是从位于 [https://www.malware-traffic-analysis.net/2022/03/21/index2.html](https://www.malware-traffic-analysis.net/2022/03/21/index2.html)
    的恶意软件流量分析网站获取的。如果事件响应分析员想要确定是否有任何 IP 地址正在发送外发的 DNS 查询，他们只需执行以下命令：
- en: '[PRE4]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The output of the preceding command is as follows:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 上述命令的输出结果如下：
- en: '![](img/Image_B18571_09_02.jpg)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Image_B18571_09_02.jpg)'
- en: Figure 9.2 – DNS query count
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.2 – DNS 查询计数
- en: Real Intelligence Threat Analytics
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实时威胁情报分析
- en: One challenge with working with packet captures is the sheer amount of data
    that is involved. A 24-hour packet capture from even a modest-sized network presents
    problems. One technique is to use tools that focus on key data points. For example,
    beaconing traffic associated with Command and Control is a critical piece of data
    to find as it is the link the adversary has to the internal network.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 使用数据包捕获时的一个挑战是涉及的数据量非常庞大。即使是来自中型网络的 24 小时数据包捕获也会带来问题。一种方法是使用关注关键数据点的工具。例如，与命令和控制（C2）相关的信标流量是需要查找的重要数据，因为它是对手与内部网络之间的连接。
- en: One tool that can assist is Active Countermeasure’s **Real Intelligence Threat
    Analytics** (**RITA**). This command-line tool uses behavioral analytics to identify
    patterns that are indicative of beaconing behavior so that an analyst can focus
    on a specific IP address or domain name. A key feature of this tool is its ability
    to process large packet captures, such as one obtained over 24 hours. This allows
    analysts to locate even very low and slow Command and Control traffic.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 一个可以提供帮助的工具是Active Countermeasure的**实时智能威胁分析**(**RITA**)工具。这个命令行工具利用行为分析来识别表明信标行为的模式，以便分析师能够专注于特定的IP地址或域名。这个工具的一个关键特性是它能够处理大型数据包捕获文件，例如通过24小时内的捕获得到的文件。这使得分析师能够找到即便是非常低速的命令与控制流量。
- en: 'Installing RITA is very straightforward. In this case, RITA has been installed
    on an Ubuntu desktop. First, make a directory for RITA. Second, download the installation
    script from the GitHub site at [https://github.com/activecm/rita/releases/tag/v4.5.1](https://github.com/activecm/rita/releases/tag/v4.5.1).
    Next, make the file executable by running the following command:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 安装RITA非常简单。在这个案例中，RITA已安装在Ubuntu桌面上。首先，创建一个RITA目录。其次，从GitHub网站下载安装脚本：[https://github.com/activecm/rita/releases/tag/v4.5.1](https://github.com/activecm/rita/releases/tag/v4.5.1)。接下来，运行以下命令使文件可执行：
- en: '[PRE5]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Next, execute the install script by running the following:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，通过运行以下命令执行安装脚本：
- en: '[PRE6]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The installation script will install the necessary dependencies, such as the
    Mongo database structure and the packet capture analysis tool Zeek.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 安装脚本会安装必要的依赖项，例如Mongo数据库结构和数据包捕获分析工具Zeek。
- en: Zeek
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: Zeek
- en: Zeek is a network monitoring and analysis tool that is used with RITA. For more
    information regarding Zeek, go to [https://docs.zeek.org/en/lts/](https://docs.zeek.org/en/lts/).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: Zeek是一个网络监控和分析工具，它与RITA一起使用。如需了解有关Zeek的更多信息，请访问[https://docs.zeek.org/en/lts/](https://docs.zeek.org/en/lts/)。
- en: 'The next step is processing the packet capture. In this case, two packet captures
    were taken from the Malware Traffic Analysis post at [https://malware-traffic-analysis.net/2022/01/27/index.html](https://malware-traffic-analysis.net/2022/01/27/index.html)
    and were merged into a single file. This file was moved into the RITA directory.
    The following command points Zeek to the packet capture so that it can be processed
    into the various log files:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是处理数据包捕获。在这种情况下，两个数据包捕获文件来自[https://malware-traffic-analysis.net/2022/01/27/index.html](https://malware-traffic-analysis.net/2022/01/27/index.html)上的恶意软件流量分析帖子，并已合并为一个文件。这个文件被移动到RITA目录中。以下命令将Zeek指向数据包捕获文件，以便它能够处理成各种日志文件：
- en: '[PRE7]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Checking the files in the directory shows the processed log files:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 检查目录中的文件，显示已处理的日志文件：
- en: '![](img/Image_B18571_09_03.jpg)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Image_B18571_09_03.jpg)'
- en: Figure 9.3 – Zeek log files
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.3 – Zeek日志文件
- en: 'After processing the packet capture with Zeek, the log files need to be imported
    into a database, `IcedID`, that RITA can read with the following command:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用Zeek处理数据包捕获后，日志文件需要导入到RITA可以读取的数据库`IcedID`中，使用以下命令：
- en: '[PRE8]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Once this command is run, the results should look as follows:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦运行该命令，结果应如下所示：
- en: '![](img/Image_B18571_09_04.jpg)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Image_B18571_09_04.jpg)'
- en: Figure 9.4 – RITA Zeek log import
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.4 – RITA Zeek日志导入
- en: 'To access the help menu for RITA, enter the following:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问RITA的帮助菜单，请输入以下命令：
- en: '[PRE9]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This will produce the following commands and associated results:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下命令及相关结果：
- en: '![](img/Image_B18571_09_05.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Image_B18571_09_05.jpg)'
- en: Figure 9.5 – RITA features
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.5 – RITA功能
- en: 'Let’s go ahead and see if there are any packets indicating beaconing behavior.
    Run the `show-beacons` command against the database that was previously created
    by running the `IcedID` database:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续查看是否有任何数据包表明信标行为。运行`show-beacons`命令，针对之前通过运行`IcedID`数据库创建的数据库进行操作：
- en: '[PRE10]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This produces the following:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 这会产生以下结果：
- en: '![](img/Image_B18571_09_06.jpg)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Image_B18571_09_06.jpg)'
- en: Figure 9.6 – RITA Beacon analysis
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.6 – RITA信标分析
- en: In *Figure 9**.6*, RITA is indicating that the internal IP address `10.1.28.101`
    has established 234 connections to the IP address `149.255.35.174`. One result
    that is of note is the first number, `0.838`, found at the beginning of the results
    line. This score indicates the confidence level RITA has in these results, from
    0 to 1\. In this case, there’s nearly 84% confidence that the traffic is beaconing
    behavior.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图 9.6*中，RITA指示内部IP地址`10.1.28.101`已与IP地址`149.255.35.174`建立了234个连接。值得注意的一个结果是结果行开头的第一个数字`0.838`。这个分数表示RITA对这些结果的置信度，范围从0到1。在这种情况下，几乎有84%的置信度认为该流量是信标行为。
- en: 'Another option is to run the `show-beacons-fqdn` command, which will show the
    domain names of systems:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个选项是运行`show-beacons-fqdn`命令，它将显示系统的域名：
- en: '[PRE11]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'This produces much of the same results but indicates that the Command and Control
    server has a domain name of `driverpackcdn.com`, as shown here:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这产生了类似的结果，但表明命令与控制服务器的域名为`driverpackcdn.com`，如下所示：
- en: '![](img/Image_B18571_09_07.jpg)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Image_B18571_09_07.jpg)'
- en: Figure 9.7 – RITA Beacon Fully Qualified Domain Name
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.7 – RITA Beacon 完全限定域名
- en: As we can see, RITA allows analysts to focus on specific IP addresses and domain
    names as potentially malicious without having to dig through gigabytes of packet
    data. From here, they can pivot directly to the connections that are critical
    in GUI-based tools, which we will focus on next.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，RITA 允许分析人员专注于特定的 IP 地址和域名，作为潜在的恶意目标，而无需挖掘数以 GB 计的数据包信息。从这里，他们可以直接转到关键的连接，这些连接在基于
    GUI 的工具中是至关重要的，我们接下来将重点讨论这一部分。
- en: NetworkMiner
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: NetworkMiner
- en: GUI-based tools that separate packet capture data are easier to navigate than
    command-line tools. One such tool is NetworkMiner, which is available at [https://www.netresec.com/?page=NetworkMiner](https://www.netresec.com/?page=NetworkMiner).
    This tool is available as a commercial or community tool, with the community tool
    having more limited functionality. Despite this, the community edition does have
    some key features that are useful in analyzing packet captures.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 与命令行工具相比，分离数据包捕获数据的基于 GUI 的工具更容易操作。一个这样的工具是 NetworkMiner，可以在[https://www.netresec.com/?page=NetworkMiner](https://www.netresec.com/?page=NetworkMiner)找到。该工具有商业版和社区版，社区版功能更有限。尽管如此，社区版仍具备一些在分析数据包捕获时非常有用的关键特性。
- en: 'In this demonstration, we will examine the PCAP file associated with a Hancitor
    infection, which can be downloaded from [https://malware-traffic-analysis.net/2022/03/21/index2.html](https://malware-traffic-analysis.net/2022/03/21/index2.html).
    Load the PCAP data by going to **File** and selecting **Open**. Navigate to the
    packet capture and click **Open**. NetworkMiner will process the PCAP and display
    the hosts found in the packet capture:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在本演示中，我们将查看与 Hancitor 感染相关的 PCAP 文件，可以从 [https://malware-traffic-analysis.net/2022/03/21/index2.html](https://malware-traffic-analysis.net/2022/03/21/index2.html)
    下载。通过选择 **文件** 并点击 **打开** 来加载 PCAP 数据。导航到数据包捕获文件并点击 **打开**。NetworkMiner 会处理 PCAP
    文件并显示数据包捕获中找到的主机：
- en: '![](img/Image_B18571_09_08.jpg)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Image_B18571_09_08.jpg)'
- en: Figure 9.8 – NetworkMiner GUI
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.8 – NetworkMiner GUI
- en: 'The next tab, **Files**, shows the files that were contained within the packet
    capture:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个标签页，**文件**，显示了数据包捕获中包含的文件：
- en: '![](img/Image_B18571_09_09.jpg)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Image_B18571_09_09.jpg)'
- en: Figure 9.9 – NetworkMiner’s Files tab
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.9 – NetworkMiner 的文件标签页
- en: 'If you drill down further into the `b123.exe` file that was downloaded from
    `bor4omkin.ru` with an IP address of `45.8.124.233`:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你进一步深入查看从`bor4omkin.ru`下载的`b123.exe`文件，源 IP 地址为`45.8.124.233`：
- en: '![](img/Image_B18571_09_10.jpg)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Image_B18571_09_10.jpg)'
- en: Figure 9.10 – Suspect files
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.10 – 可疑文件
- en: In addition to visualizing files that were contained within the packet capture,
    NetworkMiner also extracts them and places them in the `AssembledFiles` directory,
    broken down by IP address. This allows analysts to quickly identify suspect files
    and analyze them.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 除了可视化数据包捕获中的文件外，NetworkMiner 还会提取它们并将它们放入按 IP 地址分类的`AssembledFiles`目录中。这使得分析人员可以快速识别可疑文件并进行分析。
- en: NetworkMiner is a useful tool for an initial review of packet captures. It provides
    details about the files, DNS queries, sessions, and other key data points. The
    main advantage that can be leveraged is its ability to quickly focus on key data
    points so that analysts can focus on specific areas, without having to dig through
    an entire packet capture to find the key evidence items.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: NetworkMiner 是一个非常有用的工具，用于初步查看数据包捕获。它提供有关文件、DNS 查询、会话和其他关键数据点的详细信息。它的主要优势在于能够快速聚焦于关键数据点，从而使分析人员可以集中精力查看特定领域，而无需挖掘整个数据包捕获来寻找关键证据。
- en: Arkime
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Arkime
- en: Arkime is an open source packet capture and search system that allows analysts
    and responders to examine large network packet captures. By default, Arkime organizes
    the packet captures into the various sessions contained within the capture. Arkime
    can be utilized as a network monitoring system that can be leveraged by importing
    packets into the Elasticsearch infrastructure. From here, responders can examine
    network activity in near-real time. Another method that Arkime can be leveraged
    for is loading offline packet captures for indexing.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: Arkime 是一个开源的数据包捕获与搜索系统，允许分析师和响应者检查大量的网络数据包捕获。默认情况下，Arkime 会将数据包捕获按捕获中包含的各个会话进行组织。Arkime
    可以作为网络监控系统使用，通过将数据包导入到 Elasticsearch 基础架构中，响应者可以实时查看网络活动。另一个 Arkime 的使用方式是加载离线数据包捕获进行索引。
- en: Installation instructions for Arkime can be found on GitHub at [https://raw.githubusercontent.com/arkime/arkime/master/release/README.txt](https://raw.githubusercontent.com/arkime/arkime/master/release/README.txt).
    Arkime can be installed on a variety of Linux desktop or server platforms. The
    server option provides larger teams with the ability to share data concerning
    packet captures, as well as evaluate running captures. Desktop installations are
    an option for responders that will be handling offline data and who do not need
    to share the results.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: Arkime 的安装说明可以在 GitHub 上找到，网址为 [https://raw.githubusercontent.com/arkime/arkime/master/release/README.txt](https://raw.githubusercontent.com/arkime/arkime/master/release/README.txt)。Arkime
    可以安装在各种 Linux 桌面或服务器平台上。服务器选项为较大的团队提供了共享数据包捕获数据和评估正在运行的捕获的能力。桌面安装适用于处理离线数据并且不需要共享结果的响应者。
- en: In this section, we will use Arkime to analyze a packet capture from a system
    related to a phishing attack. This packet capture can be found at [https://malware-traffic-analysis.net/2022/02/25/2022-02-25-Emotet-epoch4-with-spambot-activity.pcap.zip](https://malware-traffic-analysis.net/2022/02/25/2022-02-25-Emotet-epoch4-with-spambot-activity.pcap.zip).
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用 Arkime 分析来自与钓鱼攻击相关的系统的一个数据包捕获。该数据包捕获文件可以在[https://malware-traffic-analysis.net/2022/02/25/2022-02-25-Emotet-epoch4-with-spambot-activity.pcap.zip](https://malware-traffic-analysis.net/2022/02/25/2022-02-25-Emotet-epoch4-with-spambot-activity.pcap.zip)找到。
- en: 'First, create a directory in Arkime for offline packet captures. This can be
    done in the `home` directory. Next, transfer the packet capture using SFTP to
    the offline packet capture directory. Finally, use the Arkime capture binary,
    which can be found in the `/opt/arkime/bin` directory, to process the packet capture
    using the following command:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，在 Arkime 中为离线数据包捕获创建一个目录。这可以在 `home` 目录中完成。接下来，使用 SFTP 将数据包捕获文件传输到离线数据包捕获目录中。最后，使用位于
    `/opt/arkime/bin` 目录中的 Arkime 捕获二进制文件，使用以下命令处理数据包捕获：
- en: '[PRE12]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The preceding command takes the `2022-02-25-Emotet-epoch4-with-spambot-activity.pcap`
    file and processes it so that it can be reviewed with the GUI. An important thing
    to note is the `-r` parameter, which only processes a single capture. If there
    are multiple captures, the binary can be run with the `-R` parameter set, which
    recursively processes all the packet captures in the directory. *Figure 9**.11*
    shows the packet capture being processed:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 上述命令处理`2022-02-25-Emotet-epoch4-with-spambot-activity.pcap`文件，使其可以通过 GUI 进行查看。需要注意的一点是`-r`参数，它只处理单个数据包捕获。如果有多个捕获，可以使用`-R`参数运行二进制文件，这将递归处理目录中的所有数据包捕获。*图
    9.11* 显示了正在处理的数据包捕获：
- en: '![](img/Image_B18571_09_11.jpg)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Image_B18571_09_11.jpg)'
- en: Figure 9.11 – Arkime PCAP import
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.11 – Arkime PCAP 导入
- en: 'Once completed, open a web browser and navigate to the IP address of the server
    or workstation with port `8005`. This will open the Arkime interface. In the top
    left, set the time to **All**. Once the time has been set, the following view
    will appear:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，打开浏览器并导航到服务器或工作站的 IP 地址，并指定端口 `8005`。这将打开 Arkime 界面。在左上角，将时间设置为**全部**。设置时间后，将显示以下视图：
- en: '![](img/Image_B18571_09_12.jpg)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Image_B18571_09_12.jpg)'
- en: Figure 9.12 – Arkime GUI dashboard
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.12 – Arkime GUI 仪表板
- en: 'Arkime is a feature-rich platform. The following steps provide an overview
    of some of the features available in examining offline packet captures:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: Arkime 是一个功能丰富的平台。以下步骤概述了在检查离线数据包捕获时可用的一些功能：
- en: 'An examination of the packet capture from the dashboard identifies several
    different sessions where the internal system at `10.2.25.101` is communicating
    with external IP addresses. To narrow down the search results to internet traffic
    over HTTP, the following search query should be entered into the search bar:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 仪表板中对数据包捕获的检查识别出几个不同的会话，其中`10.2.25.101`的内部系统正在与外部IP地址进行通信。为了将搜索结果缩小为HTTP上的互联网流量，应该在搜索栏中输入以下查询：
- en: '![](img/Image_B18571_09_13.jpg)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Image_B18571_09_13.jpg)'
- en: Figure 9.13 – HTTP port 80 query
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.13 – HTTP端口80查询
- en: 'This shows that there were two TCP sessions with a destination port of `80`.
    These sessions can be sorted by any of the fields present in the dashboard. One
    key piece of data that is useful is the bytes that are transferred as part of
    the session. Large deltas between bytes sent and received may indicate data exfiltration
    if the bytes sent are larger or, in the case of this capture, bytes received,
    which can indicate a file transfer, as seen in these entries:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这表明有两个目标端口为`80`的TCP会话。这些会话可以通过仪表板中显示的任何字段进行排序。一个有用的关键数据是会话中传输的字节数。如果发送和接收的字节数之间存在较大差异，可能表明存在数据外泄，如果发送的字节数较大，或者在本次捕获中，接收的字节数较大，则可能表示文件传输，如以下条目所示：
- en: '![](img/Image_B18571_09_14.jpg)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Image_B18571_09_14.jpg)'
- en: Figure 9.14 – HTTP session data
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.14 – HTTP会话数据
- en: 'The far right of the dashboard contains URIs and associated information concerning
    the sessions. For example, a check of the sessions over HTTP indicates that the
    local host navigated to what appears to be a Windows update site:'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 仪表板的最右侧包含关于会话的URI及相关信息。例如，检查HTTP上的会话表明本地主机访问了一个看起来像是Windows更新站点的页面：
- en: '![](img/Image_B18571_09_15.jpg)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Image_B18571_09_15.jpg)'
- en: Figure 9.15 – Arkime URI data
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.15 – Arkime URI数据
- en: 'Arkime provides additional information for the session in the same session
    row as the information URI related to the Windows Update. Clicking on the green
    plus sign box opens the following page:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Arkime在与Windows更新相关的信息URI所在的同一会话行中提供了额外的信息。点击绿色加号框，将打开以下页面：
- en: '![](img/Image_B18571_09_16.jpg)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Image_B18571_09_16.jpg)'
- en: Figure 9.16 – Session data
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.16 – 会话数据
- en: 'Further down, under the **HTTP** heading, is valuable data concerning the connection:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更下方，在**HTTP**标题下，是有关连接的有价值数据：
- en: '![](img/Image_B18571_09_17.jpg)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Image_B18571_09_17.jpg)'
- en: Figure 9.17 – HTTP session data
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.17 – HTTP会话数据
- en: 'Another feature that is useful with Arkime is the ability to visualize connections.
    At the top of the Arkime web application is **Connections**. If you click on **Connections**,
    the following will appear:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Arkime的另一个有用功能是能够可视化连接。在Arkime web应用程序的顶部有**连接**选项。如果点击**连接**，将出现以下内容：
- en: '![](img/Image_B18571_09_18.jpg)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Image_B18571_09_18.jpg)'
- en: Figure 9.18 – Arkime connections graph
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.18 – Arkime连接图
- en: Next, let’s have a look at how to reset Arkime.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看如何重置Arkime。
- en: How do I reset Arkime?
  id: totrans-157
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 我该如何重置Arkime？
- en: At the end of the analysis, there are two ways to clear the existing data in
    preparation for subsequent analysis. The first is to deploy Arkime on a virtualization
    platform such as VMware. Here, you can create a new installation and then capture
    a snapshot of the new installation. Once the analysis is complete, you can revert
    to the fresh installation snapshot.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在分析结束时，有两种方法可以清除现有数据，为后续分析做准备。第一种方法是在虚拟化平台（如VMware）上部署Arkime。在此，你可以创建一个新的安装，并捕获新安装的快照。一旦分析完成，你可以恢复到新的安装快照。
- en: 'Another method is to either rerun the `init` or `wipe` command. The steps are
    as follows:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法是重新运行`init`或`wipe`命令。步骤如下：
- en: Leave Elasticsearch running.
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保持Elasticsearch运行。
- en: Shut down all running viewer or capture processes so that no new data is recorded.
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 关闭所有正在运行的查看器或捕获进程，以确保不会录制新的数据。
- en: 'To delete all the SPI data stored in Elasticsearch, use the `db.pl` script
    with either the `init` or `wipe` command. The only difference between the two
    commands is that `wipe` leaves the added users so that they don’t need to be re-added:'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要删除存储在Elasticsearch中的所有SPI数据，请使用`db.pl`脚本，并使用`init`或`wipe`命令。两个命令之间的唯一区别是，`wipe`保留已添加的用户，以便它们不需要重新添加：
- en: '[PRE13]'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Delete the PCAP files. The PCAP files are stored on the filesystem in `raw`
    format. You need to do this on all of the capture machines:'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 删除PCAP文件。PCAP文件以`raw`格式存储在文件系统中。你需要在所有捕获机器上执行此操作：
- en: '[PRE14]'
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The major advantage to Arkime is the ability to view the network traffic in
    a flow view. For a more detailed packet-by-packet view, the best tool to leverage
    is Wireshark, which we will cover next.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: Arkime 的主要优势是能够以流视图查看网络流量。对于更详细的逐包视图，最好的工具是 Wireshark，接下来我们将介绍它。
- en: Wireshark
  id: totrans-167
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Wireshark
- en: Wireshark is one of the most popular packet capture analysis tools available
    to incident response analysts. In addition to the ability to capture packets,
    a great many other features are available. As entire volumes and training courses
    are built around this platform, it is impossible to identify every feature. Therefore,
    this chapter will focus on some of the key features of Wireshark that are most
    applicable to an incident investigation.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: Wireshark 是事件响应分析人员最受欢迎的数据包捕获分析工具之一。除了捕获数据包的功能外，还有许多其他功能可用。由于大量的书籍和培训课程围绕这个平台构建，因此很难列出所有的功能。因此，本章将重点介绍一些在事件调查中最为适用的
    Wireshark 关键功能。
- en: Wireshark resources
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: Wireshark 资源
- en: Arguably, Wireshark is the packet analyzer of choice for IT and security professionals.
    Due to the ubiquity of the application, there are a wide variety of resources
    available for additional training on Wireshark and its capabilities. The Wireshark
    site at [https://www.wireshark.org/](https://www.wireshark.org/) contains a great
    deal of information. Furthermore, the site at [https://www.chappell-university.com/](https://www.chappell-university.com/)
    contains exercises and training packet captures to hone skills regarding analysis.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 可以说，Wireshark 是 IT 和安全专业人员首选的数据包分析工具。由于该应用的普及，市场上有大量资源可用于深入学习 Wireshark 及其功能。Wireshark
    官网[https://www.wireshark.org/](https://www.wireshark.org/)提供了丰富的信息。此外，[https://www.chappell-university.com/](https://www.chappell-university.com/)网站提供了练习和培训数据包捕获，以帮助提升分析技能。
- en: Additionally, Lisa Bock, who authored *Learn Wireshark*, provided an in-depth
    treatment of Wireshark in her book, which is available at [https://www.packtpub.com/product/learn-wireshark-fundamentals-of-wireshark/9781789134506](https://www.packtpub.com/product/learn-wireshark-fundamentals-of-wireshark/9781789134506).
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，《*Learn Wireshark*》一书的作者 Lisa Bock 在她的书中对 Wireshark 进行了深入的讲解，该书可在[https://www.packtpub.com/product/learn-wireshark-fundamentals-of-wireshark/9781789134506](https://www.packtpub.com/product/learn-wireshark-fundamentals-of-wireshark/9781789134506)上找到。
- en: 'Because Wireshark is a feature-rich tool, some settings lend themselves more
    to network traffic analysis that are outside incident response activities. As
    a result, some changes need to be made to better assist the incident response
    analyst with performing packet capture analysis concerning an incident investigation:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 Wireshark 是一款功能丰富的工具，一些设置更适合用于网络流量分析，而不适用于事件响应活动。因此，需要进行一些更改，以更好地帮助事件响应分析人员执行有关事件调查的数据包捕获分析：
- en: '**Time**: The time setting in Wireshark provides several options. These include
    the time of the packet since 1/1/1970 or since the start of the packet capture.
    One of these options, which can be useful in an incident investigation, is the
    date and time when the individual packets were captured. This allows analysts
    to correlate the date and time of other suspicious or malicious activity with
    the date and time of specific traffic within the packet capture. To enable this,
    navigate to **View** and then to **Time Display Format**. From there, choose one
    of the time options, such as **Date and Time** or **Day or Time of Day**. Another
    option to consider is utilizing the UTC options. This is very useful if the internal
    network utilizes UTC rather than local time. The time can also be set to nanoseconds.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**时间**：Wireshark 中的时间设置提供了多个选项。包括自 1970 年 1 月 1 日起或自数据包捕获开始起的时间。这些选项中有一个在事件调查中非常有用的功能，即单个数据包捕获的日期和时间。这使得分析人员能够将其他可疑或恶意活动的日期和时间与数据包捕获中特定流量的日期和时间进行关联。要启用此功能，请导航到
    **视图**，然后选择 **时间显示格式**。从中选择一个时间选项，如 **日期和时间** 或 **日期或一天中的时间**。另一个可以考虑的选项是使用 UTC
    时间选项。如果内部网络使用 UTC 而非本地时间，这将非常有用。时间还可以设置为纳秒级。'
- en: '**Name resolution**: The name resolution setting allows analysts to toggle
    between seeing the IP addresses of the source and destination hosts and hostname
    resolution. This is useful if an analyst is examining a packet capture and wants
    to determine if any suspicious hostnames have been found. For example, if the
    packet capture is open, you will see various IP addresses:'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**名称解析**：名称解析设置允许分析人员在查看源主机和目标主机的 IP 地址与主机名解析之间切换。如果分析人员正在检查数据包捕获并希望确定是否发现了任何可疑的主机名，这将非常有用。例如，如果打开数据包捕获，你将看到各种
    IP 地址：'
- en: '![](img/Image_B18571_09_19.jpg)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Image_B18571_09_19.jpg)'
- en: Figure 9.19 – Wireshark IP address view
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.19 – Wireshark IP 地址视图
- en: 'To determine the hostnames, navigate to **View** and then **Name Resolution**.
    Click on **Resolve Network Addresses**. Wireshark will then resolve the IP addresses
    to hostnames:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 要确定主机名，请导航到 **查看** 然后选择 **名称解析**。点击 **解析网络地址**。Wireshark 将解析 IP 地址为主机名：
- en: '![](img/Image_B18571_09_20.jpg)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Image_B18571_09_20.jpg)'
- en: Figure 9.20 – Wireshark domain name view
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.20 – Wireshark 域名视图
- en: '**Colorize packet list**: This feature allows analysts to toggle between a
    blank background of the packet list or to allow Wireshark to color-code the packets:'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据包列表着色**：此功能允许分析人员在数据包列表的空白背景和让 Wireshark 为数据包上色之间切换：'
- en: '![](img/Image_B18571_09_21.jpg)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Image_B18571_09_21.jpg)'
- en: Figure 9.21 – Wireshark – Coloring Rules Classic
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.21 – Wireshark – 经典着色规则
- en: For this chapter, an exploration of Wireshark will be done while utilizing a
    packet capture that can be found on Malware Traffic Analysis at [https://malware-traffic-analysis.net/2022/04/14/index.html](https://malware-traffic-analysis.net/2022/04/14/index.html).
    This packet capture includes downloading a copy of the Qakbot malware, along with
    Cobalt Strike. For this chapter, several key elements of the packet capture will
    be identified. Before examining the packet capture, Wireshark was configured so
    that the date and time are visible, and so that the hostnames were identified.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，将使用位于 [https://malware-traffic-analysis.net/2022/04/14/index.html](https://malware-traffic-analysis.net/2022/04/14/index.html)
    的恶意软件流量分析中的数据包捕获进行 Wireshark 探索。该数据包捕获包括下载 Qakbot 恶意软件副本以及 Cobalt Strike。对于本章，将识别数据包捕获中的几个关键元素。在检查数据包捕获之前，Wireshark
    已配置为显示日期和时间，并识别主机名。
- en: 'The following are some of the features in Wireshark that provide key pieces
    of information from the packet capture:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 Wireshark 中的一些功能，它们提供了从数据包捕获中获得的关键信息：
- en: '`ip.src==10.4.14.101` syntax, which displays the following:'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ip.src==10.4.14.101` 语法，显示以下内容：'
- en: '![](img/Image_B18571_09_22.jpg)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Image_B18571_09_22.jpg)'
- en: Figure 9.22 – Source address filter
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.22 – 源地址过滤器
- en: '**Host identification**: Another key aspect of analyzing packet captures is
    to identify the localhost, if applicable. Considering that this packet capture
    is from a single host, identifying the hostname, IP address, and MAC address is
    straightforward. By double-clicking on the individual packet, a great deal of
    information can be found:'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**主机识别**：分析数据包捕获的另一个关键方面是识别本地主机（如果适用）。考虑到这个数据包捕获来自单一主机，识别主机名、IP 地址和 MAC 地址是直接的。通过双击单个数据包，可以找到大量信息：'
- en: '![](img/Image_B18571_09_23.jpg)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Image_B18571_09_23.jpg)'
- en: Figure 9.23 – Packet data
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.23 – 数据包数据
- en: '`80`.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`80`。'
- en: '`http`. Pay attention while entering this in the filter, as several different
    filters will be available. Once the filter has been typed in, click the right-facing
    arrow located at the far right of the dialog box. Wireshark will now limit the
    view of packets to those that are utilizing the HTTP protocol:'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`http`。在输入此过滤器时请注意，因为将有多个不同的过滤器可用。一旦输入了过滤器，点击对话框右侧的右箭头。Wireshark 将限制显示仅使用 HTTP
    协议的数据包：'
- en: '![](img/Image_B18571_09_24.jpg)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Image_B18571_09_24.jpg)'
- en: Figure 9.24 – HTTP packet view
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.24 – HTTP 数据包视图
- en: '`geobram.com`, may be a suspect URL. Another feature of Wireshark is the ability
    to follow the TCP or HTTP stream of communication between the source and destination
    hosts. If you right-click on the `rozhan-hse.com` hostname, the following will
    appear:'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`geobram.com` 可能是一个可疑的 URL。Wireshark 的另一个功能是能够跟踪源主机与目标主机之间的 TCP 或 HTTP 通信流。如果你右键点击
    `rozhan-hse.com` 主机名，将会出现以下内容：'
- en: '![](img/Image_B18571_09_25.jpg)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Image_B18571_09_25.jpg)'
- en: Figure 9.25 – Follow HTTP Stream
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.25 – 跟踪 HTTP 流
- en: 'A second window will appear; click on **HTTP Stream** and a third window will
    appear. This window contains the HTTP packets in a format that can be read. The
    incident response analyst can review this output to determine what types of files
    may have been sent or received:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 将会出现第二个窗口；点击**HTTP流**，第三个窗口将会出现。此窗口以可以读取的格式显示HTTP数据包。事件响应分析员可以查看此输出，确定可能已发送或接收的文件类型：
- en: '![](img/Image_B18571_09_26.jpg)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Image_B18571_09_26.jpg)'
- en: Figure 9.26 – HTTP packet data
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.26 – HTTP数据包信息
- en: '`GET` command is reaching out to the `NO_2950435796.zip` file. An analyst may
    want to extract this file for analysis. Click on **File** and then **Export Objects**,
    and then **HTTP**; a window will appear listing all of the files associated with
    the HTTP connections. This list can be sorted on any of the fields at the top
    of the window. In this case, select the hostname and scroll down until the suspected
    URL is located:'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`GET`命令正在访问`NO_2950435796.zip`文件。分析员可能需要提取该文件进行分析。点击**文件**，然后点击**导出对象**，再点击**HTTP**；会出现一个窗口，列出所有与HTTP连接相关的文件。此列表可以根据窗口顶部的任意字段进行排序。在这种情况下，选择主机名并向下滚动，直到找到可疑的URL：'
- en: '![](img/Image_B18571_09_27.jpg)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Image_B18571_09_27.jpg)'
- en: Figure 9.27 – Wireshark – Export – HTTP object list
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.27 – Wireshark – 导出 – HTTP对象列表
- en: From here, the analyst can click on the file and save it onto the local system
    for later analysis. *Chapter 12* will take select files and evaluate them for
    malicious code.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 从这里，分析员可以点击文件并将其保存到本地系统以供后续分析。*第12章*将选择文件并评估其中的恶意代码。
- en: Wireshark is a powerful tool for conducting a detailed analysis of packet captures.
    The ability to drill down to individual packets and dissect them allows analysts
    to gain a very detailed sense of what is contained within the traffic running
    to and from external hosts, as well as to and from internal hosts. This visibility
    can afford the analyst possible insight into how an infected host communicates
    with an external host, or even identify other hosts that may have become compromised.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: Wireshark是一个强大的工具，用于对数据包捕获进行详细分析。能够深入查看每个数据包并对其进行剖析，帮助分析员非常详细地了解流向外部主机和内部主机之间的流量内容。这种可见性可以为分析员提供潜在的洞察，了解受感染的主机如何与外部主机通信，甚至识别其他可能已被攻陷的主机。
- en: Summary
  id: totrans-206
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Security incidents not only produce trace evidence on host systems but also
    leave traces throughout the devices and traffic flows within a network. The ability
    to analyze this trace evidence will allow incident response analysts to have a
    better understanding of what type of incident they are investigating, as well
    as potential actions that can be taken. This chapter addressed how to evaluate
    log files through the rapid process of blacklist comparison or DNS analysis to
    log analysis utilizing the Elastic Stack or other SIEM systems. To augment this
    primary method of network evidence evaluation, we covered NetFlow analysis, and
    examined packet captures with Arkime and Wireshark. Network evidence is a critical
    component of incident investigation. This trace evidence, taken in conjunction
    with evidence obtained from potentially compromised websites, goes a long way
    in allowing analysts to reconstruct the events of an incident.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 安全事件不仅会在主机系统上产生痕迹，还会在网络中的设备和流量流经的路径上留下痕迹。分析这些痕迹证据将帮助事件响应分析员更好地理解他们正在调查的事件类型，以及可以采取的潜在措施。本章讲解了如何通过快速的黑名单对比、DNS分析以及使用Elastic
    Stack或其他SIEM系统进行日志分析来评估日志文件。为了增强这一主要的网络证据评估方法，我们还介绍了NetFlow分析，并使用Arkime和Wireshark进行了数据包捕获分析。网络证据是事件调查中的关键组成部分。结合从可能被攻陷的网站获取的证据，这些痕迹证据有助于分析员重建事件的发生过程。
- en: The next chapter will move the focus from network traffic to the host, and memory
    analysis will be explored.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章将把焦点从网络流量转向主机，接着会探讨内存分析。
- en: Questions
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: 'Answer the following questions to test your knowledge of this chapter:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 回答以下问题，测试你对本章内容的掌握：
- en: A filtered log review is one where the responder or analyst filters out specific
    logs based on a set parameter.
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 过滤日志审查是指响应者或分析员根据设定的参数过滤特定日志。
- en: 'True'
  id: totrans-212
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 正确
- en: 'False'
  id: totrans-213
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 错误
- en: What is not a component of the Elastic Stack?
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Elastic Stack的组成部分不包括什么？
- en: Elasticsearch
  id: totrans-215
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Elasticsearch
- en: Log forwarder
  id: totrans-216
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 日志转发器
- en: Logstash
  id: totrans-217
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Logstash
- en: Kibana
  id: totrans-218
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Kibana
- en: Which packet analysis tool places the packet capture into sessions as the default
    view?
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪个数据包分析工具默认将数据包捕获按会话进行分类？
- en: Wireshark
  id: totrans-220
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Wireshark
- en: NetFlow
  id: totrans-221
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: NetFlow
- en: Elastic Stack
  id: totrans-222
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Elastic Stack
- en: Arkime
  id: totrans-223
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Arkime
- en: Wireshark does not allow for DNS name resolution.
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Wireshark 不支持 DNS 名称解析。
- en: 'True'
  id: totrans-225
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 正确
- en: 'False'
  id: totrans-226
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 错误
- en: Further reading
  id: totrans-227
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'Refer to the following links for more information about the topics covered
    in this chapter:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考以下链接，获取本章所涉及主题的更多信息：
- en: '*Elasticsearch 7.0 Cookbook - Fourth* *Edition*: [https://www.packtpub.com/big-data-and-business-intelligence/elasticsearch-70-cookbook-fourth-edition](https://www.packtpub.com/big-data-and-business-intelligence/elasticsearch-70-cookbook-fourth-edition).'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Elasticsearch 7.0 Cookbook - 第四* *版*: [https://www.packtpub.com/big-data-and-business-intelligence/elasticsearch-70-cookbook-fourth-edition](https://www.packtpub.com/big-data-and-business-intelligence/elasticsearch-70-cookbook-fourth-edition)。'
- en: '*Malware traffic* *analysis*: [https://www.malware-traffic-analysis.net](https://www.malware-traffic-analysis.net).'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*恶意软件流量* *分析*: [https://www.malware-traffic-analysis.net](https://www.malware-traffic-analysis.net)。'
- en: '*Arkime*: [https://arkime.com/](https://arkime.com/).'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Arkime*: [https://arkime.com/](https://arkime.com/)。'
- en: '*Chappell* *University*: [https://www.chappell-university.com/](https://www.chappell-university.com/).'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*查普尔大学*: [https://www.chappell-university.com/](https://www.chappell-university.com/)。'
- en: '*Cisco IOS* *NetFlow*: [https://www.cisco.com/c/en/us/products/ios-nx-os-software/ios-netflow/index.html](https://www.cisco.com/c/en/us/products/ios-nx-os-software/ios-netflow/index.html).'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*思科IOS* *NetFlow*: [https://www.cisco.com/c/en/us/products/ios-nx-os-software/ios-netflow/index.html](https://www.cisco.com/c/en/us/products/ios-nx-os-software/ios-netflow/index.html)。'
